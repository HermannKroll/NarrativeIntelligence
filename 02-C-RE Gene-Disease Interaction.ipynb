{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should process a grid search for lstm?\n",
    "do_grid_search = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of docs: 9645\n",
      "Document splitted: 3215 train, 3215 dev and 3215 test\n",
      "Amount of sentences: 27763 train, 27526 dev and 27823 test\n"
     ]
    }
   ],
   "source": [
    "from ksnorkel import KSUtils\n",
    "\n",
    "train_sent, dev_sent, test_sent = KSUtils.split_sentences(session)\n",
    "print(\"Amount of sentences: {} train, {} dev and {} test\".format(len(train_sent), len(dev_sent), len(test_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 67/27763 [00:00<00:44, 626.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27763/27763 [00:10<00:00, 2628.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 3051\n",
      "Clearing existing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 34/27526 [00:00<01:23, 329.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27526/27526 [00:10<00:00, 2558.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 3304\n",
      "Clearing existing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 107/27823 [00:00<00:26, 1065.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27823/27823 [00:10<00:00, 2708.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 3124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Candidate, candidate_subclass\n",
    "from snorkel.candidates import PretaggedCandidateExtractor\n",
    "\n",
    "GeneDiseaseInteraction = candidate_subclass('GeneDiseaseInteraction', ['gene', 'disease'])\n",
    "candidate_extractor = PretaggedCandidateExtractor(GeneDiseaseInteraction, ['Gene', 'Disease'])\n",
    "\n",
    "for k, sents in enumerate([train_sent,dev_sent, test_sent]):\n",
    "    candidate_extractor.apply(sents, split=k, clear=True)\n",
    "    print(\"Number of candidates:\", session.query(GeneDiseaseInteraction).filter(GeneDiseaseInteraction.split == k).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25339259 chemical-gene assocations read from ChG-CTD_chem_gene_ixns\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import re\n",
    "\n",
    "ctd_gene_disease_inter = set()\n",
    "i = 0\n",
    "with gzip.open('data/CTD_genes_diseases.tsv.gz','r') as f:\n",
    "    for l in f:\n",
    "        line = str(l).replace('b\\'', '').replace('\\\\n\\'', '').replace('\\\\r','')\n",
    "        # skip comments\n",
    "        if line.startswith('#'):\n",
    "            continue\n",
    "        #print(line)\n",
    "        components = line.split('\\\\t')    \n",
    "        \n",
    "        # add MESH:\n",
    "        if not components[3].startswith('MESH:'):\n",
    "            components[3] = \"MESH:\" + components[1]\n",
    "        \n",
    "        #print(components)\n",
    "        gene = components[1]\n",
    "        disease = components[3]\n",
    "        key = frozenset((gene, disease))\n",
    "        #print(key)\n",
    "        ctd_gene_disease_inter.add(key)\n",
    "        i += 1\n",
    "\n",
    "\n",
    "    \n",
    "print('{} chemical-gene assocations read from ChG-CTD_chem_gene_ixns'.format(len(ctd_gene_disease_inter)))\n",
    "#240349"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cand_in_gene_disease_interactions(c):\n",
    "    key = frozenset((c.gene_cid, c.disease_cid))\n",
    "    if key in ctd_gene_disease_inter:\n",
    "    #    print(key)\n",
    "        return 1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing gold labels...\n",
      "Adding gold labels to training candidates...\n",
      "Labeld 1738 positive and 1313 negative samples in train\n",
      "Adding gold labels to develop candidates...\n",
      "Labeld 2140 positive and 1164 negative samples in dev\n",
      "Adding gold labels to test candidates...\n",
      "Labeld 1908 positive and 1216 negative samples in test\n",
      "Finished - commiting to database...\n",
      "Commit complete!\n",
      "Labeld 5786 positive and 3693 negative samples\n"
     ]
    }
   ],
   "source": [
    "from ksnorkel import KSUtils\n",
    "\n",
    "KSUtils.add_gold_labels_for_candidates(session, GeneDiseaseInteraction, cand_in_gene_disease_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def LF_GD_in_CTD_chem_gene(c):\n",
    "    if cand_in_gene_disease_interactions(c) == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "\n",
    "LFs_GD = [\n",
    "    LF_GD_in_CTD_chem_gene\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 79/3051 [00:00<00:03, 782.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3051/3051 [00:04<00:00, 760.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.07 s, sys: 28 ms, total: 4.1 s\n",
      "Wall time: 4.09 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_GD_in_CTD_chem_gene</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        j  Coverage  Overlaps  Conflicts\n",
       "LF_GD_in_CTD_chem_gene  0       1.0       0.0        0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.annotations import LabelAnnotator\n",
    "labeler = LabelAnnotator(lfs=LFs_GD)\n",
    "%time L_train = labeler.apply(lfs=LFs_GD, parallelism=1)\n",
    "L_train\n",
    "\n",
    "L_train.lf_stats(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 59/3304 [00:00<00:05, 588.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3304/3304 [00:04<00:00, 662.57it/s]\n",
      "  1%|▏         | 46/3124 [00:00<00:06, 456.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3124/3124 [00:04<00:00, 692.72it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "L_dev = labeler.apply_existing(split=1)\n",
    "L_test = labeler.apply_existing(split=2)\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold',split=1)\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 0 dependencies\n",
      "============================================================\n",
      "[1] Testing step_size = 1.00e-05, decay = 9.00e-01, epochs = 100, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 1.0\n",
      "[GenerativeModel] Model saved as <GenerativeModel_0>.\n",
      "[GenerativeModel] Model saved as <GenerativeModel_best>.\n",
      "============================================================\n",
      "[2] Testing step_size = 1.00e-04, decay = 9.00e-01, epochs = 100, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 1.0\n",
      "============================================================\n",
      "[3] Testing step_size = 1.00e-05, decay = 9.50e-01, epochs = 50, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 1.0\n",
      "============================================================\n",
      "[4] Testing step_size = 1.00e-05, decay = 9.50e-01, epochs = 100, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 1.0\n",
      "============================================================\n",
      "[5] Testing step_size = 1.00e-03, decay = 9.00e-01, epochs = 50, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 1.0\n",
      "[GenerativeModel] Model <GenerativeModel_0> loaded.\n",
      "CPU times: user 10.7 s, sys: 24 ms, total: 10.7 s\n",
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "from snorkel.learning import RandomSearch\n",
    "from snorkel.learning.structure import DependencySelector\n",
    "\n",
    "\n",
    "MAX_DEPS = 5\n",
    "\n",
    "ds = DependencySelector()\n",
    "deps = ds.select(L_train, threshold=0.1)\n",
    "deps = set(list(deps)[0:min(len(deps), MAX_DEPS)])\n",
    "\n",
    "print(\"Using {} dependencies\".format(len(deps)))\n",
    "\n",
    "\n",
    "\n",
    "# use random search to optimize the generative model\n",
    "param_grid = {\n",
    "    'step_size' : [1e-3, 1e-4, 1e-5, 1e-6],\n",
    "    'decay'     : [0.9, 0.95],\n",
    "    'epochs'    : [50,100],\n",
    "    'reg_param' : [1e-3],\n",
    "}\n",
    "\n",
    "model_class_params = {'lf_propensity' : False }#, 'deps': deps}\n",
    "\n",
    "searcher = RandomSearch(GenerativeModel, param_grid, L_train, n=5, model_class_params=model_class_params)\n",
    "%time gen_model, run_stats = searcher.fit(L_dev, L_gold_dev) #, deps=deps)\n",
    "run_stats\n",
    "\n",
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_marginals, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 1.0\n",
      "Neg. class accuracy: 1.0\n",
      "Precision            1.0\n",
      "Recall               1.0\n",
      "F1                   1.0\n",
      "----------------------------------------\n",
      "TP: 2140 | FP: 0 | TN: 1164 | FN: 0\n",
      "========================================\n",
      "\n",
      "Saved 3051 marginals\n",
      "CPU times: user 2.28 s, sys: 116 ms, total: 2.39 s\n",
      "Wall time: 2.4 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import save_marginals\n",
    "\n",
    "dev_marginals = gen_model.marginals(L_dev)\n",
    "_, _, _, _ = gen_model.error_analysis(session, L_dev, L_gold_dev)\n",
    "\n",
    "%time save_marginals(session, L_train, train_marginals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 1.0\n",
      "Neg. class accuracy: 1.0\n",
      "Precision            1.0\n",
      "Recall               1.0\n",
      "F1                   1.0\n",
      "----------------------------------------\n",
      "TP: 1908 | FP: 0 | TN: 1216 | FN: 0\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn = gen_model.error_analysis(session, L_test, L_gold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load all GeneDiseaseInteraction candidates from db...\n",
      "3051 3304 3124\n",
      "Amount of all candidates: 9479\n"
     ]
    }
   ],
   "source": [
    "print(\"Load all GeneDiseaseInteraction candidates from db...\")\n",
    "train_cands = session.query(GeneDiseaseInteraction).filter(GeneDiseaseInteraction.split == 0).order_by(GeneDiseaseInteraction.id).all()\n",
    "dev_cands   = session.query(GeneDiseaseInteraction).filter(GeneDiseaseInteraction.split == 1).order_by(GeneDiseaseInteraction.id).all()\n",
    "test_cands  = session.query(GeneDiseaseInteraction).filter(GeneDiseaseInteraction.split == 2).order_by(GeneDiseaseInteraction.id).all()\n",
    "\n",
    "\n",
    "all_cands = []\n",
    "all_cands.extend(train_cands)\n",
    "all_cands.extend(dev_cands)\n",
    "all_cands.extend(test_cands)\n",
    "\n",
    "\n",
    "print(\"{} {} {}\".format(len(train_cands), len(dev_cands), len(test_cands)))\n",
    "print(\"Amount of all candidates: {}\".format(len(all_cands)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-23-903cac04292d>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-903cac04292d>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    if not\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning.pytorch import LSTM\n",
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "#train_kwargs = {\n",
    "#    'lr':            0.01,\n",
    "#    'embedding_dim': 75,\n",
    "#    'hidden_dim':    75,\n",
    "#    'n_epochs':      100,\n",
    "#    'dropout':       0.25,\n",
    "#    'seed':          1701\n",
    "#}\n",
    "\n",
    "if not do_grid_search:\n",
    "    # Best configuration\n",
    "    train_kwargs = {\n",
    "        'lr':            0.0010,\n",
    "        'embedding_dim': 125,\n",
    "        'hidden_dim':    100,\n",
    "        'n_epochs':      100,\n",
    "        'dropout':       0.50,\n",
    "        'rebalance':     0.0,\n",
    "        'seed':          1701\n",
    "    }\n",
    "\n",
    "    lstm = LSTM(n_threads=10)\n",
    "    lstm.train(train_cands, train_marginals, X_dev=dev_cands, Y_dev=L_gold_dev, **train_kwargs)\n",
    "\n",
    "    p, r, f1 = lstm.score(test_cands, L_gold_test)\n",
    "    print(\"Prec: {0:.3f}, Recall: {1:.3f}, F1 Score: {2:.3f}\".format(p, r, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from snorkel.learning import RandomSearch\n",
    "#from snorkel.learning.pytorch import LSTM\n",
    "\n",
    "if do_grid_search:\n",
    "    seed = 12345\n",
    "    num_model_search = 25\n",
    "\n",
    "    # search over this parameter grid\n",
    "    param_grid = {}\n",
    "    param_grid['batch_size'] = [64, 128]\n",
    "    param_grid['lr']         = [1e-4, 1e-3, 1e-2]\n",
    "    param_grid['rebalance']  = [0.0,0.25, 0.5]\n",
    "    param_grid['embedding_dim'] = [75, 100, 125]\n",
    "    param_grid['hidden_dim'] = [50, 100, 150]\n",
    "    param_grid['dropout'] = [0, 0.25, 0.5]\n",
    "\n",
    "    model_class_params = {\n",
    "        'n_threads':1\n",
    "    }\n",
    "\n",
    "\n",
    "    model_hyperparams = {\n",
    "        'n_epochs': 100,\n",
    "        'print_freq': 25,\n",
    "        'dev_ckpt_delay': 0.5,\n",
    "        'X_dev': dev_cands,\n",
    "        'Y_dev': L_gold_dev,\n",
    "    }\n",
    "\n",
    "\n",
    "    searcher = RandomSearch(LSTM, param_grid, train_cands, train_marginals,\n",
    "                            n=num_model_search, seed=seed,\n",
    "                            model_class_params=model_class_params,\n",
    "                            model_hyperparams=model_hyperparams)\n",
    "\n",
    "    print(\"Discriminitive Model Parameter Space (seed={}):\".format(seed))\n",
    "    for i, params in enumerate(searcher.search_space()):\n",
    "        print(\"{} {}\".format(i, params))\n",
    "\n",
    "    disc_model, run_stats = searcher.fit(X_valid=dev_cands, Y_valid=L_gold_dev, n_threads=1)\n",
    "    lstm = disc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_grid_search:\n",
    "    run_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.681, Recall: 0.861, F1 Score: 0.760\n"
     ]
    }
   ],
   "source": [
    "p, r, f1 = lstm.score(test_cands, L_gold_test)\n",
    "print(\"Prec: {0:.3f}, Recall: {1:.3f}, F1 Score: {2:.3f}\".format(p, r, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.861\n",
      "Neg. class accuracy: 0.366\n",
      "Precision            0.681\n",
      "Recall               0.861\n",
      "F1                   0.76\n",
      "----------------------------------------\n",
      "TP: 1643 | FP: 771 | TN: 445 | FN: 265\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn = lstm.error_analysis(session, test_cands, L_gold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 9479 marginals\n"
     ]
    }
   ],
   "source": [
    "lstm.save_marginals(session, all_cands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing candidate labels into result file...\n",
      "Amount of candidates: 9479\n",
      "Storing candidate labels into result file: results/chemical_gene_interaction.tsv\n",
      "Amount of candidates: 9479\n",
      "Load mariginals from db...\n",
      "Marginals loaded!\n",
      "Building sentence to document map...\n",
      "Map built!\n",
      "Saved 6816 positive predicitions for binary relation!\n",
      "CPU times: user 1min 43s, sys: 2.69 s, total: 1min 46s\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models.candidate import Marginal\n",
    "from snorkel.models import Document, Sentence\n",
    "\n",
    "\n",
    "print(\"Storing candidate labels into result file...\")\n",
    "amount_of_candidates = session.query(Candidate).count()\n",
    "print(\"Amount of candidates: {}\".format(amount_of_candidates))\n",
    "\n",
    "all_sents = []\n",
    "all_sents.extend(train_sent)\n",
    "all_sents.extend(dev_sent)\n",
    "all_sents.extend(test_sent)\n",
    "\n",
    "header_str = '{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}'.format('document_id', 'sentence_id', 'cand_id','gene_cid', 'gene_span', 'disease_cid', 'disease_span')\n",
    "%time KSUtils.save_binary_relation_as_tsv('results/chemical_gene_interaction.tsv', session, all_cands, all_sents, header_str, 'gene_cid', 'disease_cid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM] Model saved as <gene_disease_interaction.lstm>\n"
     ]
    }
   ],
   "source": [
    "lstm.save(\"gene_disease_interaction.lstm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snorkel)",
   "language": "python",
   "name": "snorkel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
