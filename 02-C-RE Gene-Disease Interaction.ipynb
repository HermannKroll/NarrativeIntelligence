{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of docs: 9645\n",
      "Document splitted: 3215 train, 3215 dev and 3215 test\n",
      "Amount of sentences: 27763 train, 27526 dev and 27823 test\n"
     ]
    }
   ],
   "source": [
    "from ksnorkel import KSUtils\n",
    "\n",
    "train_sent, dev_sent, test_sent = KSUtils.split_sentences(session)\n",
    "print(\"Amount of sentences: {} train, {} dev and {} test\".format(len(train_sent), len(dev_sent), len(test_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 67/27763 [00:00<00:44, 626.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27763/27763 [00:10<00:00, 2628.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 3051\n",
      "Clearing existing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 34/27526 [00:00<01:23, 329.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27526/27526 [00:10<00:00, 2558.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 3304\n",
      "Clearing existing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 107/27823 [00:00<00:26, 1065.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27823/27823 [00:10<00:00, 2708.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 3124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Candidate, candidate_subclass\n",
    "from snorkel.candidates import PretaggedCandidateExtractor\n",
    "\n",
    "GeneDiseaseInteraction = candidate_subclass('GeneDiseaseInteraction', ['gene', 'disease'])\n",
    "candidate_extractor = PretaggedCandidateExtractor(GeneDiseaseInteraction, ['Gene', 'Disease'])\n",
    "\n",
    "for k, sents in enumerate([train_sent,dev_sent, test_sent]):\n",
    "    candidate_extractor.apply(sents, split=k, clear=True)\n",
    "    print(\"Number of candidates:\", session.query(GeneDiseaseInteraction).filter(GeneDiseaseInteraction.split == k).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25339259 chemical-gene assocations read from ChG-CTD_chem_gene_ixns\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import re\n",
    "\n",
    "ctd_gene_disease_inter = set()\n",
    "i = 0\n",
    "with gzip.open('data/CTD_genes_diseases.tsv.gz','r') as f:\n",
    "    for l in f:\n",
    "        line = str(l).replace('b\\'', '').replace('\\\\n\\'', '').replace('\\\\r','')\n",
    "        # skip comments\n",
    "        if line.startswith('#'):\n",
    "            continue\n",
    "        #print(line)\n",
    "        components = line.split('\\\\t')    \n",
    "        \n",
    "        # add MESH:\n",
    "        if not components[3].startswith('MESH:'):\n",
    "            components[3] = \"MESH:\" + components[1]\n",
    "        \n",
    "        #print(components)\n",
    "        gene = components[1]\n",
    "        disease = components[3]\n",
    "        key = frozenset((gene, disease))\n",
    "        #print(key)\n",
    "        ctd_gene_disease_inter.add(key)\n",
    "        i += 1\n",
    "\n",
    "\n",
    "    \n",
    "print('{} chemical-gene assocations read from ChG-CTD_chem_gene_ixns'.format(len(ctd_gene_disease_inter)))\n",
    "#240349"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cand_in_gene_disease_interactions(c):\n",
    "    key = frozenset((c.gene_cid, c.disease_cid))\n",
    "    if key in ctd_gene_disease_inter:\n",
    "    #    print(key)\n",
    "        return 1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing gold labels...\n",
      "Adding gold labels to training candidates...\n",
      "Labeld 1738 positive and 1313 negative samples in train\n",
      "Adding gold labels to develop candidates...\n",
      "Labeld 2140 positive and 1164 negative samples in dev\n",
      "Adding gold labels to test candidates...\n",
      "Labeld 1908 positive and 1216 negative samples in test\n",
      "Finished - commiting to database...\n",
      "Commit complete!\n",
      "Labeld 5786 positive and 3693 negative samples\n"
     ]
    }
   ],
   "source": [
    "from ksnorkel import KSUtils\n",
    "\n",
    "KSUtils.add_gold_labels_for_candidates(session, GeneDiseaseInteraction, cand_in_gene_disease_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def LF_GD_in_CTD_chem_gene(c):\n",
    "    if cand_in_gene_disease_interactions(c) == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "\n",
    "LFs_GD = [\n",
    "    LF_GD_in_CTD_chem_gene\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 79/3051 [00:00<00:03, 782.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3051/3051 [00:04<00:00, 760.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.07 s, sys: 28 ms, total: 4.1 s\n",
      "Wall time: 4.09 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_GD_in_CTD_chem_gene</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        j  Coverage  Overlaps  Conflicts\n",
       "LF_GD_in_CTD_chem_gene  0       1.0       0.0        0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.annotations import LabelAnnotator\n",
    "labeler = LabelAnnotator(lfs=LFs_GD)\n",
    "%time L_train = labeler.apply(lfs=LFs_GD, parallelism=1)\n",
    "L_train\n",
    "\n",
    "L_train.lf_stats(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 59/3304 [00:00<00:05, 588.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3304/3304 [00:04<00:00, 662.57it/s]\n",
      "  1%|▏         | 46/3124 [00:00<00:06, 456.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3124/3124 [00:04<00:00, 692.72it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "L_dev = labeler.apply_existing(split=1)\n",
    "L_test = labeler.apply_existing(split=2)\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold',split=1)\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 0 dependencies\n",
      "============================================================\n",
      "[1] Testing step_size = 1.00e-05, decay = 9.00e-01, epochs = 100, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 1.0\n",
      "[GenerativeModel] Model saved as <GenerativeModel_0>.\n",
      "[GenerativeModel] Model saved as <GenerativeModel_best>.\n",
      "============================================================\n",
      "[2] Testing step_size = 1.00e-04, decay = 9.00e-01, epochs = 100, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 1.0\n",
      "============================================================\n",
      "[3] Testing step_size = 1.00e-05, decay = 9.50e-01, epochs = 50, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 1.0\n",
      "============================================================\n",
      "[4] Testing step_size = 1.00e-05, decay = 9.50e-01, epochs = 100, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 1.0\n",
      "============================================================\n",
      "[5] Testing step_size = 1.00e-03, decay = 9.00e-01, epochs = 50, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 1.0\n",
      "[GenerativeModel] Model <GenerativeModel_0> loaded.\n",
      "CPU times: user 10.7 s, sys: 24 ms, total: 10.7 s\n",
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "from snorkel.learning import RandomSearch\n",
    "from snorkel.learning.structure import DependencySelector\n",
    "\n",
    "\n",
    "MAX_DEPS = 5\n",
    "\n",
    "ds = DependencySelector()\n",
    "deps = ds.select(L_train, threshold=0.1)\n",
    "deps = set(list(deps)[0:min(len(deps), MAX_DEPS)])\n",
    "\n",
    "print(\"Using {} dependencies\".format(len(deps)))\n",
    "\n",
    "\n",
    "\n",
    "# use random search to optimize the generative model\n",
    "param_grid = {\n",
    "    'step_size' : [1e-3, 1e-4, 1e-5, 1e-6],\n",
    "    'decay'     : [0.9, 0.95],\n",
    "    'epochs'    : [50,100],\n",
    "    'reg_param' : [1e-3],\n",
    "}\n",
    "\n",
    "model_class_params = {'lf_propensity' : False }#, 'deps': deps}\n",
    "\n",
    "searcher = RandomSearch(GenerativeModel, param_grid, L_train, n=5, model_class_params=model_class_params)\n",
    "%time gen_model, run_stats = searcher.fit(L_dev, L_gold_dev) #, deps=deps)\n",
    "run_stats\n",
    "\n",
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_marginals, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 1.0\n",
      "Neg. class accuracy: 1.0\n",
      "Precision            1.0\n",
      "Recall               1.0\n",
      "F1                   1.0\n",
      "----------------------------------------\n",
      "TP: 2140 | FP: 0 | TN: 1164 | FN: 0\n",
      "========================================\n",
      "\n",
      "Saved 3051 marginals\n",
      "CPU times: user 2.28 s, sys: 116 ms, total: 2.39 s\n",
      "Wall time: 2.4 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import save_marginals\n",
    "\n",
    "dev_marginals = gen_model.marginals(L_dev)\n",
    "_, _, _, _ = gen_model.error_analysis(session, L_dev, L_gold_dev)\n",
    "\n",
    "%time save_marginals(session, L_train, train_marginals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 1.0\n",
      "Neg. class accuracy: 1.0\n",
      "Precision            1.0\n",
      "Recall               1.0\n",
      "F1                   1.0\n",
      "----------------------------------------\n",
      "TP: 1908 | FP: 0 | TN: 1216 | FN: 0\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn = gen_model.error_analysis(session, L_test, L_gold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load all GeneDiseaseInteraction candidates from db...\n",
      "3051 3304 3124\n",
      "Amount of all candidates: 9479\n"
     ]
    }
   ],
   "source": [
    "print(\"Load all GeneDiseaseInteraction candidates from db...\")\n",
    "train_cands = session.query(GeneDiseaseInteraction).filter(GeneDiseaseInteraction.split == 0).order_by(GeneDiseaseInteraction.id).all()\n",
    "dev_cands   = session.query(GeneDiseaseInteraction).filter(GeneDiseaseInteraction.split == 1).order_by(GeneDiseaseInteraction.id).all()\n",
    "test_cands  = session.query(GeneDiseaseInteraction).filter(GeneDiseaseInteraction.split == 2).order_by(GeneDiseaseInteraction.id).all()\n",
    "\n",
    "\n",
    "all_cands = []\n",
    "all_cands.extend(train_cands)\n",
    "all_cands.extend(dev_cands)\n",
    "all_cands.extend(test_cands)\n",
    "\n",
    "\n",
    "print(\"{} {} {}\".format(len(train_cands), len(dev_cands), len(test_cands)))\n",
    "print(\"Amount of all candidates: {}\".format(len(all_cands)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM] Training model\n",
      "[LSTM] n_train=3051  #epochs=100  batch size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kroll/.conda/envs/snorkel/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM] Epoch 1 (11.88s)\tAverage loss=0.678665\tDev F1=76.59\n",
      "[LSTM] Epoch 2 (26.41s)\tAverage loss=0.594396\tDev F1=68.99\n",
      "[LSTM] Epoch 3 (41.13s)\tAverage loss=0.494145\tDev F1=65.96\n",
      "[LSTM] Epoch 4 (55.58s)\tAverage loss=0.441609\tDev F1=53.10\n",
      "[LSTM] Epoch 5 (70.40s)\tAverage loss=0.405789\tDev F1=72.63\n",
      "[LSTM] Epoch 6 (85.00s)\tAverage loss=0.392210\tDev F1=59.08\n",
      "[LSTM] Epoch 7 (99.29s)\tAverage loss=0.374789\tDev F1=52.90\n",
      "[LSTM] Epoch 8 (113.76s)\tAverage loss=0.363318\tDev F1=60.06\n",
      "[LSTM] Epoch 9 (127.91s)\tAverage loss=0.362813\tDev F1=64.02\n",
      "[LSTM] Epoch 10 (160.00s)\tAverage loss=0.352726\tDev F1=60.27\n",
      "[LSTM] Epoch 11 (178.23s)\tAverage loss=0.352033\tDev F1=66.75\n",
      "[LSTM] Epoch 12 (192.53s)\tAverage loss=0.348584\tDev F1=62.34\n",
      "[LSTM] Epoch 13 (206.47s)\tAverage loss=0.346925\tDev F1=56.06\n",
      "[LSTM] Epoch 14 (220.84s)\tAverage loss=0.341198\tDev F1=51.69\n",
      "[LSTM] Epoch 15 (234.99s)\tAverage loss=0.355560\tDev F1=64.37\n",
      "[LSTM] Epoch 16 (248.92s)\tAverage loss=0.344476\tDev F1=69.19\n",
      "[LSTM] Epoch 17 (263.00s)\tAverage loss=0.336612\tDev F1=71.11\n",
      "[LSTM] Epoch 18 (277.35s)\tAverage loss=0.334184\tDev F1=71.30\n",
      "[LSTM] Epoch 19 (291.38s)\tAverage loss=0.334552\tDev F1=60.97\n",
      "[LSTM] Epoch 20 (305.47s)\tAverage loss=0.333808\tDev F1=67.02\n",
      "[LSTM] Epoch 21 (320.88s)\tAverage loss=0.335313\tDev F1=72.17\n",
      "[LSTM] Epoch 22 (335.36s)\tAverage loss=0.332715\tDev F1=65.85\n",
      "[LSTM] Epoch 23 (349.62s)\tAverage loss=0.330847\tDev F1=70.75\n",
      "[LSTM] Epoch 24 (363.81s)\tAverage loss=0.331496\tDev F1=69.49\n",
      "[LSTM] Epoch 25 (378.28s)\tAverage loss=0.329249\tDev F1=66.58\n",
      "[LSTM] Epoch 26 (392.92s)\tAverage loss=0.328950\tDev F1=67.87\n",
      "[LSTM] Epoch 27 (407.43s)\tAverage loss=0.328858\tDev F1=69.06\n",
      "[LSTM] Epoch 28 (421.73s)\tAverage loss=0.331191\tDev F1=63.67\n",
      "[LSTM] Epoch 29 (435.86s)\tAverage loss=0.329990\tDev F1=68.95\n",
      "[LSTM] Epoch 30 (450.41s)\tAverage loss=0.329535\tDev F1=65.63\n",
      "[LSTM] Epoch 31 (464.37s)\tAverage loss=0.331092\tDev F1=66.80\n",
      "[LSTM] Epoch 32 (478.22s)\tAverage loss=0.331238\tDev F1=68.96\n",
      "[LSTM] Epoch 33 (492.79s)\tAverage loss=0.339222\tDev F1=68.85\n",
      "[LSTM] Epoch 34 (507.84s)\tAverage loss=0.333746\tDev F1=70.94\n",
      "[LSTM] Epoch 35 (522.60s)\tAverage loss=0.329425\tDev F1=66.48\n",
      "[LSTM] Epoch 36 (537.09s)\tAverage loss=0.329787\tDev F1=65.70\n",
      "[LSTM] Epoch 37 (551.20s)\tAverage loss=0.327884\tDev F1=72.61\n",
      "[LSTM] Epoch 38 (565.83s)\tAverage loss=0.327450\tDev F1=69.58\n",
      "[LSTM] Epoch 39 (579.98s)\tAverage loss=0.328025\tDev F1=71.91\n",
      "[LSTM] Epoch 40 (594.11s)\tAverage loss=0.328781\tDev F1=71.03\n",
      "[LSTM] Epoch 41 (608.23s)\tAverage loss=0.330855\tDev F1=65.27\n",
      "[LSTM] Epoch 42 (623.28s)\tAverage loss=0.332060\tDev F1=69.48\n",
      "[LSTM] Epoch 43 (637.62s)\tAverage loss=0.334015\tDev F1=69.16\n",
      "[LSTM] Epoch 44 (651.42s)\tAverage loss=0.328961\tDev F1=70.89\n",
      "[LSTM] Epoch 45 (665.95s)\tAverage loss=0.327896\tDev F1=72.36\n",
      "[LSTM] Epoch 46 (680.61s)\tAverage loss=0.325837\tDev F1=66.77\n",
      "[LSTM] Epoch 47 (695.57s)\tAverage loss=0.326781\tDev F1=72.86\n",
      "[LSTM] Epoch 48 (710.84s)\tAverage loss=0.329157\tDev F1=74.65\n",
      "[LSTM] Epoch 49 (726.95s)\tAverage loss=0.325236\tDev F1=69.42\n",
      "[LSTM] Epoch 50 (742.04s)\tAverage loss=0.327358\tDev F1=65.11\n",
      "[LSTM] Epoch 51 (756.87s)\tAverage loss=0.324892\tDev F1=70.96\n",
      "[LSTM] Epoch 52 (771.44s)\tAverage loss=0.347913\tDev F1=66.45\n",
      "[LSTM] Epoch 53 (786.03s)\tAverage loss=0.339893\tDev F1=71.96\n",
      "[LSTM] Epoch 54 (800.08s)\tAverage loss=0.330124\tDev F1=70.90\n",
      "[LSTM] Epoch 55 (814.72s)\tAverage loss=0.331301\tDev F1=67.75\n",
      "[LSTM] Epoch 56 (828.98s)\tAverage loss=0.328878\tDev F1=68.12\n",
      "[LSTM] Epoch 57 (843.26s)\tAverage loss=0.325313\tDev F1=70.61\n",
      "[LSTM] Epoch 58 (857.72s)\tAverage loss=0.325293\tDev F1=70.45\n",
      "[LSTM] Epoch 59 (872.04s)\tAverage loss=0.325106\tDev F1=70.45\n",
      "[LSTM] Epoch 60 (886.09s)\tAverage loss=0.325025\tDev F1=69.83\n",
      "[LSTM] Epoch 61 (899.98s)\tAverage loss=0.324907\tDev F1=69.67\n",
      "[LSTM] Epoch 62 (916.06s)\tAverage loss=0.326203\tDev F1=70.88\n",
      "[LSTM] Epoch 63 (930.42s)\tAverage loss=0.324264\tDev F1=71.46\n",
      "[LSTM] Epoch 64 (944.77s)\tAverage loss=0.324386\tDev F1=70.35\n",
      "[LSTM] Epoch 65 (959.28s)\tAverage loss=0.324096\tDev F1=70.63\n",
      "[LSTM] Epoch 66 (974.12s)\tAverage loss=0.324850\tDev F1=68.84\n",
      "[LSTM] Epoch 67 (989.11s)\tAverage loss=0.324899\tDev F1=69.18\n",
      "[LSTM] Epoch 68 (1004.52s)\tAverage loss=0.324253\tDev F1=69.74\n",
      "[LSTM] Epoch 69 (1019.84s)\tAverage loss=0.323956\tDev F1=70.08\n",
      "[LSTM] Epoch 70 (1034.57s)\tAverage loss=0.324114\tDev F1=71.13\n",
      "[LSTM] Epoch 71 (1050.12s)\tAverage loss=0.324285\tDev F1=69.95\n",
      "[LSTM] Epoch 72 (1064.93s)\tAverage loss=0.323899\tDev F1=70.49\n",
      "[LSTM] Epoch 73 (1079.23s)\tAverage loss=0.323795\tDev F1=70.05\n",
      "[LSTM] Epoch 74 (1093.83s)\tAverage loss=0.323960\tDev F1=69.91\n",
      "[LSTM] Epoch 75 (1108.49s)\tAverage loss=0.324188\tDev F1=70.21\n",
      "[LSTM] Epoch 76 (1122.86s)\tAverage loss=0.323821\tDev F1=70.24\n",
      "[LSTM] Epoch 77 (1138.01s)\tAverage loss=0.323848\tDev F1=69.94\n",
      "[LSTM] Model saved as <LSTM>\n",
      "[LSTM] Epoch 78 (1152.33s)\tAverage loss=0.324110\tDev F1=69.85\n",
      "[LSTM] Epoch 79 (1166.27s)\tAverage loss=0.323710\tDev F1=70.63\n",
      "[LSTM] Model saved as <LSTM>\n",
      "[LSTM] Epoch 80 (1180.56s)\tAverage loss=0.324511\tDev F1=67.75\n",
      "[LSTM] Epoch 81 (1195.13s)\tAverage loss=0.325293\tDev F1=67.90\n",
      "[LSTM] Epoch 82 (1210.30s)\tAverage loss=0.330390\tDev F1=75.01\n",
      "[LSTM] Model saved as <LSTM>\n",
      "[LSTM] Epoch 83 (1226.26s)\tAverage loss=0.324953\tDev F1=70.80\n",
      "[LSTM] Epoch 84 (1241.01s)\tAverage loss=0.323223\tDev F1=69.82\n",
      "[LSTM] Epoch 85 (1255.43s)\tAverage loss=0.327159\tDev F1=68.88\n",
      "[LSTM] Epoch 86 (1269.55s)\tAverage loss=0.342176\tDev F1=72.13\n",
      "[LSTM] Epoch 87 (1283.72s)\tAverage loss=0.337483\tDev F1=72.77\n",
      "[LSTM] Epoch 88 (1297.80s)\tAverage loss=0.332721\tDev F1=71.62\n",
      "[LSTM] Epoch 89 (1311.70s)\tAverage loss=0.331223\tDev F1=68.95\n",
      "[LSTM] Epoch 90 (1326.08s)\tAverage loss=0.329955\tDev F1=71.93\n",
      "[LSTM] Epoch 91 (1340.48s)\tAverage loss=0.330564\tDev F1=66.75\n",
      "[LSTM] Epoch 92 (1354.74s)\tAverage loss=0.329607\tDev F1=73.22\n",
      "[LSTM] Epoch 93 (1368.94s)\tAverage loss=0.328181\tDev F1=68.81\n",
      "[LSTM] Epoch 94 (1383.23s)\tAverage loss=0.327367\tDev F1=71.28\n",
      "[LSTM] Epoch 95 (1397.72s)\tAverage loss=0.326686\tDev F1=70.76\n",
      "[LSTM] Epoch 96 (1412.07s)\tAverage loss=0.327075\tDev F1=70.86\n",
      "[LSTM] Epoch 97 (1426.13s)\tAverage loss=0.327037\tDev F1=71.03\n",
      "[LSTM] Epoch 98 (1440.45s)\tAverage loss=0.326519\tDev F1=71.18\n",
      "[LSTM] Epoch 99 (1454.67s)\tAverage loss=0.326601\tDev F1=71.19\n",
      "[LSTM] Epoch 100 (1468.96s)\tAverage loss=0.326308\tDev F1=71.39\n",
      "[LSTM] Training done (1473.13s)\n",
      "[LSTM] Loaded model <LSTM>\n",
      "Prec: 0.681, Recall: 0.861, F1 Score: 0.760\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning.pytorch import LSTM\n",
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "#train_kwargs = {\n",
    "#    'lr':            0.01,\n",
    "#    'embedding_dim': 75,\n",
    "#    'hidden_dim':    75,\n",
    "#    'n_epochs':      100,\n",
    "#    'dropout':       0.25,\n",
    "#    'seed':          1701\n",
    "#}\n",
    "# Best configuration\n",
    "train_kwargs = {\n",
    "    'lr':            0.0010,\n",
    "    'embedding_dim': 125,\n",
    "    'hidden_dim':    100,\n",
    "    'n_epochs':      100,\n",
    "    'dropout':       0.50,\n",
    "    'rebalance':     0.0,\n",
    "    'seed':          1701\n",
    "}\n",
    "\n",
    "lstm = LSTM(n_threads=10)\n",
    "lstm.train(train_cands, train_marginals, X_dev=dev_cands, Y_dev=L_gold_dev, **train_kwargs)\n",
    "\n",
    "p, r, f1 = lstm.score(test_cands, L_gold_test)\n",
    "print(\"Prec: {0:.3f}, Recall: {1:.3f}, F1 Score: {2:.3f}\".format(p, r, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from snorkel.learning import RandomSearch\n",
    "#from snorkel.learning.pytorch import LSTM\n",
    "\n",
    "#seed = 12345\n",
    "#num_model_search = 25\n",
    "\n",
    "# search over this parameter grid\n",
    "#param_grid = {}\n",
    "#param_grid['batch_size'] = [64, 128]\n",
    "#param_grid['lr']         = [1e-4, 1e-3, 1e-2]\n",
    "#param_grid['rebalance']  = [0.0,0.25, 0.5]\n",
    "#param_grid['embedding_dim'] = [75, 100, 125]\n",
    "#param_grid['hidden_dim'] = [50, 100, 150]\n",
    "#param_grid['dropout'] = [0, 0.25, 0.5]\n",
    "\n",
    "#model_class_params = {\n",
    "#    'n_threads':1\n",
    "#}\n",
    "\n",
    "\n",
    "#model_hyperparams = {\n",
    "#    'n_epochs': 100,\n",
    "#    'print_freq': 25,\n",
    "#    'dev_ckpt_delay': 0.5,\n",
    "#    'X_dev': dev_cands,\n",
    "#    'Y_dev': L_gold_dev,\n",
    "#}\n",
    "\n",
    "\n",
    "#searcher = RandomSearch(LSTM, param_grid, train_cands, train_marginals,\n",
    "#                        n=num_model_search, seed=seed,\n",
    "#                        model_class_params=model_class_params,\n",
    "#                        model_hyperparams=model_hyperparams)\n",
    "\n",
    "#print(\"Discriminitive Model Parameter Space (seed={}):\".format(seed))\n",
    "#for i, params in enumerate(searcher.search_space()):\n",
    "#    print(\"{} {}\".format(i, params))\n",
    "\n",
    "#disc_model, run_stats = searcher.fit(X_valid=dev_cands, Y_valid=L_gold_dev, n_threads=1)\n",
    "#lstm = disc_model\n",
    "#run_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.681, Recall: 0.861, F1 Score: 0.760\n"
     ]
    }
   ],
   "source": [
    "p, r, f1 = lstm.score(test_cands, L_gold_test)\n",
    "print(\"Prec: {0:.3f}, Recall: {1:.3f}, F1 Score: {2:.3f}\".format(p, r, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.861\n",
      "Neg. class accuracy: 0.366\n",
      "Precision            0.681\n",
      "Recall               0.861\n",
      "F1                   0.76\n",
      "----------------------------------------\n",
      "TP: 1643 | FP: 771 | TN: 445 | FN: 265\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn = lstm.error_analysis(session, test_cands, L_gold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 9479 marginals\n"
     ]
    }
   ],
   "source": [
    "lstm.save_marginals(session, all_cands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing candidate labels into result file...\n",
      "Amount of candidates: 9479\n",
      "Storing candidate labels into result file: results/chemical_gene_interaction.tsv\n",
      "Amount of candidates: 9479\n",
      "Load mariginals from db...\n",
      "Marginals loaded!\n",
      "Building sentence to document map...\n",
      "Map built!\n",
      "Saved 6816 positive predicitions for binary relation!\n",
      "CPU times: user 1min 43s, sys: 2.69 s, total: 1min 46s\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models.candidate import Marginal\n",
    "from snorkel.models import Document, Sentence\n",
    "\n",
    "\n",
    "print(\"Storing candidate labels into result file...\")\n",
    "amount_of_candidates = session.query(Candidate).count()\n",
    "print(\"Amount of candidates: {}\".format(amount_of_candidates))\n",
    "\n",
    "all_sents = []\n",
    "all_sents.extend(train_sent)\n",
    "all_sents.extend(dev_sent)\n",
    "all_sents.extend(test_sent)\n",
    "\n",
    "header_str = '{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}'.format('document_id', 'sentence_id', 'cand_id','gene_cid', 'gene_span', 'disease_cid', 'disease_span')\n",
    "%time KSUtils.save_binary_relation_as_tsv('results/chemical_gene_interaction.tsv', session, all_cands, all_sents, header_str, 'gene_cid', 'disease_cid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM] Model saved as <gene_disease_interaction.lstm>\n"
     ]
    }
   ],
   "source": [
    "lstm.save(\"gene_disease_interaction.lstm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snorkel)",
   "language": "python",
   "name": "snorkel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
