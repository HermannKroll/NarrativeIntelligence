{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should process a grid search for lstm?\n",
    "do_grid_search = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reload Snorkel Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Train, Dev and Test sentences. Default Split is 1:1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of docs: 9645\n",
      "Document splitted: 3215 train, 3215 dev and 3215 test\n",
      "Amount of sentences: 27763 train, 27526 dev and 27823 test\n"
     ]
    }
   ],
   "source": [
    "from ksnorkel import KSUtils\n",
    "\n",
    "train_sent, dev_sent, test_sent = KSUtils.split_sentences(session)\n",
    "print(\"Amount of sentences: {} train, {} dev and {} test\".format(len(train_sent), len(dev_sent), len(test_sent)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now generate all candidates for each sentence set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/27763 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27763/27763 [00:21<00:00, 1305.98it/s]\n",
      "  0%|          | 68/27526 [00:00<00:40, 676.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 5861\n",
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27526/27526 [00:15<00:00, 1732.62it/s]\n",
      "  0%|          | 116/27823 [00:00<00:24, 1110.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 6165\n",
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27823/27823 [00:16<00:00, 1655.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 6437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Candidate, candidate_subclass\n",
    "from snorkel.candidates import PretaggedCandidateExtractor\n",
    "\n",
    "ChemicalDisease = candidate_subclass('ChemicalDisease', ['chemical', 'disease'])\n",
    "candidate_extractor = PretaggedCandidateExtractor(ChemicalDisease, ['Chemical', 'Disease'])\n",
    "\n",
    "for k, sents in enumerate([train_sent,dev_sent, test_sent]):\n",
    "    candidate_extractor.apply(sents, split=k, clear=True)\n",
    "    print(\"Number of candidates:\", session.query(ChemicalDisease).filter(ChemicalDisease.split == k).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load CTD Dataset as gold label for drug disease associations\n",
    "(see http://ctdbase.org/downloads/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 2414520 drug-disease associations from CTD\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "\n",
    "\n",
    "ctd_drug_disease_associations = set()\n",
    "with gzip.open('data/CTD_chemicals_diseases.tsv.gz','r') as f:\n",
    "    for l in f:\n",
    "        line = str(l).replace('b\\'', '').replace('\\\\n\\'', '')\n",
    "        # skip comments\n",
    "        if line.startswith('#'):\n",
    "            continue\n",
    "        # split line into components\n",
    "        components = line.split('\\\\t')\n",
    "        # add MESH:\n",
    "        if not components[1].startswith('MESH:'):\n",
    "            components[1] = \"MESH:\" + components[1]\n",
    "        if not components[4].startswith('MESH:'):\n",
    "            components[4] = \"MESH:\" + components[4]\n",
    "        \n",
    "        #print(\"{} {}\".format(components[1], components[4]))\n",
    "        key = frozenset((components[1], components[4]))\n",
    "        ctd_drug_disease_associations.add(key)\n",
    "\n",
    "print(\"Read {} drug-disease associations from CTD\".format(len(ctd_drug_disease_associations)))\n",
    "       \n",
    "def cand_in_ctd_drug_disease_associations(c):\n",
    "    key = frozenset((c.chemical_cid, c.disease_cid))\n",
    "    #print(key)\n",
    "    return 1 if key in ctd_drug_disease_associations else -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label all candidates of ChemicalDiesease with CTD als a ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing gold labels...\n",
      "Adding gold labels to training candidates...\n",
      "Labeld 2635 positive and 3226 negative samples in train\n",
      "Adding gold labels to develop candidates...\n",
      "Labeld 2910 positive and 3255 negative samples in dev\n",
      "Adding gold labels to test candidates...\n",
      "Labeld 2875 positive and 3562 negative samples in test\n",
      "Finished - commiting to database...\n",
      "Commit complete!\n",
      "Labeld 8420 positive and 10043 negative samples\n"
     ]
    }
   ],
   "source": [
    "from ksnorkel import KSUtils\n",
    "\n",
    "KSUtils.add_gold_labels_for_candidates(session, ChemicalDisease, cand_in_ctd_drug_disease_associations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labeling function for ctd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_cd_in_CTD(c):\n",
    "    if cand_in_ctd_drug_disease_associations(c) == 1:\n",
    "        return 1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from snorkel.lf_helpers import (\n",
    "    get_tagged_text,\n",
    "    rule_regex_search_tagged_text,\n",
    "    rule_regex_search_btw_AB,\n",
    "    rule_regex_search_btw_BA,\n",
    "    rule_regex_search_before_A,\n",
    "    rule_regex_search_before_B,\n",
    ")\n",
    "\n",
    "# List to parenthetical\n",
    "def ltp(x):\n",
    "    return '(' + '|'.join(x) + ')'\n",
    "\n",
    "def LF_induce(c):\n",
    "    return 1 if re.search(r'{{A}}.{0,20}induc.{0,20}{{B}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "causal_past = ['induced', 'caused', 'due']\n",
    "def LF_d_induced_by_c(c):\n",
    "    return rule_regex_search_btw_BA(c, '.{0,50}' + ltp(causal_past) + '.{0,9}(by|to).{0,50}', 1)\n",
    "def LF_d_induced_by_c_tight(c):\n",
    "    return rule_regex_search_btw_BA(c, '.{0,50}' + ltp(causal_past) + ' (by|to) ', 1)\n",
    "\n",
    "def LF_induce_name(c):\n",
    "    return 1 if 'induc' in c.chemical.get_span().lower() else 0     \n",
    "\n",
    "causal = ['cause[sd]?', 'induce[sd]?', 'associated with']\n",
    "def LF_c_cause_d(c):\n",
    "    return 1 if (\n",
    "        re.search(r'{{A}}.{0,50} ' + ltp(causal) + '.{0,50}{{B}}', get_tagged_text(c), re.I)\n",
    "        and not re.search('{{A}}.{0,50}(not|no).{0,20}' + ltp(causal) + '.{0,50}{{B}}', get_tagged_text(c), re.I)\n",
    "    ) else 0\n",
    "\n",
    "treat = ['treat', 'effective', 'prevent', 'resistant', 'slow', 'promise', 'therap']\n",
    "def LF_d_treat_c(c):\n",
    "    return rule_regex_search_btw_BA(c, '.{0,50}' + ltp(treat) + '.{0,50}', -1)\n",
    "def LF_c_treat_d(c):\n",
    "    return rule_regex_search_btw_AB(c, '.{0,50}' + ltp(treat) + '.{0,50}', -1)\n",
    "def LF_treat_d(c):\n",
    "    return rule_regex_search_before_B(c, ltp(treat) + '.{0,50}', -1)\n",
    "def LF_c_treat_d_wide(c):\n",
    "    return rule_regex_search_btw_AB(c, '.{0,200}' + ltp(treat) + '.{0,200}', -1)\n",
    "\n",
    "def LF_c_d(c):\n",
    "    return 1 if ('{{A}} {{B}}' in get_tagged_text(c)) else 0\n",
    "\n",
    "def LF_c_induced_d(c):\n",
    "    return 1 if (\n",
    "        ('{{A}} {{B}}' in get_tagged_text(c)) and \n",
    "        (('-induc' in c[0].get_span().lower()) or ('-assoc' in c[0].get_span().lower()))\n",
    "        ) else 0\n",
    "\n",
    "def LF_improve_before_disease(c):\n",
    "    return rule_regex_search_before_B(c, 'improv.*', -1)\n",
    "\n",
    "pat_terms = ['in a patient with ', 'in patients with']\n",
    "def LF_in_patient_with(c):\n",
    "    return -1 if re.search(ltp(pat_terms) + '{{B}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "uncertain = ['combin', 'possible', 'unlikely']\n",
    "def LF_uncertain(c):\n",
    "    return rule_regex_search_before_A(c, ltp(uncertain) + '.*', -1)\n",
    "\n",
    "def LF_induced_other(c):\n",
    "    return rule_regex_search_tagged_text(c, '{{A}}.{20,1000}-induced {{B}}', -1)\n",
    "\n",
    "def LF_far_c_d(c):\n",
    "    return rule_regex_search_btw_AB(c, '.{100,5000}', -1)\n",
    "\n",
    "def LF_far_d_c(c):\n",
    "    return rule_regex_search_btw_BA(c, '.{100,5000}', -1)\n",
    "\n",
    "def LF_risk_d(c):\n",
    "    return rule_regex_search_before_B(c, 'risk of ', 1)\n",
    "\n",
    "def LF_develop_d_following_c(c):\n",
    "    return 1 if re.search(r'develop.{0,25}{{B}}.{0,25}following.{0,25}{{A}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "procedure, following = ['inject', 'administrat'], ['following']\n",
    "def LF_d_following_c(c):\n",
    "    return 1 if re.search('{{B}}.{0,50}' + ltp(following) + '.{0,20}{{A}}.{0,50}' + ltp(procedure), get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "def LF_measure(c):\n",
    "    return -1 if re.search('measur.{0,75}{{A}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "def LF_level(c):\n",
    "    return -1 if re.search('{{A}}.{0,25} level', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "def LF_neg_d(c):\n",
    "    return -1 if re.search('(none|not|no) .{0,25}{{B}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "WEAK_PHRASES = ['none', 'although', 'was carried out', 'was conducted',\n",
    "                'seems', 'suggests', 'risk', 'implicated',\n",
    "               'the aim', 'to (investigate|assess|study)']\n",
    "\n",
    "WEAK_RGX = r'|'.join(WEAK_PHRASES)\n",
    "\n",
    "def LF_weak_assertions(c):\n",
    "    return -1 if re.search(WEAK_RGX, get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "\n",
    "def LF_closer_chem(c):\n",
    "    # Get distance between chemical and disease\n",
    "    chem_start, chem_end = c.chemical.get_word_start(), c.chemical.get_word_end()\n",
    "    dis_start, dis_end = c.disease.get_word_start(), c.disease.get_word_end()\n",
    "    if dis_start < chem_start:\n",
    "        dist = chem_start - dis_end\n",
    "    else:\n",
    "        dist = dis_start - chem_end\n",
    "    # Try to find chemical closer than @dist/2 in either direction\n",
    "    sent = c.get_parent()\n",
    "    closest_other_chem = float('inf')\n",
    "    for i in range(dis_end, min(len(sent.words), dis_end + dist // 2)):\n",
    "        et, cid = sent.entity_types[i], sent.entity_cids[i]\n",
    "        if et == 'Chemical' and cid != sent.entity_cids[chem_start]:\n",
    "            return -1\n",
    "    for i in range(max(0, dis_start - dist // 2), dis_start):\n",
    "        et, cid = sent.entity_types[i], sent.entity_cids[i]\n",
    "        if et == 'Chemical' and cid != sent.entity_cids[chem_start]:\n",
    "            return -1\n",
    "    return 0\n",
    "\n",
    "def LF_closer_dis(c):\n",
    "    # Get distance between chemical and disease\n",
    "    chem_start, chem_end = c.chemical.get_word_start(), c.chemical.get_word_end()\n",
    "    dis_start, dis_end = c.disease.get_word_start(), c.disease.get_word_end()\n",
    "    if dis_start < chem_start:\n",
    "        dist = chem_start - dis_end\n",
    "    else:\n",
    "        dist = dis_start - chem_end\n",
    "    # Try to find chemical disease than @dist/8 in either direction\n",
    "    sent = c.get_parent()\n",
    "    for i in range(chem_end, min(len(sent.words), chem_end + dist // 8)):\n",
    "        et, cid = sent.entity_types[i], sent.entity_cids[i]\n",
    "        if et == 'Disease' and cid != sent.entity_cids[dis_start]:\n",
    "            return -1\n",
    "    for i in range(max(0, chem_start - dist // 8), chem_start):\n",
    "        et, cid = sent.entity_types[i], sent.entity_cids[i]\n",
    "        if et == 'Disease' and cid != sent.entity_cids[dis_start]:\n",
    "            return -1\n",
    "    return 0\n",
    "\n",
    "\n",
    "LFs = [\n",
    "    LF_cd_in_CTD,\n",
    "    LF_c_cause_d,\n",
    "    LF_c_d,\n",
    "    LF_c_induced_d,\n",
    "    LF_c_treat_d,\n",
    "    LF_c_treat_d_wide,\n",
    "    LF_d_following_c,\n",
    "    LF_d_induced_by_c,\n",
    "    LF_d_induced_by_c_tight,\n",
    "    LF_d_treat_c,\n",
    "    LF_develop_d_following_c,\n",
    "    LF_far_c_d,\n",
    "    LF_far_d_c,\n",
    "    LF_improve_before_disease,\n",
    "    LF_in_patient_with,\n",
    "    LF_induce,\n",
    "    LF_induce_name,\n",
    "    LF_induced_other,\n",
    "    LF_level,\n",
    "    LF_measure,\n",
    "    LF_neg_d,\n",
    "    LF_risk_d,\n",
    "    LF_treat_d,\n",
    "    LF_uncertain,\n",
    "    LF_weak_assertions,\n",
    "    LF_closer_chem,\n",
    "    LF_closer_dis\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 14/5861 [00:00<00:43, 133.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5861/5861 [00:26<00:00, 222.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.5 s, sys: 172 ms, total: 26.7 s\n",
      "Wall time: 26.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<5861x25 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 9889 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.annotations import LabelAnnotator\n",
    "labeler = LabelAnnotator(lfs=LFs)\n",
    "\n",
    "%time L_train = labeler.apply(split=0)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also view statistics about the resulting label matrix.\n",
    "\n",
    "* **Coverage** is the fraction of candidates that the labeling function emits a non-zero label for.\n",
    "* **Overlap** is the fraction candidates that the labeling function emits a non-zero label for and that another labeling function emits a non-zero label for.\n",
    "* **Conflict** is the fraction candidates that the labeling function emits a non-zero label for and that another labeling function emits a *conflicting* non-zero label for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_cd_in_CTD</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.505886</td>\n",
       "      <td>0.234772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_c_cause_d</th>\n",
       "      <td>1</td>\n",
       "      <td>0.015015</td>\n",
       "      <td>0.015015</td>\n",
       "      <td>0.008531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_c_d</th>\n",
       "      <td>2</td>\n",
       "      <td>0.008360</td>\n",
       "      <td>0.008360</td>\n",
       "      <td>0.004948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_c_induced_d</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_c_treat_d</th>\n",
       "      <td>4</td>\n",
       "      <td>0.056816</td>\n",
       "      <td>0.056816</td>\n",
       "      <td>0.029517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_c_treat_d_wide</th>\n",
       "      <td>5</td>\n",
       "      <td>0.101519</td>\n",
       "      <td>0.101519</td>\n",
       "      <td>0.050162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_d_following_c</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_d_induced_by_c</th>\n",
       "      <td>7</td>\n",
       "      <td>0.009384</td>\n",
       "      <td>0.009384</td>\n",
       "      <td>0.005460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_d_induced_by_c_tight</th>\n",
       "      <td>8</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.001536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_d_treat_c</th>\n",
       "      <td>9</td>\n",
       "      <td>0.024228</td>\n",
       "      <td>0.024228</td>\n",
       "      <td>0.011602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_develop_d_following_c</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_far_c_d</th>\n",
       "      <td>11</td>\n",
       "      <td>0.159700</td>\n",
       "      <td>0.159700</td>\n",
       "      <td>0.065006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_far_d_c</th>\n",
       "      <td>12</td>\n",
       "      <td>0.096571</td>\n",
       "      <td>0.096571</td>\n",
       "      <td>0.043337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_improve_before_disease</th>\n",
       "      <td>13</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.000682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_in_patient_with</th>\n",
       "      <td>14</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.000512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_induce</th>\n",
       "      <td>15</td>\n",
       "      <td>0.016209</td>\n",
       "      <td>0.016209</td>\n",
       "      <td>0.006142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_induce_name</th>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_induced_other</th>\n",
       "      <td>17</td>\n",
       "      <td>0.008360</td>\n",
       "      <td>0.008360</td>\n",
       "      <td>0.003071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_level</th>\n",
       "      <td>18</td>\n",
       "      <td>0.026958</td>\n",
       "      <td>0.026958</td>\n",
       "      <td>0.016209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_measure</th>\n",
       "      <td>19</td>\n",
       "      <td>0.017062</td>\n",
       "      <td>0.017062</td>\n",
       "      <td>0.006484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_neg_d</th>\n",
       "      <td>20</td>\n",
       "      <td>0.014503</td>\n",
       "      <td>0.014503</td>\n",
       "      <td>0.006484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_risk_d</th>\n",
       "      <td>21</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.002047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_treat_d</th>\n",
       "      <td>22</td>\n",
       "      <td>0.024228</td>\n",
       "      <td>0.024228</td>\n",
       "      <td>0.013308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_uncertain</th>\n",
       "      <td>23</td>\n",
       "      <td>0.012455</td>\n",
       "      <td>0.012455</td>\n",
       "      <td>0.007166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_weak_assertions</th>\n",
       "      <td>24</td>\n",
       "      <td>0.088893</td>\n",
       "      <td>0.088893</td>\n",
       "      <td>0.047432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            j  Coverage  Overlaps  Conflicts\n",
       "LF_cd_in_CTD                0  1.000000  0.505886   0.234772\n",
       "LF_c_cause_d                1  0.015015  0.015015   0.008531\n",
       "LF_c_d                      2  0.008360  0.008360   0.004948\n",
       "LF_c_induced_d              3  0.000000  0.000000   0.000000\n",
       "LF_c_treat_d                4  0.056816  0.056816   0.029517\n",
       "LF_c_treat_d_wide           5  0.101519  0.101519   0.050162\n",
       "LF_d_following_c            6  0.000171  0.000171   0.000000\n",
       "LF_d_induced_by_c           7  0.009384  0.009384   0.005460\n",
       "LF_d_induced_by_c_tight     8  0.003071  0.003071   0.001536\n",
       "LF_d_treat_c                9  0.024228  0.024228   0.011602\n",
       "LF_develop_d_following_c   10  0.000000  0.000000   0.000000\n",
       "LF_far_c_d                 11  0.159700  0.159700   0.065006\n",
       "LF_far_d_c                 12  0.096571  0.096571   0.043337\n",
       "LF_improve_before_disease  13  0.001024  0.001024   0.000682\n",
       "LF_in_patient_with         14  0.000682  0.000682   0.000512\n",
       "LF_induce                  15  0.016209  0.016209   0.006142\n",
       "LF_induce_name             16  0.000000  0.000000   0.000000\n",
       "LF_induced_other           17  0.008360  0.008360   0.003071\n",
       "LF_level                   18  0.026958  0.026958   0.016209\n",
       "LF_measure                 19  0.017062  0.017062   0.006484\n",
       "LF_neg_d                   20  0.014503  0.014503   0.006484\n",
       "LF_risk_d                  21  0.002047  0.002047   0.002047\n",
       "LF_treat_d                 22  0.024228  0.024228   0.013308\n",
       "LF_uncertain               23  0.012455  0.012455   0.007166\n",
       "LF_weak_assertions         24  0.088893  0.088893   0.047432"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train.lf_stats(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15/6165 [00:00<00:43, 142.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6165/6165 [00:42<00:00, 143.87it/s]\n",
      "  0%|          | 13/6437 [00:00<00:53, 120.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6437/6437 [00:45<00:00, 142.14it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "L_dev = labeler.apply_existing(split=1)\n",
    "L_test = labeler.apply_existing(split=2)\n",
    "\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold',split=1)\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search on generative model to find the best parameter configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5 dependencies\n",
      "============================================================\n",
      "[1] Testing step_size = 1.00e-05, decay = 9.00e-01, epochs = 100, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 0.9668027693946387\n",
      "[GenerativeModel] Model saved as <GenerativeModel_0>.\n",
      "[GenerativeModel] Model saved as <GenerativeModel_best>.\n",
      "============================================================\n",
      "[2] Testing step_size = 1.00e-04, decay = 9.00e-01, epochs = 100, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 1.0\n",
      "[GenerativeModel] Model saved as <GenerativeModel_1>.\n",
      "[GenerativeModel] Model saved as <GenerativeModel_best>.\n",
      "============================================================\n",
      "[3] Testing step_size = 1.00e-05, decay = 9.50e-01, epochs = 50, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 1.0\n",
      "============================================================\n",
      "[4] Testing step_size = 1.00e-05, decay = 9.50e-01, epochs = 100, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 1.0\n",
      "============================================================\n",
      "[5] Testing step_size = 1.00e-03, decay = 9.00e-01, epochs = 50, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 1.0\n",
      "[GenerativeModel] Model <GenerativeModel_1> loaded.\n",
      "CPU times: user 3min 13s, sys: 284 ms, total: 3min 14s\n",
      "Wall time: 3min 14s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "from snorkel.learning import RandomSearch\n",
    "from snorkel.learning.structure import DependencySelector\n",
    "\n",
    "MAX_DEPS = 5\n",
    "\n",
    "ds = DependencySelector()\n",
    "deps = ds.select(L_train, threshold=0.1)\n",
    "deps = set(list(deps)[0:min(len(deps), MAX_DEPS)])\n",
    "\n",
    "print(\"Using {} dependencies\".format(len(deps)))\n",
    "\n",
    "\n",
    "\n",
    "# use random search to optimize the generative model\n",
    "param_grid = {\n",
    "    'step_size' : [1e-3, 1e-4, 1e-5, 1e-6],\n",
    "    'decay'     : [0.9, 0.95],\n",
    "    'epochs'    : [50,100], # ,150],\n",
    "    'reg_param' : [1e-3],\n",
    "}\n",
    "\n",
    "model_class_params = {'lf_propensity' : False }#, 'deps': deps}\n",
    "\n",
    "searcher = RandomSearch(GenerativeModel, param_grid, L_train, n=5, model_class_params=model_class_params)\n",
    "%time gen_model, run_stats = searcher.fit(L_dev, L_gold_dev) #, deps=deps)\n",
    "run_stats\n",
    "\n",
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_marginals, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 1.0\n",
      "Neg. class accuracy: 1.0\n",
      "Precision            1.0\n",
      "Recall               1.0\n",
      "F1                   1.0\n",
      "----------------------------------------\n",
      "TP: 2910 | FP: 0 | TN: 3255 | FN: 0\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn = gen_model.error_analysis(session, L_dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 1.0\n",
      "Neg. class accuracy: 1.0\n",
      "Precision            1.0\n",
      "Recall               1.0\n",
      "F1                   1.0\n",
      "----------------------------------------\n",
      "TP: 2875 | FP: 0 | TN: 3562 | FN: 0\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn = gen_model.error_analysis(session, L_test, L_gold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 1.0\n",
      "Neg. class accuracy: 1.0\n",
      "Precision            1.0\n",
      "Recall               1.0\n",
      "F1                   1.0\n",
      "----------------------------------------\n",
      "TP: 2910 | FP: 0 | TN: 3255 | FN: 0\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dev_marginals = gen_model.marginals(L_dev)\n",
    "_, _, _, _ = gen_model.error_analysis(session, L_dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of all candidates: 18463\n"
     ]
    }
   ],
   "source": [
    "train_cands = session.query(ChemicalDisease).filter(ChemicalDisease.split == 0).order_by(ChemicalDisease.id).all()\n",
    "dev_cands   = session.query(ChemicalDisease).filter(ChemicalDisease.split == 1).order_by(ChemicalDisease.id).all()\n",
    "test_cands  = session.query(ChemicalDisease).filter(ChemicalDisease.split == 2).order_by(ChemicalDisease.id).all()\n",
    "\n",
    "all_cands = []\n",
    "all_cands.extend(train_cands)\n",
    "all_cands.extend(dev_cands)\n",
    "all_cands.extend(test_cands)\n",
    "\n",
    "print(\"Amount of all candidates: {}\".format(len(all_cands)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM] Training model\n",
      "[LSTM] n_train=5861  #epochs=100  batch size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kroll/.conda/envs/snorkel/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM] Epoch 1 (20.56s)\tAverage loss=0.682373\tDev F1=40.46\n",
      "[LSTM] Epoch 2 (50.85s)\tAverage loss=0.600755\tDev F1=57.07\n",
      "[LSTM] Epoch 3 (80.37s)\tAverage loss=0.470878\tDev F1=58.37\n",
      "[LSTM] Epoch 4 (109.53s)\tAverage loss=0.382380\tDev F1=57.11\n",
      "[LSTM] Epoch 5 (138.89s)\tAverage loss=0.326456\tDev F1=57.98\n",
      "[LSTM] Epoch 6 (166.93s)\tAverage loss=0.263276\tDev F1=60.41\n",
      "[LSTM] Epoch 7 (196.69s)\tAverage loss=0.218974\tDev F1=62.64\n",
      "[LSTM] Epoch 8 (224.62s)\tAverage loss=0.192227\tDev F1=61.55\n",
      "[LSTM] Epoch 9 (252.19s)\tAverage loss=0.173997\tDev F1=64.10\n",
      "[LSTM] Epoch 10 (279.39s)\tAverage loss=0.168245\tDev F1=65.62\n",
      "[LSTM] Epoch 11 (306.92s)\tAverage loss=0.143658\tDev F1=60.68\n",
      "[LSTM] Epoch 12 (334.29s)\tAverage loss=0.126132\tDev F1=62.33\n",
      "[LSTM] Epoch 13 (361.68s)\tAverage loss=0.114463\tDev F1=63.55\n",
      "[LSTM] Epoch 14 (389.15s)\tAverage loss=0.098069\tDev F1=63.71\n",
      "[LSTM] Epoch 15 (416.31s)\tAverage loss=0.116841\tDev F1=55.48\n",
      "[LSTM] Epoch 16 (444.18s)\tAverage loss=0.100873\tDev F1=64.05\n",
      "[LSTM] Epoch 17 (471.99s)\tAverage loss=0.094533\tDev F1=65.73\n",
      "[LSTM] Epoch 18 (501.14s)\tAverage loss=0.102473\tDev F1=63.12\n",
      "[LSTM] Epoch 19 (528.58s)\tAverage loss=0.099988\tDev F1=65.42\n",
      "[LSTM] Epoch 20 (555.74s)\tAverage loss=0.088746\tDev F1=67.13\n",
      "[LSTM] Epoch 21 (583.58s)\tAverage loss=0.077831\tDev F1=65.21\n",
      "[LSTM] Epoch 22 (610.86s)\tAverage loss=0.074755\tDev F1=66.44\n",
      "[LSTM] Epoch 23 (637.95s)\tAverage loss=0.067589\tDev F1=65.15\n",
      "[LSTM] Epoch 24 (665.69s)\tAverage loss=0.064334\tDev F1=60.97\n",
      "[LSTM] Epoch 25 (692.95s)\tAverage loss=0.099173\tDev F1=63.00\n",
      "[LSTM] Epoch 26 (720.14s)\tAverage loss=0.093697\tDev F1=67.00\n",
      "[LSTM] Epoch 27 (747.53s)\tAverage loss=0.066549\tDev F1=65.42\n",
      "[LSTM] Epoch 28 (775.47s)\tAverage loss=0.059297\tDev F1=66.99\n",
      "[LSTM] Epoch 29 (804.52s)\tAverage loss=0.064865\tDev F1=67.26\n",
      "[LSTM] Epoch 30 (832.12s)\tAverage loss=0.057523\tDev F1=67.88\n",
      "[LSTM] Epoch 31 (859.77s)\tAverage loss=0.056697\tDev F1=66.96\n",
      "[LSTM] Epoch 32 (887.26s)\tAverage loss=0.055554\tDev F1=68.13\n",
      "[LSTM] Epoch 33 (914.46s)\tAverage loss=0.055926\tDev F1=64.85\n",
      "[LSTM] Epoch 34 (941.25s)\tAverage loss=0.090916\tDev F1=67.33\n",
      "[LSTM] Epoch 35 (968.52s)\tAverage loss=0.064061\tDev F1=64.22\n",
      "[LSTM] Epoch 36 (996.03s)\tAverage loss=0.065622\tDev F1=62.83\n",
      "[LSTM] Epoch 37 (1023.16s)\tAverage loss=0.069378\tDev F1=66.46\n",
      "[LSTM] Epoch 38 (1050.78s)\tAverage loss=0.059045\tDev F1=68.59\n",
      "[LSTM] Epoch 39 (1078.52s)\tAverage loss=0.058342\tDev F1=68.86\n",
      "[LSTM] Epoch 40 (1107.55s)\tAverage loss=0.056548\tDev F1=68.81\n",
      "[LSTM] Epoch 41 (1134.38s)\tAverage loss=0.063251\tDev F1=67.73\n",
      "[LSTM] Epoch 42 (1161.94s)\tAverage loss=0.061977\tDev F1=67.68\n",
      "[LSTM] Epoch 43 (1189.37s)\tAverage loss=0.071714\tDev F1=65.85\n",
      "[LSTM] Epoch 44 (1216.45s)\tAverage loss=0.063436\tDev F1=70.00\n",
      "[LSTM] Epoch 45 (1244.34s)\tAverage loss=0.060276\tDev F1=67.27\n",
      "[LSTM] Epoch 46 (1272.05s)\tAverage loss=0.056769\tDev F1=68.49\n",
      "[LSTM] Epoch 47 (1298.90s)\tAverage loss=0.054947\tDev F1=68.64\n",
      "[LSTM] Epoch 48 (1326.22s)\tAverage loss=0.054203\tDev F1=68.81\n",
      "[LSTM] Epoch 49 (1353.97s)\tAverage loss=0.053586\tDev F1=69.18\n",
      "[LSTM] Epoch 50 (1381.12s)\tAverage loss=0.071166\tDev F1=67.17\n",
      "[LSTM] Epoch 51 (1410.34s)\tAverage loss=0.076562\tDev F1=67.47\n",
      "[LSTM] Epoch 52 (1437.63s)\tAverage loss=0.066069\tDev F1=69.17\n",
      "[LSTM] Epoch 53 (1464.53s)\tAverage loss=0.058337\tDev F1=68.56\n",
      "[LSTM] Epoch 54 (1492.04s)\tAverage loss=0.056457\tDev F1=69.00\n",
      "[LSTM] Epoch 55 (1519.31s)\tAverage loss=0.063268\tDev F1=66.75\n",
      "[LSTM] Epoch 56 (1546.69s)\tAverage loss=0.058818\tDev F1=70.52\n",
      "[LSTM] Epoch 57 (1573.73s)\tAverage loss=0.055716\tDev F1=68.28\n",
      "[LSTM] Epoch 58 (1601.24s)\tAverage loss=0.056528\tDev F1=63.69\n",
      "[LSTM] Epoch 59 (1628.22s)\tAverage loss=0.064187\tDev F1=68.40\n",
      "[LSTM] Epoch 60 (1655.43s)\tAverage loss=0.058702\tDev F1=68.80\n",
      "[LSTM] Epoch 61 (1682.32s)\tAverage loss=0.053837\tDev F1=68.61\n",
      "[LSTM] Epoch 62 (1711.71s)\tAverage loss=0.052716\tDev F1=69.41\n",
      "[LSTM] Epoch 63 (1739.46s)\tAverage loss=0.052992\tDev F1=69.80\n",
      "[LSTM] Epoch 64 (1768.66s)\tAverage loss=0.052786\tDev F1=69.14\n",
      "[LSTM] Epoch 65 (1796.47s)\tAverage loss=0.056500\tDev F1=63.49\n",
      "[LSTM] Epoch 66 (1823.96s)\tAverage loss=0.055409\tDev F1=69.52\n",
      "[LSTM] Epoch 67 (1850.82s)\tAverage loss=0.054786\tDev F1=66.84\n",
      "[LSTM] Epoch 68 (1877.84s)\tAverage loss=0.053412\tDev F1=68.55\n",
      "[LSTM] Epoch 69 (1905.85s)\tAverage loss=0.055513\tDev F1=69.05\n",
      "[LSTM] Epoch 70 (1933.38s)\tAverage loss=0.054129\tDev F1=69.04\n",
      "[LSTM] Epoch 71 (1960.87s)\tAverage loss=0.053046\tDev F1=69.17\n",
      "[LSTM] Epoch 72 (1988.46s)\tAverage loss=0.052964\tDev F1=66.99\n",
      "[LSTM] Epoch 73 (2017.39s)\tAverage loss=0.054507\tDev F1=66.56\n",
      "[LSTM] Epoch 74 (2044.40s)\tAverage loss=0.053428\tDev F1=65.12\n",
      "[LSTM] Epoch 75 (2071.88s)\tAverage loss=0.053894\tDev F1=68.29\n",
      "[LSTM] Epoch 76 (2099.51s)\tAverage loss=0.060236\tDev F1=66.01\n",
      "[LSTM] Epoch 77 (2126.34s)\tAverage loss=0.071391\tDev F1=70.25\n",
      "[LSTM] Model saved as <LSTM>\n",
      "[LSTM] Epoch 78 (2153.49s)\tAverage loss=0.060650\tDev F1=70.79\n",
      "[LSTM] Model saved as <LSTM>\n",
      "[LSTM] Epoch 79 (2180.72s)\tAverage loss=0.058317\tDev F1=69.90\n",
      "[LSTM] Epoch 80 (2207.44s)\tAverage loss=0.053541\tDev F1=64.12\n",
      "[LSTM] Epoch 81 (2234.00s)\tAverage loss=0.055259\tDev F1=69.85\n",
      "[LSTM] Epoch 82 (2260.66s)\tAverage loss=0.053868\tDev F1=70.38\n",
      "[LSTM] Epoch 83 (2288.38s)\tAverage loss=0.053253\tDev F1=68.45\n",
      "[LSTM] Epoch 84 (2316.99s)\tAverage loss=0.070923\tDev F1=71.23\n",
      "[LSTM] Model saved as <LSTM>\n",
      "[LSTM] Epoch 85 (2344.66s)\tAverage loss=0.059227\tDev F1=70.01\n",
      "[LSTM] Epoch 86 (2371.63s)\tAverage loss=0.055308\tDev F1=69.16\n",
      "[LSTM] Epoch 87 (2399.48s)\tAverage loss=0.053920\tDev F1=69.61\n",
      "[LSTM] Epoch 88 (2426.29s)\tAverage loss=0.053256\tDev F1=68.87\n",
      "[LSTM] Epoch 89 (2453.80s)\tAverage loss=0.059254\tDev F1=68.71\n",
      "[LSTM] Epoch 90 (2481.10s)\tAverage loss=0.056361\tDev F1=68.83\n",
      "[LSTM] Epoch 91 (2508.66s)\tAverage loss=0.053177\tDev F1=69.97\n",
      "[LSTM] Epoch 92 (2536.02s)\tAverage loss=0.053127\tDev F1=69.83\n",
      "[LSTM] Epoch 93 (2563.20s)\tAverage loss=0.053735\tDev F1=61.20\n",
      "[LSTM] Epoch 94 (2590.40s)\tAverage loss=0.057352\tDev F1=69.65\n",
      "[LSTM] Epoch 95 (2618.90s)\tAverage loss=0.054877\tDev F1=69.66\n",
      "[LSTM] Epoch 96 (2645.83s)\tAverage loss=0.057058\tDev F1=70.97\n",
      "[LSTM] Epoch 97 (2672.41s)\tAverage loss=0.062190\tDev F1=68.57\n",
      "[LSTM] Epoch 98 (2699.71s)\tAverage loss=0.058025\tDev F1=70.20\n",
      "[LSTM] Epoch 99 (2726.52s)\tAverage loss=0.054653\tDev F1=70.11\n",
      "[LSTM] Epoch 100 (2754.08s)\tAverage loss=0.052947\tDev F1=70.36\n",
      "[LSTM] Training done (2762.41s)\n",
      "[LSTM] Loaded model <LSTM>\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning.pytorch import LSTM\n",
    "\n",
    "#train_kwargs = {\n",
    "#    'lr':              0.01,\n",
    "#    'embedding_dim':   75,\n",
    "#    'hidden_dim':      75,\n",
    "#    'n_epochs':        100,\n",
    "#    'dropout':         0.5,\n",
    "#    'rebalance':       0.25,\n",
    "#    'seed':            1701\n",
    "#}\n",
    "\n",
    "if not do_grid_search:\n",
    "    # Best Configuration after grid search\n",
    "    train_kwargs = {\n",
    "        'batchsize':       64,\n",
    "        'lr':              0.001,\n",
    "        'embedding_dim':   100,\n",
    "        'hidden_dim':      150,\n",
    "        'n_epochs':        100,\n",
    "        'dropout':         0.25,\n",
    "        'rebalance':       0.0,\n",
    "        'seed':            1701\n",
    "    }\n",
    "\n",
    "    lstm = LSTM(n_threads=10)\n",
    "    lstm.train(train_cands, train_marginals, X_dev=dev_cands, Y_dev=L_gold_dev,use_cudnn=True, **train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.learning import RandomSearch\n",
    "from snorkel.learning.pytorch import LSTM\n",
    "\n",
    "if do_grid_search:\n",
    "    seed = 12345\n",
    "    num_model_search = 25\n",
    "\n",
    "    # search over this parameter grid\n",
    "    param_grid = {}\n",
    "    param_grid['batch_size'] = [64, 128]\n",
    "    param_grid['lr']         = [1e-4, 1e-3, 1e-2]\n",
    "    #param_grid['l1_penalty'] = [1e-6, 1e-4, 1e-2]\n",
    "    #param_grid['l2_penalty'] = [1e-6, 1e-4, 1e-2]\n",
    "    param_grid['rebalance']  = [0.0,0.25, 0.5]\n",
    "    param_grid['embedding_dim'] = [75, 100, 125]\n",
    "    param_grid['hidden_dim'] = [50, 100, 150]\n",
    "    param_grid['dropout'] = [0, 0.25, 0.5]\n",
    "\n",
    "    model_class_params = {\n",
    "        'n_threads':1\n",
    "    }\n",
    "\n",
    "\n",
    "    model_hyperparams = {\n",
    "        'n_epochs': 100,\n",
    "        'print_freq': 25,\n",
    "        'dev_ckpt_delay': 0.5,\n",
    "        'X_dev': dev_cands,\n",
    "        'Y_dev': L_gold_dev,\n",
    "    }\n",
    "\n",
    "    #lstm = LSTM(n_threads=1)\n",
    "\n",
    "    searcher = RandomSearch(LSTM, param_grid, train_cands, train_marginals,\n",
    "                            n=num_model_search, seed=seed,\n",
    "                            model_class_params=model_class_params,\n",
    "                            model_hyperparams=model_hyperparams)\n",
    "\n",
    "    print(\"Discriminitive Model Parameter Space (seed={}):\".format(seed))\n",
    "    for i, params in enumerate(searcher.search_space()):\n",
    "        print(\"{} {}\".format(i, params))\n",
    "\n",
    "    disc_model, run_stats = searcher.fit(X_valid=dev_cands, Y_valid=L_gold_dev, n_threads=1)\n",
    "    lstm = disc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_grid_search:\n",
    "    run_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.708, Recall: 0.732, F1 Score: 0.720\n"
     ]
    }
   ],
   "source": [
    "p, r, f1 = lstm.score(test_cands, L_gold_test)\n",
    "print(\"Prec: {0:.3f}, Recall: {1:.3f}, F1 Score: {2:.3f}\".format(p, r, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.732\n",
      "Neg. class accuracy: 0.756\n",
      "Precision            0.708\n",
      "Recall               0.732\n",
      "F1                   0.72\n",
      "----------------------------------------\n",
      "TP: 2104 | FP: 869 | TN: 2693 | FN: 771\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn = lstm.error_analysis(session, test_cands, L_gold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 18463 marginals\n"
     ]
    }
   ],
   "source": [
    "lstm.save_marginals(session, all_cands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing candidate labels into result file: results/chemical_disease_association.tsv\n",
      "Amount of candidates: 18463\n",
      "Load mariginals from db...\n",
      "Marginals loaded!\n",
      "Building sentence to document map...\n",
      "Map built!\n",
      "Saved 8398 positive predicitions for binary relation!\n",
      "CPU times: user 1min 44s, sys: 2.93 s, total: 1min 47s\n",
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "from ksnorkel import KSUtils\n",
    "\n",
    "all_sents = []\n",
    "all_sents.extend(train_sent)\n",
    "all_sents.extend(dev_sent)\n",
    "all_sents.extend(test_sent)\n",
    "\n",
    "header_str = '{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}'.format('document_id', 'sentence_id', 'cand_id', 'chemical_cid', 'chemical_span', 'disease_cid', 'disease_span')\n",
    "%time KSUtils.save_binary_relation_as_tsv('results/chemical_disease_association.tsv', session, all_cands, all_sents, header_str, 'chemical_cid', 'disease_cid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM] Model saved as <chemical_disease.lstm>\n"
     ]
    }
   ],
   "source": [
    "lstm.save(\"chemical_disease.lstm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snorkel)",
   "language": "python",
   "name": "snorkel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
