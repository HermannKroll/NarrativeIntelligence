{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of docs: 9645\n",
      "Document splitted: 3215 train, 3215 dev and 3215 test\n",
      "Amount of sentences: 27763 train, 27526 dev and 27823 test\n"
     ]
    }
   ],
   "source": [
    "from ksnorkel import KSUtils\n",
    "\n",
    "train_sent, dev_sent, test_sent = KSUtils.split_sentences(session)\n",
    "print(\"Amount of sentences: {} train, {} dev and {} test\".format(len(train_sent), len(dev_sent), len(test_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 101/27763 [00:00<00:28, 978.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27763/27763 [00:21<00:00, 1286.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 4297\n",
      "Clearing existing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 128/27526 [00:00<00:21, 1272.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27526/27526 [00:13<00:00, 2067.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 4337\n",
      "Clearing existing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 63/27823 [00:00<00:44, 626.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27823/27823 [00:13<00:00, 2105.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 4595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Candidate, candidate_subclass\n",
    "from snorkel.candidates import PretaggedCandidateExtractor\n",
    "\n",
    "ChemicalGeneInteraction = candidate_subclass('ChemicalGeneInteraction', ['chemical', 'gene'])\n",
    "candidate_extractor = PretaggedCandidateExtractor(ChemicalGeneInteraction, ['Chemical', 'Gene'])\n",
    "\n",
    "for k, sents in enumerate([train_sent,dev_sent, test_sent]):  \n",
    "    candidate_extractor.apply(sents, split=k, clear=True)\n",
    "    print(\"Number of candidates:\", session.query(ChemicalGeneInteraction).filter(ChemicalGeneInteraction.split == k).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1044988 chemical-gene assocations read from ChG-CTD_chem_gene_ixns\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import re\n",
    "\n",
    "ctd_chem_gene_inter = set()\n",
    "i = 0\n",
    "with gzip.open('data/CTD_chem_gene_ixns.tsv.gz','r') as f:\n",
    "    for l in f:\n",
    "        line = str(l).replace('b\\'', '').replace('\\\\n\\'', '').replace('\\\\r','')\n",
    "        # skip comments\n",
    "        if line.startswith('#'):\n",
    "            continue\n",
    "        #print(line)\n",
    "        components = line.split('\\\\t')    \n",
    "        \n",
    "        # add MESH:\n",
    "        if not components[1].startswith('MESH:'):\n",
    "            components[1] = \"MESH:\" + components[1]\n",
    "            \n",
    "        chemical = components[1]\n",
    "        gene = components[4]\n",
    "        key = frozenset((chemical, gene))\n",
    "        ctd_chem_gene_inter.add(key)\n",
    "        i += 1\n",
    "\n",
    "    \n",
    "print('{} chemical-gene assocations read from ChG-CTD_chem_gene_ixns'.format(len(ctd_chem_gene_inter)))\n",
    "#240349\n",
    "def cand_in_chemical_gene_interactions(c):\n",
    "    key = frozenset((c.chemical_cid, c.gene_cid))\n",
    "    if key in ctd_chem_gene_inter:\n",
    "    #    print(key)\n",
    "        return 1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing gold labels...\n",
      "Adding gold labels to training candidates...\n",
      "Labeld 682 positive and 3615 negative samples in train\n",
      "Adding gold labels to develop candidates...\n",
      "Labeld 814 positive and 3523 negative samples in dev\n",
      "Adding gold labels to test candidates...\n",
      "Labeld 704 positive and 3891 negative samples in test\n",
      "Finished - commiting to database...\n",
      "Commit complete!\n",
      "Labeld 2200 positive and 11029 negative samples\n"
     ]
    }
   ],
   "source": [
    "from ksnorkel import KSUtils\n",
    "\n",
    "KSUtils.add_gold_labels_for_candidates(session, ChemicalGeneInteraction, cand_in_chemical_gene_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from snorkel.lf_helpers import (\n",
    "    get_tagged_text,\n",
    "    rule_regex_search_tagged_text,\n",
    "    rule_regex_search_btw_AB,\n",
    "    rule_regex_search_btw_BA,\n",
    "    rule_regex_search_before_A,\n",
    "    rule_regex_search_before_B\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# List to parenthetical\n",
    "def ltp(x):\n",
    "    return '(' + '|'.join(x) + ')'\n",
    "\n",
    "\n",
    "\n",
    "inhibition_samples = [\"inhibitors\", \"inhibition\", \"auto-inhibition\"]\n",
    "\n",
    "\n",
    "def LF_CG_AB_before_inhibition(c):\n",
    "    return 1 if (re.search(r'{{A}}.{0,50} ' + '{{B}}.{0,50}' + 'inhibition' , get_tagged_text(c), re.I) or\n",
    "                re.search(r'{{B}}.{0,50} ' + '{{A}}.{0,50}' + 'inhibition' , get_tagged_text(c), re.I)) else 0\n",
    "                \n",
    "\n",
    "def LF_CG_AB_after_inhibition(c):\n",
    "    return 1 if (rule_regex_search_before_A(c,  ltp(inhibition_samples) + '.{0,100}', 1) and\n",
    "                  rule_regex_search_before_B(c, ltp(inhibition_samples) + '.{0,100}', 1)) else 0\n",
    "\n",
    "def LF_CG_A_inhibition_B_far(c):\n",
    "    return rule_regex_search_btw_AB(c, '.{0,400}' + ltp(inhibition_samples) + '.{0,400}', -1) \n",
    "\n",
    "def LF_CG_B_inhibition_A_far(c):\n",
    "    return rule_regex_search_btw_BA(c, '.{0,400}' + ltp(inhibition_samples) + '.{0,400}', -1)\n",
    "\n",
    "def LF_CG_A_inhibition_B(c):\n",
    "    return rule_regex_search_btw_AB(c, '.{0,50}' + ltp(inhibition_samples) + '.{0,50}', 1) \n",
    "\n",
    "def LF_CG_B_inhibition_A(c):\n",
    "    return rule_regex_search_btw_BA(c, '.{0,50}' + ltp(inhibition_samples) + '.{0,50}', 1)\n",
    "\n",
    "def LG_CG_inhibition_before_B_near(c):\n",
    "    return rule_regex_search_before_B(c, ltp(inhibition_samples) + '.{0,50}', 1)\n",
    " \n",
    "def LG_CG_inhibition_before_B_far(c):\n",
    "    return rule_regex_search_before_B(c, ltp(inhibition_samples) + '.{0,2000}', -1)\n",
    "\n",
    "\n",
    "inhibits_samples = [\"inhibit\"]\n",
    "\n",
    "def LF_CG_A_inhibitis_B(c):\n",
    "    return rule_regex_search_btw_AB(c, '.{0,50}' + ltp(inhibits_samples) + '.{0,50}', 1) \n",
    "\n",
    "inhibited_samples = [\"inhibited\"]\n",
    "\n",
    "\n",
    "\n",
    "def LF_CG_B_inhibited_A(c):\n",
    "    return rule_regex_search_btw_BA(c, '.{0,50}' + ltp(inhibited_samples) + '.{0,50}', 1) \n",
    "\n",
    "\n",
    "\n",
    "def LF_CG_not_inhibited(c):\n",
    "    sent = c.get_parent()\n",
    "    if 'not inhib' not in get_tagged_text(c):\n",
    "        return -1\n",
    "    return 0\n",
    "                \n",
    "\n",
    "    \n",
    "LFs_DG = [\n",
    "    LF_CG_AB_before_inhibition,\n",
    "    LF_CG_AB_after_inhibition,\n",
    "    LF_CG_A_inhibition_B_far,\n",
    "    LF_CG_B_inhibition_A_far,\n",
    "    LF_CG_A_inhibition_B,\n",
    "    LF_CG_B_inhibition_A,\n",
    "    LG_CG_inhibition_before_B_near,\n",
    "    LG_CG_inhibition_before_B_far,\n",
    "    LF_CG_A_inhibitis_B,\n",
    "    LF_CG_B_inhibited_A#,  \n",
    " #   LF_CG_not_inhibited\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from snorkel.lf_helpers import (\n",
    "    get_tagged_text,\n",
    "    rule_regex_search_tagged_text,\n",
    "    rule_regex_search_btw_AB,\n",
    "    rule_regex_search_btw_BA,\n",
    "    rule_regex_search_before_A,\n",
    "    rule_regex_search_before_B,\n",
    ")\n",
    "# List to parenthetical\n",
    "def ltp(x):\n",
    "    return '(' + '|'.join(x) + ')'\n",
    "\n",
    "\n",
    "\n",
    "inhibition_samples = [\"metabolism\", \"metabolite\", \"auto-inhibition\"]\n",
    "\n",
    "def LF_GC_A_metabolism_B(c):\n",
    "    return rule_regex_search_btw_AB(c, '.{0,50}' + ltp(inhibition_samples) + '.{0,50}', 1) \n",
    "\n",
    "def LF_GC_B_metabolism_A(c):\n",
    "    return rule_regex_search_btw_BA(c, '.{0,50}' + ltp(inhibition_samples) + '.{0,50}', 1)\n",
    "\n",
    "def LG_GC_metabolism_before_B_near(c):\n",
    "    return rule_regex_search_before_B(c, ltp(inhibition_samples) + '.{0,50}', 1)\n",
    " \n",
    "def LG_GC_metabolism_before_B_far(c):\n",
    "    return rule_regex_search_before_B(c, ltp(inhibition_samples) + '.{0,2000}', 1)\n",
    "\n",
    "\n",
    "inhibits_samples = [\"metabolises\", \"metabolizes\"]\n",
    "\n",
    "def LF_GC_A_metabolis_B(c):\n",
    "    return rule_regex_search_btw_AB(c, '.{0,50}' + ltp(inhibits_samples) + '.{0,50}', 1) \n",
    "\n",
    "inhibited_samples = [\"metabolised\", \"metabolized\"]\n",
    "\n",
    "def LF_GC_A_metabolized_B(c):\n",
    "    return rule_regex_search_btw_AB(c, '.{0,50}' + ltp(inhibited_samples) + '.{0,50}', 1) \n",
    "\n",
    "def LF_GC_B_metabolized_A(c):\n",
    "    return rule_regex_search_btw_BA(c, '.{0,50}' + ltp(inhibited_samples) + '.{0,50}', 1) \n",
    "\n",
    "\n",
    "\n",
    "def LF_CG_not_metabol(c):\n",
    "    sent = c.get_parent()\n",
    "    if 'not metabol' in get_tagged_text(c):\n",
    "        return -1\n",
    "    return 0\n",
    "                \n",
    "    \n",
    "def LF_CG_in_CTD_chem_gene(c):\n",
    "    if cand_in_chemical_gene_interactions(c) == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "\n",
    "LFs_GC = [\n",
    "    LF_GC_A_metabolism_B,\n",
    "    LF_GC_B_metabolism_A,\n",
    "    LG_GC_metabolism_before_B_near,\n",
    "    LG_GC_metabolism_before_B_far,\n",
    "    LF_GC_A_metabolis_B,\n",
    "    LF_GC_B_metabolized_A,\n",
    "#    LF_CG_not_metabol,\n",
    "    LF_CG_in_CTD_chem_gene\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFs_DG.extend(LFs_GC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16/4297 [00:00<00:26, 158.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4297/4297 [00:17<00:00, 248.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.3 s, sys: 132 ms, total: 17.4 s\n",
      "Wall time: 17.4 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_CG_AB_before_inhibition</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002560</td>\n",
       "      <td>0.002560</td>\n",
       "      <td>0.001862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_CG_AB_after_inhibition</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_CG_A_inhibition_B_far</th>\n",
       "      <td>2</td>\n",
       "      <td>0.005818</td>\n",
       "      <td>0.005818</td>\n",
       "      <td>0.002793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_CG_B_inhibition_A_far</th>\n",
       "      <td>3</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>0.001629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_CG_A_inhibition_B</th>\n",
       "      <td>4</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>0.001862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_CG_B_inhibition_A</th>\n",
       "      <td>5</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.001164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LG_CG_inhibition_before_B_near</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LG_CG_inhibition_before_B_far</th>\n",
       "      <td>7</td>\n",
       "      <td>0.001629</td>\n",
       "      <td>0.001629</td>\n",
       "      <td>0.001629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_CG_A_inhibitis_B</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_CG_B_inhibited_A</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_GC_A_metabolism_B</th>\n",
       "      <td>10</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>0.001862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_GC_B_metabolism_A</th>\n",
       "      <td>11</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.001164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LG_GC_metabolism_before_B_near</th>\n",
       "      <td>12</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LG_GC_metabolism_before_B_far</th>\n",
       "      <td>13</td>\n",
       "      <td>0.001629</td>\n",
       "      <td>0.001629</td>\n",
       "      <td>0.001629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_GC_A_metabolis_B</th>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_GC_B_metabolized_A</th>\n",
       "      <td>15</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_CG_in_CTD_chem_gene</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013963</td>\n",
       "      <td>0.008378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 j  Coverage  Overlaps  Conflicts\n",
       "LF_CG_AB_before_inhibition       0  0.002560  0.002560   0.001862\n",
       "LF_CG_AB_after_inhibition        1  0.000000  0.000000   0.000000\n",
       "LF_CG_A_inhibition_B_far         2  0.005818  0.005818   0.002793\n",
       "LF_CG_B_inhibition_A_far         3  0.003491  0.003491   0.001629\n",
       "LF_CG_A_inhibition_B             4  0.001862  0.001862   0.001862\n",
       "LF_CG_B_inhibition_A             5  0.001164  0.001164   0.001164\n",
       "LG_CG_inhibition_before_B_near   6  0.000465  0.000465   0.000465\n",
       "LG_CG_inhibition_before_B_far    7  0.001629  0.001629   0.001629\n",
       "LF_CG_A_inhibitis_B              8  0.000000  0.000000   0.000000\n",
       "LF_CG_B_inhibited_A              9  0.000465  0.000465   0.000465\n",
       "LF_GC_A_metabolism_B            10  0.001862  0.001862   0.001862\n",
       "LF_GC_B_metabolism_A            11  0.001164  0.001164   0.001164\n",
       "LG_GC_metabolism_before_B_near  12  0.000465  0.000465   0.000465\n",
       "LG_GC_metabolism_before_B_far   13  0.001629  0.001629   0.001629\n",
       "LF_GC_A_metabolis_B             14  0.000000  0.000000   0.000000\n",
       "LF_GC_B_metabolized_A           15  0.000465  0.000465   0.000465\n",
       "LF_CG_in_CTD_chem_gene          16  1.000000  0.013963   0.008378"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.annotations import LabelAnnotator\n",
    "labeler = LabelAnnotator(lfs=LFs_DG)\n",
    "%time L_train = labeler.apply(lfs=LFs_DG, parallelism=1)\n",
    "L_train\n",
    "\n",
    "L_train.lf_stats(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/4337 [00:00<01:03, 68.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4337/4337 [00:24<00:00, 177.12it/s]\n",
      "  0%|          | 8/4595 [00:00<01:00, 76.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4595/4595 [00:28<00:00, 160.87it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "L_dev = labeler.apply_existing(split=1)\n",
    "L_test = labeler.apply_existing(split=2)\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold',split=1)\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5 dependencies\n",
      "============================================================\n",
      "[1] Testing step_size = 1.00e-05, decay = 9.50e-01, epochs = 150, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 1.0\n",
      "[GenerativeModel] Model saved as <GenerativeModel_0>.\n",
      "[GenerativeModel] Model saved as <GenerativeModel_best>.\n",
      "============================================================\n",
      "[2] Testing step_size = 1.00e-04, decay = 9.50e-01, epochs = 50, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 1.0\n",
      "============================================================\n",
      "[3] Testing step_size = 1.00e-05, decay = 9.00e-01, epochs = 100, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 0.9975490196078431\n",
      "============================================================\n",
      "[4] Testing step_size = 1.00e-05, decay = 9.50e-01, epochs = 150, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 1.0\n",
      "============================================================\n",
      "[5] Testing step_size = 1.00e-03, decay = 9.00e-01, epochs = 100, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 1.0\n",
      "============================================================\n",
      "[6] Testing step_size = 1.00e-05, decay = 9.50e-01, epochs = 50, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 1.0\n",
      "============================================================\n",
      "[7] Testing step_size = 1.00e-05, decay = 9.00e-01, epochs = 50, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 0.9975490196078431\n",
      "============================================================\n",
      "[8] Testing step_size = 1.00e-04, decay = 9.50e-01, epochs = 50, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 1.0\n",
      "============================================================\n",
      "[9] Testing step_size = 1.00e-06, decay = 9.50e-01, epochs = 50, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 0.9975490196078431\n",
      "============================================================\n",
      "[10] Testing step_size = 1.00e-05, decay = 9.00e-01, epochs = 100, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 0.9975490196078431\n",
      "[GenerativeModel] Model <GenerativeModel_0> loaded.\n",
      "CPU times: user 3min 15s, sys: 84 ms, total: 3min 15s\n",
      "Wall time: 3min 15s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "from snorkel.learning import RandomSearch\n",
    "from snorkel.learning.structure import DependencySelector\n",
    "\n",
    "\n",
    "MAX_DEPS = 5\n",
    "\n",
    "ds = DependencySelector()\n",
    "deps = ds.select(L_train, threshold=0.1)\n",
    "deps = set(list(deps)[0:min(len(deps), MAX_DEPS)])\n",
    "\n",
    "print(\"Using {} dependencies\".format(len(deps)))\n",
    "\n",
    "\n",
    "\n",
    "# use random search to optimize the generative model\n",
    "param_grid = {\n",
    "    'step_size' : [1e-3, 1e-4, 1e-5, 1e-6],\n",
    "    'decay'     : [0.9, 0.95],\n",
    "    'epochs'    : [50,100,150],\n",
    "    'reg_param' : [1e-3],\n",
    "}\n",
    "\n",
    "model_class_params = {'lf_propensity' : False }#, 'deps': deps}\n",
    "\n",
    "searcher = RandomSearch(GenerativeModel, param_grid, L_train, n=10, model_class_params=model_class_params)\n",
    "%time gen_model, run_stats = searcher.fit(L_dev, L_gold_dev) #, deps=deps)\n",
    "run_stats\n",
    "\n",
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_marginals, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 1.0\n",
      "Neg. class accuracy: 1.0\n",
      "Precision            1.0\n",
      "Recall               1.0\n",
      "F1                   1.0\n",
      "----------------------------------------\n",
      "TP: 814 | FP: 0 | TN: 3523 | FN: 0\n",
      "========================================\n",
      "\n",
      "Saved 4297 marginals\n",
      "CPU times: user 2.8 s, sys: 108 ms, total: 2.91 s\n",
      "Wall time: 2.91 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import save_marginals\n",
    "\n",
    "dev_marginals = gen_model.marginals(L_dev)\n",
    "_, _, _, _ = gen_model.error_analysis(session, L_dev, L_gold_dev)\n",
    "\n",
    "%time save_marginals(session, L_train, train_marginals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 1.0\n",
      "Neg. class accuracy: 1.0\n",
      "Precision            1.0\n",
      "Recall               1.0\n",
      "F1                   1.0\n",
      "----------------------------------------\n",
      "TP: 704 | FP: 0 | TN: 3891 | FN: 0\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn = gen_model.error_analysis(session, L_test, L_gold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load all ChemicalGeneInteraction candidates from db...\n",
      "4297 4337 4595\n",
      "Amount of all candidates: 13229\n"
     ]
    }
   ],
   "source": [
    "print(\"Load all ChemicalGeneInteraction candidates from db...\")\n",
    "train_cands = session.query(ChemicalGeneInteraction).filter(ChemicalGeneInteraction.split == 0).order_by(ChemicalGeneInteraction.id).all()\n",
    "dev_cands   = session.query(ChemicalGeneInteraction).filter(ChemicalGeneInteraction.split == 1).order_by(ChemicalGeneInteraction.id).all()\n",
    "test_cands  = session.query(ChemicalGeneInteraction).filter(ChemicalGeneInteraction.split == 2).order_by(ChemicalGeneInteraction.id).all()\n",
    "\n",
    "\n",
    "all_cands = []\n",
    "all_cands.extend(train_cands)\n",
    "all_cands.extend(dev_cands)\n",
    "all_cands.extend(test_cands)\n",
    "\n",
    "\n",
    "print(\"{} {} {}\".format(len(train_cands), len(dev_cands), len(test_cands)))\n",
    "print(\"Amount of all candidates: {}\".format(len(all_cands)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.learning.pytorch import LSTM\n",
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "#train_kwargs = {\n",
    "#    'lr':            0.01,\n",
    "#    'embedding_dim': 75,\n",
    "#    'hidden_dim':    75,\n",
    "#    'n_epochs':      100,\n",
    "#    'dropout':       0.25,\n",
    "#    'seed':          1701\n",
    "#}\n",
    "\n",
    "# Best configuration\n",
    "train_kwargs = {\n",
    "    'batch_size':    128,\n",
    "    'lr':            0.01,\n",
    "    'embedding_dim': 100,\n",
    "    'hidden_dim':    100,\n",
    "    'n_epochs':      100,\n",
    "    'dropout':       0.0,\n",
    "    'rebalance':     0.0,\n",
    "    'seed':          1701\n",
    "}\n",
    "\n",
    "lstm = LSTM(n_threads=10)\n",
    "lstm.train(train_cands, train_marginals, X_dev=dev_cands, Y_dev=L_gold_dev, **train_kwargs)\n",
    "\n",
    "p, r, f1 = lstm.score(test_cands, L_gold_test)\n",
    "print(\"Prec: {0:.3f}, Recall: {1:.3f}, F1 Score: {2:.3f}\".format(p, r, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminitive Model Parameter Space (seed=12345):\n",
      "0 (64, 0.01, 0.0, 125, 150, 0.0)\n",
      "1 (128, 0.001, 0.5, 125, 50, 0.5)\n",
      "2 (128, 0.01, 0.0, 75, 50, 0.25)\n",
      "3 (128, 0.01, 0.0, 75, 150, 0.5)\n",
      "4 (64, 0.001, 0.25, 125, 100, 0.0)\n",
      "5 (128, 0.0001, 0.5, 125, 50, 0.0)\n",
      "6 (64, 0.001, 0.0, 100, 150, 0.5)\n",
      "7 (64, 0.001, 0.5, 75, 100, 0.5)\n",
      "8 (128, 0.0001, 0.0, 75, 100, 0.0)\n",
      "9 (64, 0.0001, 0.0, 100, 50, 0.25)\n",
      "10 (128, 0.0001, 0.5, 75, 100, 0.25)\n",
      "11 (128, 0.0001, 0.25, 125, 150, 0.0)\n",
      "12 (64, 0.001, 0.5, 125, 100, 0.25)\n",
      "13 (128, 0.01, 0.5, 100, 150, 0.25)\n",
      "14 (128, 0.001, 0.5, 100, 100, 0.0)\n",
      "15 (64, 0.001, 0.25, 75, 100, 0.25)\n",
      "16 (128, 0.01, 0.5, 100, 50, 0.25)\n",
      "17 (128, 0.001, 0.5, 75, 100, 0.5)\n",
      "18 (128, 0.0001, 0.25, 125, 50, 0.5)\n",
      "19 (64, 0.001, 0.25, 100, 50, 0.0)\n",
      "20 (64, 0.01, 0.0, 125, 150, 0.0)\n",
      "21 (64, 0.0001, 0.5, 75, 150, 0.25)\n",
      "22 (128, 0.001, 0.0, 100, 50, 0.25)\n",
      "23 (128, 0.0001, 0.25, 100, 50, 0.0)\n",
      "24 (128, 0.01, 0.5, 100, 150, 0.25)\n",
      "============================================================\n",
      "[1] Testing batch_size = 128, lr = 1.00e-02, rebalance = 0.00e+00, embedding_dim = 75, hidden_dim = 100, dropout = 0.00e+00\n",
      "============================================================\n",
      "[LSTM] Training model\n",
      "[LSTM] n_train=4297  #epochs=100  batch size=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kroll/.conda/envs/snorkel/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM] Epoch 1 (10.35s)\tAverage loss=0.509957\tDev F1=0.25\n",
      "[LSTM] Epoch 26 (275.02s)\tAverage loss=0.266228\tDev F1=23.90\n",
      "[LSTM] Epoch 51 (537.05s)\tAverage loss=0.263297\tDev F1=23.77\n",
      "[LSTM] Epoch 76 (797.58s)\tAverage loss=0.254499\tDev F1=31.42\n",
      "[LSTM] Model saved as <LSTM>\n",
      "[LSTM] Epoch 100 (1047.17s)\tAverage loss=0.250658\tDev F1=31.38\n",
      "[LSTM] Training done (1052.27s)\n",
      "[LSTM] Loaded model <LSTM>\n",
      "[LSTM] F-1 Score: 0.3142458100558659\n",
      "[LSTM] Model saved as <LSTM_0>\n",
      "[LSTM] Model saved as <LSTM_best>\n",
      "============================================================\n",
      "[2] Testing batch_size = 64, lr = 1.00e-04, rebalance = 5.00e-01, embedding_dim = 75, hidden_dim = 150, dropout = 0.00e+00\n",
      "============================================================\n",
      "[LSTM] Training model\n",
      "[LSTM] n_train=1364  #epochs=100  batch size=64\n",
      "[LSTM] Epoch 1 (4.34s)\tAverage loss=0.648880\tDev F1=0.00\n",
      "[LSTM] Epoch 26 (118.36s)\tAverage loss=0.360500\tDev F1=26.53\n",
      "[LSTM] Epoch 51 (232.94s)\tAverage loss=0.301972\tDev F1=30.25\n",
      "[LSTM] Epoch 76 (345.97s)\tAverage loss=0.278742\tDev F1=31.14\n",
      "[LSTM] Model saved as <LSTM>\n",
      "[LSTM] Epoch 100 (453.43s)\tAverage loss=0.271746\tDev F1=30.95\n",
      "[LSTM] Training done (460.40s)\n",
      "[LSTM] Loaded model <LSTM>\n",
      "[LSTM] F-1 Score: 0.31144872490504616\n",
      "============================================================\n",
      "[3] Testing batch_size = 128, lr = 1.00e-03, rebalance = 5.00e-01, embedding_dim = 125, hidden_dim = 100, dropout = 2.50e-01\n",
      "============================================================\n",
      "[LSTM] Training model\n",
      "[LSTM] n_train=1364  #epochs=100  batch size=128\n",
      "[LSTM] Epoch 1 (3.29s)\tAverage loss=0.534959\tDev F1=0.00\n",
      "[LSTM] Epoch 26 (86.61s)\tAverage loss=0.279663\tDev F1=17.11\n",
      "[LSTM] Epoch 51 (168.69s)\tAverage loss=0.261254\tDev F1=24.48\n",
      "[LSTM] Epoch 76 (251.46s)\tAverage loss=0.258301\tDev F1=24.44\n",
      "[LSTM] Model saved as <LSTM>\n",
      "[LSTM] Epoch 100 (331.91s)\tAverage loss=0.261380\tDev F1=25.56\n",
      "[LSTM] Model saved as <LSTM>\n",
      "[LSTM] Training done (337.28s)\n",
      "[LSTM] Loaded model <LSTM>\n",
      "[LSTM] F-1 Score: 0.2555762081784387\n",
      "============================================================\n",
      "[4] Testing batch_size = 128, lr = 1.00e-03, rebalance = 5.00e-01, embedding_dim = 125, hidden_dim = 100, dropout = 5.00e-01\n",
      "============================================================\n",
      "[LSTM] Training model\n",
      "[LSTM] n_train=1364  #epochs=100  batch size=128\n",
      "[LSTM] Epoch 1 (3.25s)\tAverage loss=0.536723\tDev F1=0.00\n",
      "[LSTM] Epoch 26 (85.38s)\tAverage loss=0.276282\tDev F1=17.16\n",
      "[LSTM] Epoch 51 (167.22s)\tAverage loss=0.267290\tDev F1=22.53\n",
      "[LSTM] Epoch 76 (248.33s)\tAverage loss=0.260590\tDev F1=19.75\n",
      "[LSTM] Model saved as <LSTM>\n",
      "[LSTM] Epoch 100 (329.26s)\tAverage loss=0.258161\tDev F1=21.24\n",
      "[LSTM] Model saved as <LSTM>\n",
      "[LSTM] Training done (334.77s)\n",
      "[LSTM] Loaded model <LSTM>\n",
      "[LSTM] F-1 Score: 0.21236872812135354\n",
      "============================================================\n",
      "[5] Testing batch_size = 128, lr = 1.00e-04, rebalance = 5.00e-01, embedding_dim = 100, hidden_dim = 50, dropout = 5.00e-01\n",
      "============================================================\n",
      "[LSTM] Training model\n",
      "[LSTM] n_train=1364  #epochs=100  batch size=128\n",
      "[LSTM] Epoch 1 (3.03s)\tAverage loss=0.657748\tDev F1=2.64\n",
      "[LSTM] Epoch 26 (74.94s)\tAverage loss=0.484517\tDev F1=1.46\n",
      "[LSTM] Epoch 51 (146.52s)\tAverage loss=0.441935\tDev F1=1.46\n",
      "[LSTM] Epoch 76 (219.01s)\tAverage loss=0.340739\tDev F1=27.74\n",
      "[LSTM] Model saved as <LSTM>\n",
      "[LSTM] Epoch 100 (290.56s)\tAverage loss=0.313427\tDev F1=29.49\n",
      "[LSTM] Model saved as <LSTM>\n",
      "[LSTM] Training done (295.87s)\n",
      "[LSTM] Loaded model <LSTM>\n",
      "[LSTM] F-1 Score: 0.29493087557603687\n",
      "============================================================\n",
      "[6] Testing batch_size = 64, lr = 1.00e-04, rebalance = 2.50e-01, embedding_dim = 75, hidden_dim = 100, dropout = 2.50e-01\n",
      "============================================================\n",
      "[LSTM] Training model\n",
      "[LSTM] n_train=2728  #epochs=100  batch size=64\n",
      "[LSTM] Epoch 1 (8.02s)\tAverage loss=0.648378\tDev F1=3.73\n",
      "[LSTM] Epoch 26 (211.17s)\tAverage loss=0.363819\tDev F1=27.52\n",
      "[LSTM] Epoch 51 (416.13s)\tAverage loss=0.307322\tDev F1=30.44\n",
      "[LSTM] Epoch 76 (632.80s)\tAverage loss=0.279708\tDev F1=31.11\n",
      "[LSTM] Model saved as <LSTM>\n",
      "[LSTM] Epoch 100 (829.88s)\tAverage loss=0.270951\tDev F1=31.21\n",
      "[LSTM] Model saved as <LSTM>\n",
      "[LSTM] Training done (835.88s)\n",
      "[LSTM] Loaded model <LSTM>\n",
      "[LSTM] F-1 Score: 0.31208466650258426\n",
      "============================================================\n",
      "[7] Testing batch_size = 64, lr = 1.00e-02, rebalance = 2.50e-01, embedding_dim = 75, hidden_dim = 50, dropout = 0.00e+00\n",
      "============================================================\n",
      "[LSTM] Training model\n",
      "[LSTM] n_train=2728  #epochs=100  batch size=64\n",
      "[LSTM] Epoch 1 (11.36s)\tAverage loss=0.488445\tDev F1=2.40\n",
      "[LSTM] Epoch 26 (195.72s)\tAverage loss=0.261963\tDev F1=31.75\n",
      "[LSTM] Epoch 51 (377.34s)\tAverage loss=0.260319\tDev F1=30.96\n",
      "[LSTM] Epoch 76 (566.30s)\tAverage loss=0.263071\tDev F1=30.09\n",
      "[LSTM] Model saved as <LSTM>\n",
      "[LSTM] Epoch 100 (740.14s)\tAverage loss=0.266219\tDev F1=32.49\n",
      "[LSTM] Model saved as <LSTM>\n",
      "[LSTM] Training done (745.62s)\n",
      "[LSTM] Loaded model <LSTM>\n",
      "[LSTM] F-1 Score: 0.3249299719887956\n",
      "[LSTM] Model saved as <LSTM_6>\n",
      "[LSTM] Model saved as <LSTM_best>\n",
      "============================================================\n",
      "[8] Testing batch_size = 64, lr = 1.00e-03, rebalance = 5.00e-01, embedding_dim = 75, hidden_dim = 100, dropout = 5.00e-01\n",
      "============================================================\n",
      "[LSTM] Training model\n",
      "[LSTM] n_train=1364  #epochs=100  batch size=64\n",
      "[LSTM] Epoch 1 (3.82s)\tAverage loss=0.542867\tDev F1=1.70\n"
     ]
    }
   ],
   "source": [
    "#from snorkel.learning import RandomSearch\n",
    "#from snorkel.learning.pytorch import LSTM\n",
    "\n",
    "#seed = 12345\n",
    "#num_model_search = 25\n",
    "\n",
    "# search over this parameter grid\n",
    "#param_grid = {}\n",
    "#param_grid['batch_size'] = [64, 128]\n",
    "#param_grid['lr']         = [1e-4, 1e-3, 1e-2]\n",
    "#param_grid['rebalance']  = [0.0,0.25, 0.5]\n",
    "#param_grid['embedding_dim'] = [75, 100, 125]\n",
    "#param_grid['hidden_dim'] = [50, 100, 150]\n",
    "#param_grid['dropout'] = [0, 0.25, 0.5]\n",
    "\n",
    "#model_class_params = {\n",
    "#    'n_threads':1\n",
    "#}\n",
    "\n",
    "\n",
    "#model_hyperparams = {\n",
    "#    'n_epochs': 100,\n",
    "#    'print_freq': 25,\n",
    "#    'dev_ckpt_delay': 0.5,\n",
    "#    'X_dev': dev_cands,\n",
    "#    'Y_dev': L_gold_dev,\n",
    "#}\n",
    "\n",
    "\n",
    "#searcher = RandomSearch(LSTM, param_grid, train_cands, train_marginals,\n",
    "#                        n=num_model_search, seed=seed,\n",
    "#                        model_class_params=model_class_params,\n",
    "#                        model_hyperparams=model_hyperparams)\n",
    "\n",
    "#print(\"Discriminitive Model Parameter Space (seed={}):\".format(seed))\n",
    "#for i, params in enumerate(searcher.search_space()):\n",
    "#    print(\"{} {}\".format(i, params))\n",
    "\n",
    "#disc_model, run_stats = searcher.fit(X_valid=dev_cands, Y_valid=L_gold_dev, n_threads=1)\n",
    "#lstm = disc_model\n",
    "#run_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>rebalance</th>\n",
       "      <th>embedding_dim</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>dropout</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>Rec.</th>\n",
       "      <th>F-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.394366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.443493</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.370529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.00</td>\n",
       "      <td>125</td>\n",
       "      <td>100</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.266742</td>\n",
       "      <td>0.577396</td>\n",
       "      <td>0.364907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.25</td>\n",
       "      <td>75</td>\n",
       "      <td>150</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.300752</td>\n",
       "      <td>0.442260</td>\n",
       "      <td>0.358031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.25</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.283639</td>\n",
       "      <td>0.455774</td>\n",
       "      <td>0.349670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.238004</td>\n",
       "      <td>0.609337</td>\n",
       "      <td>0.342305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.235987</td>\n",
       "      <td>0.615479</td>\n",
       "      <td>0.341164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.25</td>\n",
       "      <td>75</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.298661</td>\n",
       "      <td>0.356265</td>\n",
       "      <td>0.324930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.260138</td>\n",
       "      <td>0.417690</td>\n",
       "      <td>0.320603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.00</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.364078</td>\n",
       "      <td>0.276413</td>\n",
       "      <td>0.314246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.25</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.195137</td>\n",
       "      <td>0.778870</td>\n",
       "      <td>0.312085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.50</td>\n",
       "      <td>75</td>\n",
       "      <td>150</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.199861</td>\n",
       "      <td>0.705160</td>\n",
       "      <td>0.311449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.25</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.239175</td>\n",
       "      <td>0.427518</td>\n",
       "      <td>0.306743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.50</td>\n",
       "      <td>75</td>\n",
       "      <td>50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.201664</td>\n",
       "      <td>0.625307</td>\n",
       "      <td>0.304973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.50</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.235988</td>\n",
       "      <td>0.393120</td>\n",
       "      <td>0.294931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.50</td>\n",
       "      <td>75</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.210903</td>\n",
       "      <td>0.470516</td>\n",
       "      <td>0.291255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.50</td>\n",
       "      <td>75</td>\n",
       "      <td>50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.191085</td>\n",
       "      <td>0.605651</td>\n",
       "      <td>0.290513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.25</td>\n",
       "      <td>75</td>\n",
       "      <td>150</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.248136</td>\n",
       "      <td>0.286241</td>\n",
       "      <td>0.265830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.50</td>\n",
       "      <td>125</td>\n",
       "      <td>100</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.205531</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.255576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.50</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.180517</td>\n",
       "      <td>0.402948</td>\n",
       "      <td>0.249335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.25</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.303435</td>\n",
       "      <td>0.195332</td>\n",
       "      <td>0.237668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.50</td>\n",
       "      <td>125</td>\n",
       "      <td>150</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.211921</td>\n",
       "      <td>0.235872</td>\n",
       "      <td>0.223256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.50</td>\n",
       "      <td>125</td>\n",
       "      <td>100</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.202222</td>\n",
       "      <td>0.223587</td>\n",
       "      <td>0.212369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.50</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.278729</td>\n",
       "      <td>0.140049</td>\n",
       "      <td>0.186427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.50</td>\n",
       "      <td>125</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.221176</td>\n",
       "      <td>0.115479</td>\n",
       "      <td>0.151735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    batch_size      lr  rebalance  embedding_dim  hidden_dim  dropout  \\\n",
       "15         128  0.0100       0.00            100         100     0.00   \n",
       "8           64  0.0010       0.00            100         150     0.25   \n",
       "21          64  0.0010       0.00            125         100     0.50   \n",
       "17         128  0.0100       0.25             75         150     0.25   \n",
       "11         128  0.0010       0.25            100          50     0.25   \n",
       "12         128  0.0001       0.00            100         100     0.25   \n",
       "24         128  0.0001       0.00            100         100     0.25   \n",
       "6           64  0.0100       0.25             75          50     0.00   \n",
       "18          64  0.0001       0.00            100         150     0.25   \n",
       "0          128  0.0100       0.00             75         100     0.00   \n",
       "5           64  0.0001       0.25             75         100     0.25   \n",
       "1           64  0.0001       0.50             75         150     0.00   \n",
       "19         128  0.0100       0.25             75         100     0.25   \n",
       "20          64  0.0010       0.50             75          50     0.50   \n",
       "4          128  0.0001       0.50            100          50     0.50   \n",
       "10         128  0.0010       0.50             75          50     0.00   \n",
       "22          64  0.0010       0.50             75          50     0.50   \n",
       "9           64  0.0100       0.25             75         150     0.25   \n",
       "2          128  0.0010       0.50            125         100     0.25   \n",
       "7           64  0.0010       0.50             75         100     0.50   \n",
       "14          64  0.0001       0.25            100         100     0.00   \n",
       "23          64  0.0010       0.50            125         150     0.25   \n",
       "3          128  0.0010       0.50            125         100     0.50   \n",
       "13          64  0.0100       0.50            100         100     0.50   \n",
       "16          64  0.0001       0.50            125         100     0.00   \n",
       "\n",
       "       Prec.      Rec.       F-1  \n",
       "15  0.411765  0.378378  0.394366  \n",
       "8   0.443493  0.318182  0.370529  \n",
       "21  0.266742  0.577396  0.364907  \n",
       "17  0.300752  0.442260  0.358031  \n",
       "11  0.283639  0.455774  0.349670  \n",
       "12  0.238004  0.609337  0.342305  \n",
       "24  0.235987  0.615479  0.341164  \n",
       "6   0.298661  0.356265  0.324930  \n",
       "18  0.260138  0.417690  0.320603  \n",
       "0   0.364078  0.276413  0.314246  \n",
       "5   0.195137  0.778870  0.312085  \n",
       "1   0.199861  0.705160  0.311449  \n",
       "19  0.239175  0.427518  0.306743  \n",
       "20  0.201664  0.625307  0.304973  \n",
       "4   0.235988  0.393120  0.294931  \n",
       "10  0.210903  0.470516  0.291255  \n",
       "22  0.191085  0.605651  0.290513  \n",
       "9   0.248136  0.286241  0.265830  \n",
       "2   0.205531  0.337838  0.255576  \n",
       "7   0.180517  0.402948  0.249335  \n",
       "14  0.303435  0.195332  0.237668  \n",
       "23  0.211921  0.235872  0.223256  \n",
       "3   0.202222  0.223587  0.212369  \n",
       "13  0.278729  0.140049  0.186427  \n",
       "16  0.221176  0.115479  0.151735  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.405\n",
      "Neg. class accuracy: 0.891\n",
      "Precision            0.403\n",
      "Recall               0.405\n",
      "F1                   0.404\n",
      "----------------------------------------\n",
      "TP: 285 | FP: 423 | TN: 3468 | FN: 419\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn = lstm.error_analysis(session, test_cands, L_gold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 13229 marginals\n"
     ]
    }
   ],
   "source": [
    "lstm.save_marginals(session, all_cands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing candidate labels into result file...\n",
      "Amount of candidates: 13229\n",
      "Storing candidate labels into result file: results/chemical_gene_interaction.tsv\n",
      "Amount of candidates: 13229\n",
      "Load mariginals from db...\n",
      "Marginals loaded!\n",
      "Building sentence to document map...\n",
      "Map built!\n",
      "Saved 2134 positive predicitions for binary relation!\n",
      "CPU times: user 1min 26s, sys: 2.63 s, total: 1min 29s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models.candidate import Marginal\n",
    "from snorkel.models import Document, Sentence\n",
    "\n",
    "\n",
    "print(\"Storing candidate labels into result file...\")\n",
    "amount_of_candidates = session.query(Candidate).count()\n",
    "print(\"Amount of candidates: {}\".format(amount_of_candidates))\n",
    "all_sents = []\n",
    "all_sents.extend(train_sent)\n",
    "all_sents.extend(dev_sent)\n",
    "all_sents.extend(test_sent)\n",
    "\n",
    "header_str = '{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}'.format('document_id', 'sentence_id', 'cand_id','chemical_cid', 'chemical_span', 'gene_cid', 'gene_span')\n",
    "%time KSUtils.save_binary_relation_as_tsv('results/chemical_gene_interaction.tsv', session, all_cands, all_sents, header_str, 'chemical_cid', 'gene_cid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM] Model saved as <chemical_gene_interaction.lstm>\n"
     ]
    }
   ],
   "source": [
    "lstm.save(\"chemical_gene_interaction.lstm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snorkel)",
   "language": "python",
   "name": "snorkel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
