{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_path = 'results/pmcsimcyp100/'\n",
    "result_path = 'results/pmc_sim_ami_128/'\n",
    "\n",
    "mine_stories = False\n",
    "min_support = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_mapping = {}\n",
    "\n",
    "first = True\n",
    "with open(result_path+ 'doc_mapping.tsv', 'r') as f:\n",
    "    for l in f:\n",
    "       #skip first line\n",
    "        if first:\n",
    "            first = False\n",
    "            continue\n",
    "        comp = l.replace('\\n','').split('\\t')\n",
    "        snorkel_doc_id = comp[0]\n",
    "        pubmed_id = comp[1]\n",
    "        \n",
    "        doc_mapping[snorkel_doc_id] = pubmed_id\n",
    "        \n",
    "print('Amount of document ids: {}'.format(len(doc_mapping)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_dict = {}\n",
    "\n",
    "with open('data/mesh2018.tsv', 'r') as f:\n",
    "    for l in f: \n",
    "        comp = l.replace('\\n','').split('\\t')\n",
    "        mesh_id = comp[0]\n",
    "        mesh_name = comp[1]\n",
    "        \n",
    "        mesh_dict[mesh_id] = mesh_name\n",
    "        \n",
    "print('Amount of mesh ids: {}'.format(len(mesh_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "gene_dict = {}\n",
    "\n",
    "first = True\n",
    "with gzip.open('data/CTD_genes.tsv.gz', 'r') as f:\n",
    "    for l in f: \n",
    "        line = str(l).replace('b\\'', '')\n",
    "        # skip comments\n",
    "        if line.startswith('#'):\n",
    "            continue\n",
    "        #print(line)\n",
    "        comp = line.replace('\\\\n','').split('\\\\t')\n",
    "        #print(comp)\n",
    "        gene_id = comp[2]\n",
    "        gene_name = comp[1]\n",
    "     \n",
    "        gene_dict[gene_id] = gene_name\n",
    "        \n",
    "print('Amount of gene ids: {}'.format(len(gene_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_mesh_id_with_name(mesh_id):\n",
    "    mesh_id_c = mesh_id\n",
    "    if mesh_id.startswith('MESH:'):\n",
    "        mesh_id_c = mesh_id.replace('MESH:','')\n",
    "    \n",
    "    if mesh_id_c not in mesh_dict:\n",
    "        print('Error: Mesh_ID {} not in mesh dict'.format(mesh_id_c))\n",
    "        return mesh_id\n",
    "    \n",
    "    name = mesh_dict[mesh_id_c]\n",
    "    return name\n",
    "\n",
    "def replace_gene_id_with_name(gene_id):\n",
    "    if gene_id not in gene_dict:\n",
    "        print('Error: Gene_ID {} not in gene dict'.format(gene_id))\n",
    "        return gene_id\n",
    "    \n",
    "    name = gene_dict[gene_id]\n",
    "    return name\n",
    "\n",
    "def replace_snorkel_doc_id_with_pubmed_id(doc_id):\n",
    "    return doc_mapping[doc_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactStore:\n",
    "    def __init__(self):\n",
    "        self.unique_fact_id_counter = 0\n",
    "        self.id_to_fact = {}\n",
    "        self.fact_to_id = {}\n",
    "        self.doc_to_facts = {}\n",
    "       \n",
    "        self.chem_id_to_span = {}\n",
    "        self.dis_id_to_span = {}\n",
    "        self.gen_id_to_span = {}\n",
    "        \n",
    "    def add_fact(self, doc_id, fact):\n",
    "        key = frozenset(fact)\n",
    "        if key in self.fact_to_id:\n",
    "            unique_fact_id = self.fact_to_id[key]\n",
    "        else:\n",
    "            unique_fact_id = self.unique_fact_id_counter\n",
    "            self.fact_to_id[key] = unique_fact_id\n",
    "            self.unique_fact_id_counter += 1\n",
    "\n",
    "\n",
    "        if doc_id not in self.doc_to_facts:\n",
    "            self.doc_to_facts[doc_id] = set()\n",
    "\n",
    "        self.doc_to_facts[doc_id].add(unique_fact_id)\n",
    "        self.id_to_fact[unique_fact_id] = fact\n",
    "        \n",
    "    def find_fact_id(fact):\n",
    "        key = frozenset(fact)\n",
    "        if key in self.fact_to_id:\n",
    "            return self.fact_to_id[key]\n",
    "        return None\n",
    "        \n",
    "    def print_info(self):\n",
    "        print(\"---------------------------------------\")\n",
    "        print(\"Amount of ids   : {}\".format(len(self.id_to_fact.keys())))\n",
    "        print(\"Amount of facts : {}\".format(len(self.fact_to_id.keys())))\n",
    "        print(\"Amount of docs  : {}\".format(len(self.doc_to_facts.keys())))\n",
    "        print(\"Known chemicals : {}\".format(len(self.chem_id_to_span.keys())))\n",
    "        print(\"Known diseases  : {}\".format(len(self.dis_id_to_span.keys())))\n",
    "        print(\"Known genes     : {}\".format(len(self.gen_id_to_span.keys())))\n",
    "        print(\"---------------------------------------\")\n",
    "        \n",
    "    def facts_to_str(self, facts):\n",
    "        str_res = \"\"\n",
    "        str_res += \"[\"\n",
    "        for f in facts:  \n",
    "            if 'c_asso_d' is f[1]:\n",
    "                c_name = replace_mesh_id_with_name(f[0])\n",
    "                d_name = replace_mesh_id_with_name(f[2])\n",
    "                str_res += '({}, associated, {})'.format(c_name, d_name) \n",
    "            if 'c_inter_g' is f[1]:\n",
    "                c_name = replace_mesh_id_with_name(f[0])\n",
    "                g_name = replace_gene_id_with_name(f[2])\n",
    "                str_res += '({}, interacts, {})'.format(c_name, g_name)\n",
    "            if 'g_inter_d' is f[1]:\n",
    "                g_name = replace_gene_id_with_name(f[0])\n",
    "                d_name = replace_mesh_id_with_name(f[2])\n",
    "                str_res += '({}, interacts, {})'.format(g_name, d_name)\n",
    "\n",
    "\n",
    "            if 'c_inhibits_g' is f[1]:\n",
    "                c_name = replace_mesh_id_with_name(f[0])\n",
    "                g_name = replace_gene_id_with_name(f[2])\n",
    "                str_res += '({}, inhibits, {})'.format(c_name, g_name)\n",
    "            if 'g_metabol_c' is f[1]:\n",
    "                g_name = replace_gene_id_with_name(f[0])\n",
    "                c_name = replace_mesh_id_with_name(f[2])\n",
    "                str_res += '({}, metabol, {})'.format(g_name, c_name)\n",
    "\n",
    "            str_res += ','\n",
    "\n",
    "        str_res = str_res[0:-1] +  \"]\"\n",
    "        return str_res\n",
    "\n",
    "        \n",
    "    def match_query_facts_in_doc_facts(self, query_facts, doc_facts):\n",
    "        # store all qf substitutions \n",
    "        qf_substitutions = {}\n",
    "\n",
    "        # all query facts must match\n",
    "        for qf in query_facts:\n",
    "            # just check whether there is a direct match\n",
    "            # here no substitution is necessary\n",
    "            if qf not in doc_facts:\n",
    "                return (False, {})\n",
    "            \n",
    "            # allow variables in query\n",
    "            if qf[0].startswith('?') or qf[2].startswith('?'):\n",
    "                # look for possible substitution\n",
    "                substitutions = []\n",
    "                for df in doc_facts:\n",
    "                    # predicates are equal?\n",
    "                    if qf[1] == df[1]:\n",
    "                        # is qf[0] not variable?\n",
    "                        if not qf[0].startswith('?'):\n",
    "                            # then both must be equal\n",
    "                            if qf[0] == df[0]:\n",
    "                                substitutions.append(df)\n",
    "                            else:\n",
    "                                # no match\n",
    "                                break\n",
    "                        # is qf[2] not variable?\n",
    "                        if not qf[2].startswith('?'):\n",
    "                            # then both must be equal\n",
    "                            if qf[2] == df[2]:\n",
    "                                substitutions.append(df)\n",
    "                            else:\n",
    "                                # no match\n",
    "                                break\n",
    "                # no substitution found?\n",
    "                if len(substitutions) == 0:\n",
    "                    return (False, {}) # query is not found in documents\n",
    "\n",
    "                # there is at least one substitution - this fact is matched!\n",
    "                qf_substitutions[qf] = substitutions\n",
    "                continue # continue matching process\n",
    "\n",
    "  \n",
    "        return (True, qf_substitutions)\n",
    "\n",
    "\n",
    "    def match_query_facts(self, query_facts):\n",
    "        number_of_matches = 0\n",
    "        matched_doc_ids = []\n",
    "        # go through all documents\n",
    "        for doc_id, doc_fact_ids in self.doc_to_facts.items():\n",
    "            # replace all fact_ids by their their original facts\n",
    "            doc_facts = []\n",
    "            for dfi in doc_fact_ids:\n",
    "                doc_facts.append(self.id_to_fact[dfi])\n",
    "\n",
    "            # now match query against this facts\n",
    "            (matched, subs) = self.match_query_facts_in_doc_facts(query_facts, doc_facts)\n",
    "            if matched:\n",
    "                # match found\n",
    "                print('Match in {} (PMID: {}) with substitutions:'.format(doc_id, replace_snorkel_doc_id_with_pubmed_id(doc_id)))\n",
    "                for k, v in subs.items():\n",
    "                    print('\\t{} is substituted by {}\\n'.format(k, self.facts_to_str(v)))\n",
    "                print('\\n')\n",
    "                number_of_matches += 1\n",
    "                matched_doc_ids.append(doc_id)\n",
    "        print('{} matches found!'.format(number_of_matches))\n",
    "        return matched_doc_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_store = FactStore()\n",
    "\n",
    "\n",
    "with open(result_path + 'chemical_disease_association.tsv', 'r') as f:\n",
    "    first = True\n",
    "    for line in f:\n",
    "        if first: # skip header\n",
    "            first = False\n",
    "            continue\n",
    "        \n",
    "        spl = line.replace('\\n', '').split('\\t')\n",
    "        doc_id = spl[0]\n",
    "        sen_id = spl[1]\n",
    "        chem_id = spl[3]\n",
    "        chem_span = spl[4]\n",
    "        dis_id = spl[5]\n",
    "        dis_span = spl[6]\n",
    "        \n",
    "        fact_store.chem_id_to_span[chem_id] = chem_span\n",
    "        fact_store.dis_id_to_span[dis_id] = dis_span\n",
    "        \n",
    "        #fact = (chem_span, 'cd', dis_span)      \n",
    "        fact = (chem_id, 'c_asso_d', dis_id)\n",
    "        fact_store.add_fact(doc_id, fact)\n",
    "\n",
    "fact_store.print_info()\n",
    "\n",
    "with open(result_path + 'chemical_gene_interaction.tsv', 'r') as f:\n",
    "    first = True\n",
    "    for line in f:\n",
    "        if first: # skip header\n",
    "            first = False\n",
    "            continue\n",
    "        \n",
    "        spl = line.replace('\\n', '').split('\\t')\n",
    "        doc_id = spl[0]\n",
    "        sen_id = spl[1]\n",
    "        chem_id = spl[3]\n",
    "        chem_span = spl[4]\n",
    "        gen_id = spl[5]\n",
    "        gen_span = spl[6]\n",
    "        \n",
    "        fact_store.chem_id_to_span[chem_id] = chem_span\n",
    "        fact_store.gen_id_to_span[gen_id] = gen_span\n",
    "                \n",
    "        #fact = (chem_span, 'inh', gen_span)\n",
    "        fact = (chem_id, 'c_inter_g', gen_id)\n",
    "        fact_store.add_fact(doc_id, fact)\n",
    "\n",
    "        \n",
    "fact_store.print_info()\n",
    "\n",
    "with open(result_path + 'gene_disease_interaction.tsv', 'r') as f:\n",
    "    first = True\n",
    "    for line in f:\n",
    "        if first: # skip header\n",
    "            first = False\n",
    "            continue\n",
    "        \n",
    "        spl = line.replace('\\n', '').split('\\t')\n",
    "        doc_id = spl[0]\n",
    "        sen_id = spl[1]\n",
    "        gen_id = spl[3]\n",
    "        gen_span = spl[4]\n",
    "        dis_id = spl[5]\n",
    "        dis_span = spl[6]\n",
    "        \n",
    "        fact_store.gen_id_to_span[gen_id] = gen_span\n",
    "        fact_store.dis_id_to_span[dis_id] = dis_span\n",
    "               \n",
    "        #fact = (chem_span, 'inh', gen_span)\n",
    "        fact = (gen_id, 'g_inter_d', dis_id)\n",
    "        fact_store.add_fact(doc_id, fact)\n",
    "\n",
    "fact_store.print_info()\n",
    "\n",
    "with open(result_path + 'chemical_gene_inhibition.tsv', 'r') as f:\n",
    "    first = True\n",
    "    for line in f:\n",
    "        if first: # skip header\n",
    "            first = False\n",
    "            continue\n",
    "        \n",
    "        spl = line.replace('\\n', '').split('\\t')\n",
    "        doc_id = spl[0]\n",
    "        sen_id = spl[1]\n",
    "        chem_id = spl[3]\n",
    "        chem_span = spl[4]\n",
    "        gen_id = spl[5]\n",
    "        gen_span = spl[6]\n",
    "        \n",
    "        fact_store.gen_id_to_span[gen_id] = gen_span\n",
    "        fact_store.chem_id_to_span[chem_id] = chem_span\n",
    "               \n",
    "        fact = (chem_id, 'c_inhibits_g', gen_id)\n",
    "        fact_store.add_fact(doc_id, fact)\n",
    "\n",
    "        \n",
    "fact_store.print_info()\n",
    "\n",
    "with open(result_path + 'gene_chemical_metabolism.tsv', 'r') as f:\n",
    "    first = True\n",
    "    for line in f:\n",
    "        if first: # skip header\n",
    "            first = False\n",
    "            continue\n",
    "        \n",
    "        spl = line.replace('\\n', '').split('\\t')\n",
    "        doc_id = spl[0]\n",
    "        sen_id = spl[1]\n",
    "        gen_id = spl[3]\n",
    "        gen_span = spl[4]\n",
    "        chem_id = spl[5]\n",
    "        chem_span = spl[6]\n",
    "        \n",
    "        fact_store.gen_id_to_span[gen_id] = gen_span\n",
    "        fact_store.chem_id_to_span[chem_id] = chem_span\n",
    "               \n",
    "        fact = (gen_id, 'g_metabol_c', chem_id)\n",
    "        fact_store.add_fact(doc_id, fact)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "fact_store.print_info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing frequent occurring facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mine_stories:\n",
    "    to_check = []\n",
    "    ids_with_min_support = set()\n",
    "    for f_id in fact_store.id_to_fact.keys():\n",
    "        support = 0\n",
    "        # go through all documents\n",
    "        for doc_facts in fact_store.doc_to_facts.values():\n",
    "            if f_id in doc_facts:\n",
    "                 support += 1\n",
    "\n",
    "        if support >= min_support:\n",
    "            t_set = set()\n",
    "            t_set.add(f_id)\n",
    "            to_check.append(t_set)\n",
    "            ids_with_min_support.add(f_id)\n",
    "    print(ids_with_min_support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing frequent item sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mine_stories:\n",
    "    results = []\n",
    "\n",
    "    explored_sets = set()\n",
    "    while to_check:\n",
    "        # get fact candidate ids\n",
    "        cand_ids_org = to_check.pop()\n",
    "        for f_id in ids_with_min_support:\n",
    "            if f_id in cand_ids_org:\n",
    "                continue\n",
    "            # check with this id included\n",
    "            cand_ids = cand_ids_org.copy()\n",
    "            cand_ids.add(f_id)\n",
    "\n",
    "            # already checked this combi\n",
    "            if frozenset(cand_ids) in explored_sets:\n",
    "                continue\n",
    "\n",
    "            #print(\"Starting with candidate ids: {}\".format(cand_ids_org))\n",
    "            # how much support does these ids have?\n",
    "            support = 0\n",
    "            # go through all documents\n",
    "            doc_ids_supporting = []\n",
    "            for doc_id, doc_facts in fact_store.doc_to_facts.items():\n",
    "                included = True\n",
    "                for f_id in cand_ids:\n",
    "                    if f_id not in doc_facts:\n",
    "                        # if a fact id is not included - stop here (no support)\n",
    "                        included = False\n",
    "                        break\n",
    "                if included:\n",
    "                    doc_ids_supporting.append(doc_id)\n",
    "                    support += 1\n",
    "\n",
    "            explored_sets.add(frozenset(cand_ids))\n",
    "\n",
    "            if support >= min_support:\n",
    "                results.append((cand_ids.copy(), support, doc_ids_supporting))\n",
    "                to_check.append(cand_ids)\n",
    "                print(\"Support {} for {} in doc_ids: {}\".format(support, cand_ids, doc_ids_supporting))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mine_stories:\n",
    "    stories = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for res, support, doc_ids in stories:\n",
    "        facts = []\n",
    "        for f_id in res:\n",
    "            facts.append(fact_store.id_to_fact[f_id])\n",
    "        print(\"Support {} for {}\\n\".format(support,fact_store.facts_to_str(facts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mine_stories:\n",
    "    len(stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mine_stories:\n",
    "    filename = result_path + 'stories_supp{}.tsv'.format(min_support)\n",
    "    with open(filename, 'w') as f:\n",
    "        #f.write('{}\\t{}\\n'.format('support', 'frequent item set'))\n",
    "        for res, support, doc_ids in stories:\n",
    "            facts = set()\n",
    "            for f_id in res:\n",
    "                facts.add(fact_store.id_to_fact[f_id])\n",
    "\n",
    "            # translate documument id\n",
    "            translated_doc_ids = []\n",
    "            for doc_id in doc_ids:\n",
    "                translated_doc_ids.append(replace_snorkel_doc_id_with_pubmed_id(doc_id))\n",
    "\n",
    "\n",
    "            f.write('{}\\t{}\\t{}\\n'.format(support,facts, translated_doc_ids))\n",
    "    print('Stories saved at {}'.format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mine_stories:\n",
    "    filename = result_path + 'stories_supp{}_translated.tsv'.format(min_support)\n",
    "    with open(filename, 'w') as f:\n",
    "        for story, supp, doc_ids in stories:\n",
    "            line = '{}'.format(supp)\n",
    "\n",
    "            # translate id to facts\n",
    "            facts = set()\n",
    "            for f_id in story:\n",
    "                facts.add(fact_store.id_to_fact[f_id])\n",
    "\n",
    "            for event in facts:\n",
    "                pred = event[1]\n",
    "\n",
    "                if pred == 'c_asso_d':\n",
    "                    ev1 = replace_mesh_id_with_name(event[0])\n",
    "                    ev2 = replace_mesh_id_with_name(event[2])\n",
    "                elif pred == 'c_inter_g':\n",
    "                    ev1 = replace_mesh_id_with_name(event[0])\n",
    "                    ev2 = replace_gene_id_with_name(event[2])\n",
    "                elif pred == 'g_inter_d':\n",
    "                    ev1 = replace_gene_id_with_name(event[0])\n",
    "                    ev2 = replace_mesh_id_with_name(event[2])\n",
    "                elif pred == 'c_inhibits_g':\n",
    "                    ev1 = replace_mesh_id_with_name(event[0])\n",
    "                    ev2 = replace_gene_id_with_name(event[2])\n",
    "                elif pred == 'g_metabol_c':\n",
    "                    ev1 = replace_gene_id_with_name(event[0])\n",
    "                    ev2 = replace_mesh_id_with_name(event[2])\n",
    "\n",
    "                line += '\\t({},{},{})'.format(ev1, pred, ev2)\n",
    "\n",
    "            # translate documument id\n",
    "            translated_doc_ids = []\n",
    "            for doc_id in doc_ids:\n",
    "                translated_doc_ids.append(replace_snorkel_doc_id_with_pubmed_id(doc_id))\n",
    "\n",
    "            line += '\\t{}'.format(translated_doc_ids)\n",
    "\n",
    "            line += '\\n'\n",
    "            f.write(line)\n",
    "    print('Translated stories saved at {}'.format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sim -- asso -- Rhabdo, CYP3A4 -- meta -- Simvastatn, ?X -- inhib -- 1576\n",
    "#query = [('MESH:D019821', 'c_asso_d', 'MESH:D012206'), ('1576', 'g_metabol_c', 'MESH:D019821'), ('?X', 'c_inhibits_g', '1576')]\n",
    "\n",
    "#query = [('1576', 'g_metabol_c', 'MESH:D019821'), ('?X', 'c_inhibits_g', '1576')]\n",
    "\n",
    "\n",
    "# CYP3A4 - meta - Simvastatin, Erythromycin - inhibits - CYP3A4\n",
    "#query = [('1576', 'g_metabol_c', 'MESH:D019821'), ('MESH:D004917', 'c_inhibits_g', '1576')]\n",
    "\n",
    "# CYP3A4 - meta - Simvastatin, Amiodarone - inhibits - CYP3A4\n",
    "query = [('1576', 'g_metabol_c', 'MESH:D019821'), ('MESH:D000638', 'c_inhibits_g', '1576')]\n",
    "\n",
    "\n",
    "%time query_doc_ids = fact_store.match_query_facts(query)\n",
    "\n",
    "print(query_doc_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d_id in query_doc_ids[0:1]:\n",
    "    facts = []\n",
    "    for f_id in fact_store.doc_to_facts[d_id]:\n",
    "        facts.append(fact_store.id_to_fact[f_id])\n",
    "    print(\"Story for PMID {}: {}\\n\\n\".format(replace_snorkel_doc_id_with_pubmed_id(d_id), fact_store.facts_to_str(facts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# pick a sample of random documents\n",
    "sample_size = 25\n",
    "\n",
    "# sample of document ids\n",
    "sample_doc_ids = random.choices(list(fact_store.doc_to_facts.keys()), k=sample_size)\n",
    "\n",
    "print(sample_doc_ids)\n",
    "\n",
    "\n",
    "filename = result_path + 'graph_queried_documents.tsv'\n",
    "with open(filename, 'w') as f:\n",
    "    f.write('Document ID\\tMatch?')\n",
    "    for doc_id in sample_doc_ids:\n",
    "        pmid = replace_snorkel_doc_id_with_pubmed_id(doc_id)\n",
    "        if doc_id in query_doc_ids:\n",
    "            # contains match\n",
    "            f.write('\\nPMC{}\\tMatch'.format(pmid))\n",
    "        else:\n",
    "            # contains no match\n",
    "            f.write('\\nPMC{}\\tNo Match'.format(pmid))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snorkel)",
   "language": "python",
   "name": "snorkel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
