{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print('remove snorkel db...')\n",
    "os.remove(\"snorkel.db\") \n",
    "print('snorkel db removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "\n",
      "DONE in 9.000768899917603\n"
     ]
    }
   ],
   "source": [
    "from snorkel import SnorkelSession\n",
    "from snorkel.parser import CorpusParser, Spacy, StanfordCoreNLPServer\n",
    "from pubtator import PubTatorDocPreprocessor, PubTatorTagProcessor, PubTatorParser\n",
    "from time import time\n",
    "\n",
    "parser = \"spacy\"\n",
    "num_procs = 1\n",
    "\n",
    "start_ts = time()\n",
    "\n",
    "filelist = ['data/SimCyp298_filtered.pubtator']\n",
    "\n",
    "for fp in filelist:\n",
    "    doc_preprocessor = PubTatorDocPreprocessor(fp, annotations=False)\n",
    "    #arser = Spacy() if parser == \"spacy\" else StanfordCoreNLPServer()\n",
    "    parser = PubTatorParser(stop_on_err=False)\n",
    "    corpus_parser = CorpusParser(parser=parser)\n",
    "    corpus_parser.apply(doc_preprocessor, parallelism=num_procs, clear=True)\n",
    "    end_ts = time()\n",
    "\n",
    "print(\"\\nDONE in {}\".format((time() - start_ts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: 298\n",
      "Sentences: 3452\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Document, Sentence\n",
    "\n",
    "print(\"Documents:\", session.query(Document).count())\n",
    "print(\"Sentences:\", session.query(Sentence).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation of the directory results/simcyp298/ failed because it may exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#subdir in results\n",
    "result_path = 'results/simcyp298/'\n",
    "\n",
    "try:  \n",
    "    os.mkdir(result_path)\n",
    "except OSError:  \n",
    "    print (\"Creation of the directory {} failed because it may exists\".format(result_path))\n",
    "else:  \n",
    "    print (\"Successfully created the directory %s \" % result_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of docs: 298\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Document\n",
    "\n",
    "all_docs = session.query(Document).all()\n",
    "\n",
    "print('Amount of docs: {}'.format(len(all_docs)))\n",
    "with open(result_path + 'doc_mapping.tsv', 'w') as f:\n",
    "    f.write('{}\\t{}\\n'.format('snorkel_id', 'pmid'))\n",
    "    for doc in all_docs:\n",
    "        f.write('{}\\t{}\\n'.format(doc.id, doc.name))\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: 298\n",
      "Sentences: 3452\n",
      "Loading all sentences from db...\n",
      "Loading complete!\n",
      "Amount of sentences: 3452\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Document, Sentence\n",
    "\n",
    "print(\"Documents:\", session.query(Document).count())\n",
    "print(\"Sentences:\", session.query(Sentence).count())\n",
    "\n",
    "print(\"Loading all sentences from db...\")\n",
    "all_sents = session.query(Sentence).all()\n",
    "print(\"Loading complete!\")\n",
    "\n",
    "\n",
    "print('Amount of sentences: {}'.format(len(all_sents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 60/3452 [00:00<00:05, 596.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3452/3452 [00:05<00:00, 641.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 1286\n",
      "[LSTM] Loaded model <chemical_disease.lstm>\n",
      "Loading all candidates from db...\n",
      "1286 candidates load from db!\n",
      "Applying LSTM to candidates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kroll/.conda/envs/snorkel/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1286 marginals\n",
      "CPU times: user 11.6 s, sys: 440 ms, total: 12 s\n",
      "Wall time: 3.04 s\n",
      "LSTM applied!\n",
      "Storing candidate labels into result file: results/simcyp298/chemical_disease_association.tsv\n",
      "Amount of candidates: 1286\n",
      "Load mariginals from db...\n",
      "Marginals loaded!\n",
      "Building sentence to document map...\n",
      "Map built!\n",
      "Saved 639 positive predicitions for binary relation!\n",
      "CPU times: user 6.27 s, sys: 104 ms, total: 6.37 s\n",
      "Wall time: 5.13 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Candidate, candidate_subclass\n",
    "from snorkel.candidates import PretaggedCandidateExtractor\n",
    "\n",
    "ChemicalDisease = candidate_subclass('ChemicalDisease', ['chemical', 'disease'])\n",
    "candidate_extractor = PretaggedCandidateExtractor(ChemicalDisease, ['Chemical', 'Disease'])\n",
    "\n",
    "for k, sents in enumerate([all_sents]):\n",
    "    candidate_extractor.apply(sents, split=k, clear=True)\n",
    "    print(\"Number of candidates:\", session.query(ChemicalDisease).filter(ChemicalDisease.split == k).count())\n",
    "    \n",
    "\n",
    "from snorkel.learning.pytorch import LSTM\n",
    "\n",
    "lstm = LSTM(n_threads=10)\n",
    "lstm.load('chemical_disease.lstm')\n",
    "\n",
    "print(\"Loading all candidates from db...\")\n",
    "all_cands = session.query(ChemicalDisease).filter(ChemicalDisease.split == 0).order_by(ChemicalDisease.id).all()\n",
    "print(\"{} candidates load from db!\".format(len(all_cands)))\n",
    "\n",
    "\n",
    "print(\"Applying LSTM to candidates...\")\n",
    "%time lstm.save_marginals(session, all_cands)\n",
    "print(\"LSTM applied!\")\n",
    "\n",
    "from ksnorkel import KSUtils\n",
    "\n",
    "header_str = '{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}'.format('document_id', 'sentence_id', 'cand_id', 'chemical_cid', 'chemical_span', 'disease_cid', 'disease_span')\n",
    "%time KSUtils.save_binary_relation_as_tsv(result_path + \"chemical_disease_association.tsv\", session, all_cands, all_sents, header_str, 'chemical_cid', 'disease_cid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 63/3452 [00:00<00:05, 615.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3452/3452 [00:05<00:00, 602.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 3148\n",
      "[LSTM] Loaded model <chemical_gene_interaction.lstm>\n",
      "Loading all candidates from db...\n",
      "3148 candidates load from db!\n",
      "Applying LSTM to candidates...\n",
      "Saved 3148 marginals\n",
      "CPU times: user 18.1 s, sys: 992 ms, total: 19.1 s\n",
      "Wall time: 7.11 s\n",
      "LSTM applied!\n",
      "Storing candidate labels into result file: results/simcyp298/chemical_gene_interaction.tsv\n",
      "Amount of candidates: 3148\n",
      "Load mariginals from db...\n",
      "Marginals loaded!\n",
      "Building sentence to document map...\n",
      "Map built!\n",
      "Saved 947 positive predicitions for binary relation!\n",
      "CPU times: user 3.97 s, sys: 88 ms, total: 4.06 s\n",
      "Wall time: 3.5 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Candidate, candidate_subclass\n",
    "from snorkel.candidates import PretaggedCandidateExtractor\n",
    "\n",
    "ChemicalGeneInteraction = candidate_subclass('ChemicalGeneInteraction', ['chemical', 'gene'])\n",
    "candidate_extractor = PretaggedCandidateExtractor(ChemicalGeneInteraction, ['Chemical', 'Gene'])\n",
    "\n",
    "for k, sents in enumerate([all_sents]):\n",
    "    candidate_extractor.apply(sents, split=k, clear=True)\n",
    "    print(\"Number of candidates:\", session.query(ChemicalGeneInteraction).filter(ChemicalGeneInteraction.split == k).count())\n",
    "    \n",
    "from snorkel.learning.pytorch import LSTM\n",
    "\n",
    "lstm = LSTM(n_threads=10)\n",
    "lstm.load('chemical_gene_interaction.lstm')\n",
    "\n",
    "\n",
    "print(\"Loading all candidates from db...\")\n",
    "all_cands = session.query(ChemicalGeneInteraction).filter(ChemicalGeneInteraction.split == 0).order_by(ChemicalGeneInteraction.id).all()\n",
    "print(\"{} candidates load from db!\".format(len(all_cands)))\n",
    "\n",
    "print(\"Applying LSTM to candidates...\")\n",
    "%time lstm.save_marginals(session, all_cands)\n",
    "print(\"LSTM applied!\")\n",
    "\n",
    "from ksnorkel import KSUtils\n",
    "\n",
    "header_str = '{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}'.format('document_id', 'sentence_id', 'cand_id','chemical_cid', 'chemical_span', 'gene_cid', 'gene_span')\n",
    "%time KSUtils.save_binary_relation_as_tsv(result_path + \"chemical_gene_interaction.tsv\", session, all_cands, all_sents, header_str, 'chemical_cid', 'gene_cid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3452 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3452/3452 [00:01<00:00, 2366.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 327\n",
      "[LSTM] Loaded model <gene_disease_interaction.lstm>\n",
      "Loading all candidates from db...\n",
      "327 candidates load from db!\n",
      "Applying LSTM to candidates...\n",
      "Saved 327 marginals\n",
      "CPU times: user 2.59 s, sys: 0 ns, total: 2.59 s\n",
      "Wall time: 968 ms\n",
      "LSTM applied!\n",
      "Storing candidate labels into result file: results/simcyp298/gene_disease_interaction.tsv\n",
      "Amount of candidates: 327\n",
      "Load mariginals from db...\n",
      "Marginals loaded!\n",
      "Building sentence to document map...\n",
      "Map built!\n",
      "Saved 296 positive predicitions for binary relation!\n",
      "CPU times: user 3.3 s, sys: 16 ms, total: 3.32 s\n",
      "Wall time: 719 ms\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Candidate, candidate_subclass\n",
    "from snorkel.candidates import PretaggedCandidateExtractor\n",
    "\n",
    "GeneDiseaseInteraction = candidate_subclass('GeneDiseaseInteraction', ['gene', 'disease'])\n",
    "candidate_extractor = PretaggedCandidateExtractor(GeneDiseaseInteraction, ['Gene', 'Disease'])\n",
    "\n",
    "for k, sents in enumerate([all_sents]):\n",
    "    candidate_extractor.apply(sents, split=k, clear=True)\n",
    "    print(\"Number of candidates:\", session.query(GeneDiseaseInteraction).filter(GeneDiseaseInteraction.split == k).count())\n",
    "    \n",
    "from snorkel.learning.pytorch import LSTM\n",
    "\n",
    "lstm = LSTM(n_threads=10)\n",
    "lstm.load('gene_disease_interaction.lstm')\n",
    "\n",
    "print(\"Loading all candidates from db...\")\n",
    "all_cands = session.query(GeneDiseaseInteraction).filter(GeneDiseaseInteraction.split == 0).order_by(GeneDiseaseInteraction.id).all()\n",
    "print(\"{} candidates load from db!\".format(len(all_cands)))\n",
    "\n",
    "print(\"Applying LSTM to candidates...\")\n",
    "%time lstm.save_marginals(session, all_cands)\n",
    "print(\"LSTM applied!\")\n",
    "\n",
    "from ksnorkel import KSUtils\n",
    "\n",
    "header_str = '{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}'.format('document_id', 'sentence_id', 'cand_id','gene_cid', 'gene_span', 'disease_cid', 'disease_span')\n",
    "%time KSUtils.save_binary_relation_as_tsv(result_path + \"gene_disease_interaction.tsv\", session, all_cands, all_sents, header_str, 'gene_cid', 'disease_cid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 68/3452 [00:00<00:04, 679.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3452/3452 [00:05<00:00, 640.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 3148\n",
      "[LSTM] Loaded model <gene_chemical_metabolism.lstm>\n",
      "Loading all candidates from db...\n",
      "3148 candidates load from db!\n",
      "Applying LSTM to candidates...\n",
      "Saved 3148 marginals\n",
      "CPU times: user 16.6 s, sys: 352 ms, total: 17 s\n",
      "Wall time: 7.06 s\n",
      "LSTM applied!\n",
      "Storing candidate labels into result file: results/simcyp298/gene_chemical_metabolism.tsv\n",
      "Amount of candidates: 3148\n",
      "Load mariginals from db...\n",
      "Marginals loaded!\n",
      "Building sentence to document map...\n",
      "Map built!\n",
      "Saved 186 positive predicitions for binary relation!\n",
      "CPU times: user 3.86 s, sys: 40 ms, total: 3.9 s\n",
      "Wall time: 2.5 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Candidate, candidate_subclass\n",
    "from snorkel.candidates import PretaggedCandidateExtractor\n",
    "\n",
    "from snorkel.models import Candidate, candidate_subclass\n",
    "from snorkel.candidates import PretaggedCandidateExtractor\n",
    "from snorkel.models import Candidate, candidate_subclass\n",
    "from snorkel.candidates import PretaggedCandidateExtractor\n",
    "\n",
    "\n",
    "GeneChemicalMetabolism = candidate_subclass('GeneChemicalMetabolism', ['gene', 'chemical'])\n",
    "candidate_gene_chemical_metabolism_extractor = PretaggedCandidateExtractor(GeneChemicalMetabolism, ['Gene', 'Chemical'])\n",
    "\n",
    "for k, sents in enumerate([all_sents]):\n",
    "    candidate_gene_chemical_metabolism_extractor.apply(sents, split=k, clear=True)\n",
    "    print(\"Number of candidates:\", session.query(GeneChemicalMetabolism).filter(GeneChemicalMetabolism.split == k).count())\n",
    "    \n",
    "    \n",
    "from snorkel.learning.pytorch import LSTM\n",
    "\n",
    "lstm = LSTM(n_threads=10)\n",
    "lstm.load('gene_chemical_metabolism.lstm')\n",
    "\n",
    "print(\"Loading all candidates from db...\")\n",
    "all_cands = session.query(GeneChemicalMetabolism).filter(GeneChemicalMetabolism.split == 0).order_by(GeneChemicalMetabolism.id).all()\n",
    "print(\"{} candidates load from db!\".format(len(all_cands)))\n",
    "\n",
    "print(\"Applying LSTM to candidates...\")\n",
    "%time lstm.save_marginals(session, all_cands)\n",
    "print(\"LSTM applied!\")\n",
    "\n",
    "from ksnorkel import KSUtils\n",
    "\n",
    "header_str = '{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}'.format('document_id', 'sentence_id', 'cand_id','gene_cid', 'gene_span', 'chemical_cid', 'chemical_span')\n",
    "%time KSUtils.save_binary_relation_as_tsv(result_path + \"gene_chemical_metabolism.tsv\", session, all_cands, all_sents, header_str, 'gene_cid', 'chemical_cid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3452 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3452/3452 [00:05<00:00, 643.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 3148\n",
      "[LSTM] Loaded model <chemical_gene_inhibition.lstm>\n",
      "Loading all candidates from db...\n",
      "3148 candidates load from db!\n",
      "Applying LSTM to candidates...\n",
      "Saved 3148 marginals\n",
      "CPU times: user 15.6 s, sys: 1.29 s, total: 16.9 s\n",
      "Wall time: 6.93 s\n",
      "LSTM applied!\n",
      "Storing candidate labels into result file: results/simcyp298/chemical_gene_inhibition.tsv\n",
      "Amount of candidates: 3148\n",
      "Load mariginals from db...\n",
      "Marginals loaded!\n",
      "Building sentence to document map...\n",
      "Map built!\n",
      "Saved 105 positive predicitions for binary relation!\n",
      "CPU times: user 3.14 s, sys: 32 ms, total: 3.18 s\n",
      "Wall time: 2.44 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Candidate, candidate_subclass\n",
    "from snorkel.candidates import PretaggedCandidateExtractor\n",
    "\n",
    "from snorkel.models import Candidate, candidate_subclass\n",
    "from snorkel.candidates import PretaggedCandidateExtractor\n",
    "from snorkel.models import Candidate, candidate_subclass\n",
    "from snorkel.candidates import PretaggedCandidateExtractor\n",
    "\n",
    "\n",
    "\n",
    "ChemicalGeneInhibition = candidate_subclass('ChemicalGeneInhibition', ['chemical', 'gene'])\n",
    "candidate_gene_chemical_inhibit_extractor = PretaggedCandidateExtractor(ChemicalGeneInhibition, ['Chemical', 'Gene'])\n",
    "\n",
    "\n",
    "for k, sents in enumerate([all_sents]):\n",
    "    candidate_gene_chemical_inhibit_extractor.apply(sents, split=k, clear=True)\n",
    "    print(\"Number of candidates:\", session.query(ChemicalGeneInhibition).filter(ChemicalGeneInhibition.split == k).count())\n",
    "    \n",
    "from snorkel.learning.pytorch import LSTM\n",
    "\n",
    "lstm = LSTM(n_threads=10)\n",
    "lstm.load('chemical_gene_inhibition.lstm')\n",
    "\n",
    "print(\"Loading all candidates from db...\")\n",
    "all_cands = session.query(ChemicalGeneInhibition).filter(ChemicalGeneInhibition.split == 0).order_by(ChemicalGeneInhibition.id).all()\n",
    "print(\"{} candidates load from db!\".format(len(all_cands)))\n",
    "\n",
    "print(\"Applying LSTM to candidates...\")\n",
    "%time lstm.save_marginals(session, all_cands)\n",
    "print(\"LSTM applied!\")\n",
    "\n",
    "from ksnorkel import KSUtils\n",
    "\n",
    "header_str = '{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}'.format('document_id', 'sentence_id', 'cand_id','chemical_cid', 'chemical_span', 'gene_cid', 'gene_span')\n",
    "%time KSUtils.save_binary_relation_as_tsv(result_path + \"chemical_gene_inhibition.tsv\", session, all_cands, all_sents, header_str, 'chemical_cid', 'gene_cid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snorkel)",
   "language": "python",
   "name": "snorkel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
