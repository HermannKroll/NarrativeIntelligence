{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subdir in results\n",
    "#result_path = 'results/simcyp298/'\n",
    "result_path = 'results/pmc_sim_ami_128/'\n",
    "\n",
    "\n",
    "# load puptator file\n",
    "#filelist = ['data/Tafamidis97_filtered.pubtator']\n",
    "#filelist = ['data/SimCyp298_filtered.pubtator']\n",
    "\n",
    "# pmc\n",
    "filelist = ['data/pmc_simvastatin_amiodarone_filtered_128.pubtator']\n",
    "#filelist = ['data/pmc_simvastatin_erythromycin_filtered_108.pubtator']\n",
    "#filelist = ['data/pmc_sim_cyp_100_filtered.pubtator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove snorkel db...\n",
      "snorkel db removed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print('remove snorkel db...')\n",
    "os.remove(\"snorkel.db\") \n",
    "print('snorkel db removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "DEBUG: processing doc_id: 5951216 ...\n",
      "DEBUG: processing doc_id: 3643340 ...\n",
      "DEBUG: processing doc_id: 4872953 ...\n",
      "DEBUG: processing doc_id: 5045550 ...\n",
      "DEBUG: processing doc_id: 6299330 ...\n",
      "DEBUG: processing doc_id: 5791210 ...\n",
      "DEBUG: processing doc_id: 4849387 ...\n",
      "DEBUG: processing doc_id: 2963161 ...\n",
      "DEBUG: processing doc_id: 5332115 ...\n",
      "DEBUG: processing doc_id: 6402887 ...\n",
      "DEBUG: processing doc_id: 3722377 ...\n",
      "DEBUG: processing doc_id: 6044386 ...\n",
      "DEBUG: processing doc_id: 3929149 ...\n",
      "DEBUG: processing doc_id: 6268819 ...\n",
      "DEBUG: processing doc_id: 2941787 ...\n",
      "DEBUG: processing doc_id: 5588350 ...\n",
      "DEBUG: processing doc_id: 4243320 ...\n",
      "DEBUG: processing doc_id: 4800352 ...\n",
      "DEBUG: processing doc_id: 6354302 ...\n",
      "DEBUG: processing doc_id: 4726750 ...\n",
      "DEBUG: processing doc_id: 4894065 ...\n",
      "DEBUG: processing doc_id: 5021965 ...\n",
      "DEBUG: processing doc_id: 6082457 ...\n",
      "DEBUG: processing doc_id: 6390564 ...\n",
      "DEBUG: processing doc_id: 2672446 ...\n",
      "DEBUG: processing doc_id: 3291838 ...\n",
      "DEBUG: processing doc_id: 5045601 ...\n",
      "DEBUG: processing doc_id: 2902014 ...\n",
      "DEBUG: processing doc_id: 5853001 ...\n",
      "DEBUG: processing doc_id: 5152992 ...\n",
      "DEBUG: processing doc_id: 5206369 ...\n",
      "WARNING: parsing exception list index out of range in document 5206369\n",
      "Missing annotations:\n",
      "['5206369', '68596', '68600', '5X10', 'Chemical', 'MESH:C052091']\n",
      "\n",
      "\n",
      "WARNING: Annotations missed (Count = 1)\n",
      "DEBUG: processing doc_id: 4077852 ...\n",
      "DEBUG: processing doc_id: 3467596 ...\n",
      "DEBUG: processing doc_id: 3743363 ...\n",
      "DEBUG: processing doc_id: 6440683 ...\n",
      "DEBUG: processing doc_id: 5395279 ...\n",
      "DEBUG: processing doc_id: 2725793 ...\n",
      "DEBUG: processing doc_id: 3868060 ...\n",
      "DEBUG: processing doc_id: 5083780 ...\n",
      "DEBUG: processing doc_id: 3920796 ...\n",
      "DEBUG: processing doc_id: 4806822 ...\n",
      "DEBUG: processing doc_id: 3721883 ...\n",
      "DEBUG: processing doc_id: 6263305 ...\n",
      "DEBUG: processing doc_id: 5529355 ...\n",
      "DEBUG: processing doc_id: 3201110 ...\n",
      "DEBUG: processing doc_id: 5019982 ...\n",
      "DEBUG: processing doc_id: 4000599 ...\n",
      "DEBUG: processing doc_id: 3751280 ...\n",
      "DEBUG: processing doc_id: 4079824 ...\n",
      "DEBUG: processing doc_id: 5477947 ...\n",
      "DEBUG: processing doc_id: 4102417 ...\n",
      "DEBUG: processing doc_id: 5102850 ...\n",
      "DEBUG: processing doc_id: 4379380 ...\n",
      "DEBUG: processing doc_id: 4353943 ...\n",
      "DEBUG: processing doc_id: 3678699 ...\n",
      "DEBUG: processing doc_id: 3753504 ...\n",
      "DEBUG: processing doc_id: 3994740 ...\n",
      "DEBUG: processing doc_id: 4186413 ...\n",
      "DEBUG: processing doc_id: 4889699 ...\n",
      "DEBUG: processing doc_id: 4913441 ...\n",
      "DEBUG: processing doc_id: 6231259 ...\n",
      "DEBUG: processing doc_id: 2672455 ...\n",
      "DEBUG: processing doc_id: 4859367 ...\n",
      "DEBUG: processing doc_id: 3974814 ...\n",
      "DEBUG: processing doc_id: 4289727 ...\n",
      "DEBUG: processing doc_id: 6017357 ...\n",
      "DEBUG: processing doc_id: 3218677 ...\n",
      "DEBUG: processing doc_id: 5651339 ...\n",
      "DEBUG: processing doc_id: 5004485 ...\n",
      "DEBUG: processing doc_id: 6169143 ...\n",
      "DEBUG: processing doc_id: 4421160 ...\n",
      "DEBUG: processing doc_id: 5080647 ...\n",
      "DEBUG: processing doc_id: 2586623 ...\n",
      "DEBUG: processing doc_id: 5085745 ...\n",
      "DEBUG: processing doc_id: 3641424 ...\n",
      "DEBUG: processing doc_id: 4761011 ...\n",
      "DEBUG: processing doc_id: 2780822 ...\n",
      "DEBUG: processing doc_id: 5977136 ...\n",
      "DEBUG: processing doc_id: 4172546 ...\n",
      "DEBUG: processing doc_id: 6166104 ...\n",
      "DEBUG: processing doc_id: 6187411 ...\n",
      "DEBUG: processing doc_id: 2394453 ...\n",
      "DEBUG: processing doc_id: 4004403 ...\n",
      "DEBUG: processing doc_id: 5122612 ...\n",
      "DEBUG: processing doc_id: 4468594 ...\n",
      "DEBUG: processing doc_id: 2808736 ...\n",
      "DEBUG: processing doc_id: 5874549 ...\n",
      "DEBUG: processing doc_id: 2615789 ...\n",
      "DEBUG: processing doc_id: 4460158 ...\n",
      "DEBUG: processing doc_id: 3141916 ...\n",
      "DEBUG: processing doc_id: 4522589 ...\n",
      "DEBUG: processing doc_id: 2147024 ...\n",
      "DEBUG: processing doc_id: 4391689 ...\n",
      "DEBUG: processing doc_id: 3747997 ...\n",
      "DEBUG: processing doc_id: 3153000 ...\n",
      "DEBUG: processing doc_id: 5385703 ...\n",
      "DEBUG: processing doc_id: 6322107 ...\n",
      "DEBUG: processing doc_id: 3140289 ...\n",
      "DEBUG: processing doc_id: 3763635 ...\n",
      "DEBUG: processing doc_id: 3436715 ...\n",
      "DEBUG: processing doc_id: 4753968 ...\n",
      "DEBUG: processing doc_id: 5340814 ...\n",
      "DEBUG: processing doc_id: 4943290 ...\n",
      "DEBUG: processing doc_id: 4107437 ...\n",
      "DEBUG: processing doc_id: 5555012 ...\n",
      "DEBUG: processing doc_id: 6043481 ...\n",
      "DEBUG: processing doc_id: 3090750 ...\n",
      "DEBUG: processing doc_id: 5520756 ...\n",
      "DEBUG: processing doc_id: 3798168 ...\n",
      "DEBUG: processing doc_id: 6249663 ...\n",
      "DEBUG: processing doc_id: 3267401 ...\n",
      "DEBUG: processing doc_id: 5225154 ...\n",
      "DEBUG: processing doc_id: 4466327 ...\n",
      "DEBUG: processing doc_id: 2374948 ...\n",
      "DEBUG: processing doc_id: 3552608 ...\n",
      "DEBUG: processing doc_id: 5019974 ...\n",
      "DEBUG: processing doc_id: 4422870 ...\n",
      "DEBUG: processing doc_id: 2922313 ...\n",
      "DEBUG: processing doc_id: 3897029 ...\n",
      "DEBUG: processing doc_id: 6289166 ...\n",
      "DEBUG: processing doc_id: 4061534 ...\n",
      "DEBUG: processing doc_id: 4664558 ...\n",
      "DEBUG: processing doc_id: 4783028 ...\n",
      "DEBUG: processing doc_id: 6405602 ...\n",
      "DEBUG: processing doc_id: 3531317 ...\n",
      "DEBUG: processing doc_id: 2740214 ...\n",
      "DEBUG: processing doc_id: 5110224 ...\n",
      "\n",
      "DONE in 85.7799756526947\n"
     ]
    }
   ],
   "source": [
    "from snorkel import SnorkelSession\n",
    "from snorkel.parser import CorpusParser, Spacy, StanfordCoreNLPServer\n",
    "from pubtator import PubTatorDocPreprocessor, PubTatorTagProcessor, PubTatorParser\n",
    "from time import time\n",
    "\n",
    "parser = \"spacy\"\n",
    "num_procs = 1\n",
    "\n",
    "start_ts = time()\n",
    "\n",
    "\n",
    "for fp in filelist:\n",
    "    doc_preprocessor = PubTatorDocPreprocessor(fp, annotations=False, debug=True)\n",
    "    #arser = Spacy() if parser == \"spacy\" else StanfordCoreNLPServer()\n",
    "    parser = PubTatorParser(stop_on_err=False)\n",
    "    corpus_parser = CorpusParser(parser=parser)\n",
    "    corpus_parser.apply(doc_preprocessor, parallelism=num_procs, clear=True)\n",
    "    end_ts = time()\n",
    "\n",
    "print(\"\\nDONE in {}\".format((time() - start_ts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: 127\n",
      "Sentences: 31662\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Document, Sentence\n",
    "\n",
    "print(\"Documents:\", session.query(Document).count())\n",
    "print(\"Sentences:\", session.query(Sentence).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the directory results/pmc_sim_ami_128/ \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "try:  \n",
    "    os.mkdir(result_path)\n",
    "except OSError:  \n",
    "    print (\"Creation of the directory {} failed because it may exists\".format(result_path))\n",
    "else:  \n",
    "    print (\"Successfully created the directory %s \" % result_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of docs: 127\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Document\n",
    "\n",
    "all_docs = session.query(Document).all()\n",
    "\n",
    "print('Amount of docs: {}'.format(len(all_docs)))\n",
    "with open(result_path + 'doc_mapping.tsv', 'w') as f:\n",
    "    f.write('{}\\t{}'.format('snorkel_id', 'pmid'))\n",
    "    for doc in all_docs:\n",
    "        f.write('\\n{}\\t{}'.format(doc.id, doc.name))\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: 127\n",
      "Sentences: 31662\n",
      "Loading all sentences from db...\n",
      "Loading complete!\n",
      "Amount of sentences: 31662\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Document, Sentence\n",
    "\n",
    "print(\"Documents:\", session.query(Document).count())\n",
    "print(\"Sentences:\", session.query(Sentence).count())\n",
    "\n",
    "print(\"Loading all sentences from db...\")\n",
    "all_sents = session.query(Sentence).all()\n",
    "print(\"Loading complete!\")\n",
    "\n",
    "\n",
    "print('Amount of sentences: {}'.format(len(all_sents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 52/31662 [00:00<01:01, 517.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31662/31662 [00:40<00:00, 779.82it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 15005\n",
      "[LSTM] Loaded model <chemical_disease.lstm>\n",
      "Loading all candidates from db...\n",
      "15005 candidates load from db!\n",
      "Applying LSTM to candidates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kroll/.conda/envs/snorkel/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 15005 marginals\n",
      "CPU times: user 1min 17s, sys: 7.8 s, total: 1min 25s\n",
      "Wall time: 38.9 s\n",
      "LSTM applied!\n",
      "Storing candidate labels into result file: results/pmc_sim_ami_128/chemical_disease_association.tsv\n",
      "Amount of candidates: 15005\n",
      "Load mariginals from db...\n",
      "Marginals loaded!\n",
      "Building sentence to document map...\n",
      "Map built!\n",
      "Saved 6199 positive predicitions for binary relation!\n",
      "CPU times: user 47.8 s, sys: 1.35 s, total: 49.2 s\n",
      "Wall time: 49.2 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Candidate, candidate_subclass\n",
    "from snorkel.candidates import PretaggedCandidateExtractor\n",
    "\n",
    "ChemicalDisease = candidate_subclass('ChemicalDisease', ['chemical', 'disease'])\n",
    "candidate_extractor = PretaggedCandidateExtractor(ChemicalDisease, ['Chemical', 'Disease'])\n",
    "\n",
    "for k, sents in enumerate([all_sents]):\n",
    "    candidate_extractor.apply(sents, split=k, clear=True)\n",
    "    print(\"Number of candidates:\", session.query(ChemicalDisease).filter(ChemicalDisease.split == k).count())\n",
    "    \n",
    "\n",
    "from snorkel.learning.pytorch import LSTM\n",
    "\n",
    "lstm = LSTM(n_threads=10)\n",
    "lstm.load('chemical_disease.lstm')\n",
    "\n",
    "print(\"Loading all candidates from db...\")\n",
    "all_cands = session.query(ChemicalDisease).filter(ChemicalDisease.split == 0).order_by(ChemicalDisease.id).all()\n",
    "print(\"{} candidates load from db!\".format(len(all_cands)))\n",
    "\n",
    "\n",
    "print(\"Applying LSTM to candidates...\")\n",
    "%time lstm.save_marginals(session, all_cands)\n",
    "print(\"LSTM applied!\")\n",
    "\n",
    "from ksnorkel import KSUtils\n",
    "\n",
    "header_str = '{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}'.format('document_id', 'sentence_id', 'cand_id', 'chemical_cid', 'chemical_span', 'disease_cid', 'disease_span')\n",
    "%time KSUtils.save_binary_relation_as_tsv(result_path + \"chemical_disease_association.tsv\", session, all_cands, all_sents, header_str, 'chemical_cid', 'disease_cid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/31662 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31662/31662 [00:24<00:00, 1318.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 9869\n",
      "[LSTM] Loaded model <chemical_gene_interaction.lstm>\n",
      "Loading all candidates from db...\n",
      "9869 candidates load from db!\n",
      "Applying LSTM to candidates...\n",
      "Saved 9869 marginals\n",
      "CPU times: user 52.4 s, sys: 2.72 s, total: 55.2 s\n",
      "Wall time: 25 s\n",
      "LSTM applied!\n",
      "Storing candidate labels into result file: results/pmc_sim_ami_128/chemical_gene_interaction.tsv\n",
      "Amount of candidates: 9869\n",
      "Load mariginals from db...\n",
      "Marginals loaded!\n",
      "Building sentence to document map...\n",
      "Map built!\n",
      "Saved 1847 positive predicitions for binary relation!\n",
      "CPU times: user 9.35 s, sys: 304 ms, total: 9.65 s\n",
      "Wall time: 9.65 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Candidate, candidate_subclass\n",
    "from snorkel.candidates import PretaggedCandidateExtractor\n",
    "\n",
    "ChemicalGeneInteraction = candidate_subclass('ChemicalGeneInteraction', ['chemical', 'gene'])\n",
    "candidate_extractor = PretaggedCandidateExtractor(ChemicalGeneInteraction, ['Chemical', 'Gene'])\n",
    "\n",
    "for k, sents in enumerate([all_sents]):\n",
    "    candidate_extractor.apply(sents, split=k, clear=True)\n",
    "    print(\"Number of candidates:\", session.query(ChemicalGeneInteraction).filter(ChemicalGeneInteraction.split == k).count())\n",
    "    \n",
    "from snorkel.learning.pytorch import LSTM\n",
    "\n",
    "lstm = LSTM(n_threads=10)\n",
    "lstm.load('chemical_gene_interaction.lstm')\n",
    "\n",
    "\n",
    "print(\"Loading all candidates from db...\")\n",
    "all_cands = session.query(ChemicalGeneInteraction).filter(ChemicalGeneInteraction.split == 0).order_by(ChemicalGeneInteraction.id).all()\n",
    "print(\"{} candidates load from db!\".format(len(all_cands)))\n",
    "\n",
    "print(\"Applying LSTM to candidates...\")\n",
    "%time lstm.save_marginals(session, all_cands)\n",
    "print(\"LSTM applied!\")\n",
    "\n",
    "from ksnorkel import KSUtils\n",
    "\n",
    "header_str = '{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}'.format('document_id', 'sentence_id', 'cand_id','chemical_cid', 'chemical_span', 'gene_cid', 'gene_span')\n",
    "%time KSUtils.save_binary_relation_as_tsv(result_path + \"chemical_gene_interaction.tsv\", session, all_cands, all_sents, header_str, 'chemical_cid', 'gene_cid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/31662 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31662/31662 [00:11<00:00, 2831.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 2318\n",
      "[LSTM] Loaded model <gene_disease_interaction.lstm>\n",
      "Loading all candidates from db...\n",
      "2318 candidates load from db!\n",
      "Applying LSTM to candidates...\n",
      "Saved 2318 marginals\n",
      "CPU times: user 18.9 s, sys: 1.28 s, total: 20.2 s\n",
      "Wall time: 6.86 s\n",
      "LSTM applied!\n",
      "Storing candidate labels into result file: results/pmc_sim_ami_128/gene_disease_interaction.tsv\n",
      "Amount of candidates: 2318\n",
      "Load mariginals from db...\n",
      "Marginals loaded!\n",
      "Building sentence to document map...\n",
      "Map built!\n",
      "Saved 2015 positive predicitions for binary relation!\n",
      "CPU times: user 5.93 s, sys: 172 ms, total: 6.1 s\n",
      "Wall time: 5.01 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Candidate, candidate_subclass\n",
    "from snorkel.candidates import PretaggedCandidateExtractor\n",
    "\n",
    "GeneDiseaseInteraction = candidate_subclass('GeneDiseaseInteraction', ['gene', 'disease'])\n",
    "candidate_extractor = PretaggedCandidateExtractor(GeneDiseaseInteraction, ['Gene', 'Disease'])\n",
    "\n",
    "for k, sents in enumerate([all_sents]):\n",
    "    candidate_extractor.apply(sents, split=k, clear=True)\n",
    "    print(\"Number of candidates:\", session.query(GeneDiseaseInteraction).filter(GeneDiseaseInteraction.split == k).count())\n",
    "    \n",
    "from snorkel.learning.pytorch import LSTM\n",
    "\n",
    "lstm = LSTM(n_threads=10)\n",
    "lstm.load('gene_disease_interaction.lstm')\n",
    "\n",
    "print(\"Loading all candidates from db...\")\n",
    "all_cands = session.query(GeneDiseaseInteraction).filter(GeneDiseaseInteraction.split == 0).order_by(GeneDiseaseInteraction.id).all()\n",
    "print(\"{} candidates load from db!\".format(len(all_cands)))\n",
    "\n",
    "print(\"Applying LSTM to candidates...\")\n",
    "%time lstm.save_marginals(session, all_cands)\n",
    "print(\"LSTM applied!\")\n",
    "\n",
    "from ksnorkel import KSUtils\n",
    "\n",
    "header_str = '{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}'.format('document_id', 'sentence_id', 'cand_id','gene_cid', 'gene_span', 'disease_cid', 'disease_span')\n",
    "%time KSUtils.save_binary_relation_as_tsv(result_path + \"gene_disease_interaction.tsv\", session, all_cands, all_sents, header_str, 'gene_cid', 'disease_cid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/31662 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31662/31662 [00:21<00:00, 1463.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 9869\n",
      "[LSTM] Loaded model <gene_chemical_metabolism.lstm>\n",
      "Loading all candidates from db...\n",
      "9869 candidates load from db!\n",
      "Applying LSTM to candidates...\n",
      "Saved 9869 marginals\n",
      "CPU times: user 41.6 s, sys: 1.87 s, total: 43.5 s\n",
      "Wall time: 25.1 s\n",
      "LSTM applied!\n",
      "Storing candidate labels into result file: results/pmc_sim_ami_128/gene_chemical_metabolism.tsv\n",
      "Amount of candidates: 9869\n",
      "Load mariginals from db...\n",
      "Marginals loaded!\n",
      "Building sentence to document map...\n",
      "Map built!\n",
      "Saved 758 positive predicitions for binary relation!\n",
      "CPU times: user 7.96 s, sys: 252 ms, total: 8.22 s\n",
      "Wall time: 8.21 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Candidate, candidate_subclass\n",
    "from snorkel.candidates import PretaggedCandidateExtractor\n",
    "\n",
    "from snorkel.models import Candidate, candidate_subclass\n",
    "from snorkel.candidates import PretaggedCandidateExtractor\n",
    "from snorkel.models import Candidate, candidate_subclass\n",
    "from snorkel.candidates import PretaggedCandidateExtractor\n",
    "\n",
    "\n",
    "GeneChemicalMetabolism = candidate_subclass('GeneChemicalMetabolism', ['gene', 'chemical'])\n",
    "candidate_gene_chemical_metabolism_extractor = PretaggedCandidateExtractor(GeneChemicalMetabolism, ['Gene', 'Chemical'])\n",
    "\n",
    "for k, sents in enumerate([all_sents]):\n",
    "    candidate_gene_chemical_metabolism_extractor.apply(sents, split=k, clear=True)\n",
    "    print(\"Number of candidates:\", session.query(GeneChemicalMetabolism).filter(GeneChemicalMetabolism.split == k).count())\n",
    "    \n",
    "    \n",
    "from snorkel.learning.pytorch import LSTM\n",
    "\n",
    "lstm = LSTM(n_threads=10)\n",
    "lstm.load('gene_chemical_metabolism.lstm')\n",
    "\n",
    "print(\"Loading all candidates from db...\")\n",
    "all_cands = session.query(GeneChemicalMetabolism).filter(GeneChemicalMetabolism.split == 0).order_by(GeneChemicalMetabolism.id).all()\n",
    "print(\"{} candidates load from db!\".format(len(all_cands)))\n",
    "\n",
    "print(\"Applying LSTM to candidates...\")\n",
    "%time lstm.save_marginals(session, all_cands)\n",
    "print(\"LSTM applied!\")\n",
    "\n",
    "from ksnorkel import KSUtils\n",
    "\n",
    "header_str = '{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}'.format('document_id', 'sentence_id', 'cand_id','gene_cid', 'gene_span', 'chemical_cid', 'chemical_span')\n",
    "%time KSUtils.save_binary_relation_as_tsv(result_path + \"gene_chemical_metabolism.tsv\", session, all_cands, all_sents, header_str, 'gene_cid', 'chemical_cid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/31662 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31662/31662 [00:21<00:00, 1459.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 9869\n",
      "[LSTM] Loaded model <chemical_gene_inhibition.lstm>\n",
      "Loading all candidates from db...\n",
      "9869 candidates load from db!\n",
      "Applying LSTM to candidates...\n",
      "Saved 9869 marginals\n",
      "CPU times: user 43.3 s, sys: 2.56 s, total: 45.9 s\n",
      "Wall time: 25 s\n",
      "LSTM applied!\n",
      "Storing candidate labels into result file: results/pmc_sim_ami_128/chemical_gene_inhibition.tsv\n",
      "Amount of candidates: 9869\n",
      "Load mariginals from db...\n",
      "Marginals loaded!\n",
      "Building sentence to document map...\n",
      "Map built!\n",
      "Saved 1059 positive predicitions for binary relation!\n",
      "CPU times: user 7.95 s, sys: 208 ms, total: 8.16 s\n",
      "Wall time: 8.15 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Candidate, candidate_subclass\n",
    "from snorkel.candidates import PretaggedCandidateExtractor\n",
    "\n",
    "from snorkel.models import Candidate, candidate_subclass\n",
    "from snorkel.candidates import PretaggedCandidateExtractor\n",
    "from snorkel.models import Candidate, candidate_subclass\n",
    "from snorkel.candidates import PretaggedCandidateExtractor\n",
    "\n",
    "\n",
    "\n",
    "ChemicalGeneInhibition = candidate_subclass('ChemicalGeneInhibition', ['chemical', 'gene'])\n",
    "candidate_gene_chemical_inhibit_extractor = PretaggedCandidateExtractor(ChemicalGeneInhibition, ['Chemical', 'Gene'])\n",
    "\n",
    "\n",
    "for k, sents in enumerate([all_sents]):\n",
    "    candidate_gene_chemical_inhibit_extractor.apply(sents, split=k, clear=True)\n",
    "    print(\"Number of candidates:\", session.query(ChemicalGeneInhibition).filter(ChemicalGeneInhibition.split == k).count())\n",
    "    \n",
    "from snorkel.learning.pytorch import LSTM\n",
    "\n",
    "lstm = LSTM(n_threads=10)\n",
    "lstm.load('chemical_gene_inhibition.lstm')\n",
    "\n",
    "print(\"Loading all candidates from db...\")\n",
    "all_cands = session.query(ChemicalGeneInhibition).filter(ChemicalGeneInhibition.split == 0).order_by(ChemicalGeneInhibition.id).all()\n",
    "print(\"{} candidates load from db!\".format(len(all_cands)))\n",
    "\n",
    "print(\"Applying LSTM to candidates...\")\n",
    "%time lstm.save_marginals(session, all_cands)\n",
    "print(\"LSTM applied!\")\n",
    "\n",
    "from ksnorkel import KSUtils\n",
    "\n",
    "header_str = '{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}'.format('document_id', 'sentence_id', 'cand_id','chemical_cid', 'chemical_span', 'gene_cid', 'gene_span')\n",
    "%time KSUtils.save_binary_relation_as_tsv(result_path + \"chemical_gene_inhibition.tsv\", session, all_cands, all_sents, header_str, 'chemical_cid', 'gene_cid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snorkel)",
   "language": "python",
   "name": "snorkel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
