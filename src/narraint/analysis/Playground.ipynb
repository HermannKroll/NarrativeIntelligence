{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-18:13:54:44,767 INFO     [entityresolver.py:55] Mesh index (29640 keys) load in 0:00:00.005545s\n",
      "2020-09-18:13:54:44,831 INFO     [entityresolver.py:59] Mesh Supplement index (268976 keys) load in 0:00:00.063466s\n",
      "2020-09-18:13:54:44,927 INFO     [entityresolver.py:122] Gene index (305657 keys) load in 0:00:00.095839s\n",
      "2020-09-18:13:54:45,873 INFO     [entityresolver.py:217] Species index (2231199 keys) load in 0:00:00.945791s\n",
      "2020-09-18:13:54:45,874 INFO     [entityresolver.py:249] DosageForm index (23 keys) load in 0:00:00.000110s\n",
      "2020-09-18:13:54:51,169 INFO     [entitytagger.py:48] 2781921 different terms map to entities\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: 19 correct of 25 documents\n",
      "Q2: 16 correct of 25 documents\n",
      "Q3: 17 correct of 25 documents\n",
      "Q4: 16 correct of 25 documents\n",
      "Q5: 6 correct of 25 documents\n",
      "Q6: 5 correct of 25 documents\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from sqlalchemy import func\n",
    "from narraint.analysis.cikm2020.expert_evaluation import eval_q1_ids_met_dia, eval_q2_ids_sim_chol, eval_q3_ids_sim_rab, \\\n",
    "    eval_q4_ids_met_mtor\n",
    "from narrant.backend.database import Session\n",
    "from narrant.backend.models import Document, Predication\n",
    "import pandas as pd\n",
    "from narraint.entity.entityresolver import EntityResolver\n",
    "from narraint.queryengine.engine import QueryEngine\n",
    "\n",
    "session = Session.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "#from ui.views import convert_query_text_to_fact_patterns\n",
    "#query_engine = QueryEngine()\n",
    "#gq, _ = convert_query_text_to_fact_patterns(\"?X(Chemical) treats ?Y(Disease)\")\n",
    "#results = query_engine.process_query_with_expansion(gq, \"PubMed\")\n",
    "q = session.query(Predication).filter(Predication.document_collection == 'PubMed')\n",
    "q = q.filter(Predication.predicate_canonicalized == 'induces')\n",
    "q = q.order_by(func.random())\n",
    "q = q.limit(1000)\n",
    "\n",
    "relevant_doc_ids = set()\n",
    "for r in q:\n",
    "    relevant_doc_ids.add(int(r.document_id))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "ids = set()\n",
    "ids.update(relevant_doc_ids)\n",
    "#ids.update(eval_q2_ids_sim_chol)\n",
    "#ids.update(eval_q3_ids_sim_rab)\n",
    "#ids.update(eval_q4_ids_met_mtor)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "doc2text = {}\n",
    "q = session.query(Document).filter(Document.collection == 'PubMed')\n",
    "q = q.filter(Document.id.in_(ids))\n",
    "\n",
    "print('loading data from db')\n",
    "for d in q:\n",
    "    doc2text[int(d.id)] = '{}. {}'.format(d.title, d.abstract)\n",
    "\n",
    "print('finished')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#doc2facts = defaultdict(list)\n",
    "doc2triples = defaultdict(set)\n",
    "entity_resolver = EntityResolver.instance()\n",
    "\n",
    "q = session.query(Predication).filter(Predication.document_collection == 'PubMed')\n",
    "q = q.filter(Predication.document_id.in_(ids))\n",
    "for pred in q:\n",
    "   # doc2facts[pred.document_id].append(pred)\n",
    "    try:\n",
    "        s = pred.subject_id# entity_resolver.get_name_for_var_ent_id(pred.subject_id, pred.subject_type, resolve_gene_by_id=False)\n",
    "    except KeyError:\n",
    "        print('{} ({})'.format(pred.subject_id, pred.subject_type))\n",
    "        continue\n",
    "    try:\n",
    "        o = pred.object_id #entity_resolver.get_name_for_var_ent_id(pred.object_id, pred.object_type, resolve_gene_by_id=False)\n",
    "    except KeyError:\n",
    "        print('{} ({})'.format(pred.object_id, pred.object_type))\n",
    "        continue\n",
    "    doc2triples[pred.document_id].add((pred.subject_type, pred.object_type))\n",
    "    doc2triples[pred.document_id].add((pred.object_type, pred.subject_type))\n",
    "\n",
    "print('finished')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin mining...\n",
      "        support                                           itemsets  length\n",
      "2      0.904714                               (Chemical<>Chemical)       1\n",
      "3      0.605817                                (Chemical<>Disease)       1\n",
      "7      0.605817                                (Disease<>Chemical)       1\n",
      "69     0.605817             (Disease<>Chemical, Chemical<>Disease)       2\n",
      "42     0.510532            (Chemical<>Chemical, Chemical<>Disease)       2\n",
      "...         ...                                                ...     ...\n",
      "4097   0.010030  (Disease<>Species, Species<>Chemical, Disease<...       4\n",
      "30722  0.010030  (Gene<>Gene, Species<>Gene, Chemical<>Gene, Ch...       8\n",
      "4113   0.010030  (Disease<>Species, Species<>Chemical, Disease<...       4\n",
      "30721  0.010030  (Gene<>Gene, Chemical<>Gene, Chemical<>Species...       8\n",
      "42414  0.010030  (Disease<>Chemical, Gene<>Gene, Species<>Gene,...      14\n",
      "\n",
      "[42415 rows x 3 columns]\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "def frequent_item_set_mining(doc2factset, output):\n",
    "    transformed_list = []\n",
    "    for doc, facts in doc2factset.items():\n",
    "        transaction = []\n",
    "        for s, o in facts:\n",
    "            transaction.append(('{}<>{}'.format(s, o)))\n",
    "        transformed_list.append(transaction)\n",
    "\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(transformed_list).transform(transformed_list)\n",
    "    df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "    frequent_itemsets = apriori(df, min_support=0.01, use_colnames=True, low_memory=False)\n",
    "    frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "    frequent_itemsets.sort_values(by=['support'], inplace=True, ascending=False)\n",
    "    #doc_count = len(doc2facts)\n",
    "    #frequent_itemsets['documents'] = frequent_itemsets['support'].apply(lambda x: int(x * doc_count))\n",
    "    print(frequent_itemsets)\n",
    "    frequent_itemsets.to_csv(output, sep='\\t')\n",
    "\n",
    "print('begin mining...')\n",
    "frequent_item_set_mining(doc2triples, 'frequentitemsets.tsv')\n",
    "print('finished')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}