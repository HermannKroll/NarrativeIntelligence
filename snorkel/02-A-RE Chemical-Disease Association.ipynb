{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should process a grid search for lstm?\n",
    "do_grid_search = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reload Snorkel Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Train, Dev and Test sentences. Default Split is 1:1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ksnorkel import KSUtils\n",
    "\n",
    "\n",
    "train_sent, dev_sent, test_sent = KSUtils.split_sentences(session, split=[0.8, 0.1, 0.1], seed=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now generate all candidates for each sentence set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.models import Candidate, candidate_subclass\n",
    "from snorkel.candidates import PretaggedCandidateExtractor\n",
    "\n",
    "ChemicalDisease = candidate_subclass('ChemicalDisease', ['chemical', 'disease'])\n",
    "candidate_extractor = PretaggedCandidateExtractor(ChemicalDisease, ['Chemical', 'Disease'])\n",
    "\n",
    "for k, sents in enumerate([train_sent,dev_sent, test_sent]):\n",
    "    candidate_extractor.apply(sents, split=k, clear=True)\n",
    "    print(\"Number of candidates:\", session.query(ChemicalDisease).filter(ChemicalDisease.split == k).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load CTD Dataset as gold label for drug disease associations\n",
    "(see http://ctdbase.org/downloads/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "\n",
    "ctd_drug_disease_associations = set()\n",
    "with gzip.open('data/CTD_chemicals_diseases.tsv.gz','r') as f:\n",
    "    for l in f:\n",
    "        line = str(l).replace('b\\'', '').replace('\\\\n\\'', '')\n",
    "        # skip comments\n",
    "        if line.startswith('#'):\n",
    "            continue\n",
    "        # split line into components\n",
    "        components = line.split('\\\\t')\n",
    "        # add MESH:\n",
    "        if not components[1].startswith('MESH:'):\n",
    "            components[1] = \"MESH:\" + components[1]\n",
    "        if not components[4].startswith('MESH:'):\n",
    "            components[4] = \"MESH:\" + components[4]\n",
    "        \n",
    "        #print(\"{} {}\".format(components[1], components[4]))\n",
    "        key = frozenset((components[1], components[4]))\n",
    "        ctd_drug_disease_associations.add(key)\n",
    "\n",
    "print(\"Read {} drug-disease associations from CTD\".format(len(ctd_drug_disease_associations)))\n",
    "       \n",
    "def cand_in_ctd_drug_disease_associations(c):\n",
    "    key = frozenset((c.chemical_cid, c.disease_cid))\n",
    "    #print(key)\n",
    "    return 1 if key in ctd_drug_disease_associations else -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label all candidates of ChemicalDiesease with CTD als a ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ksnorkel import KSUtils\n",
    "\n",
    "KSUtils.add_gold_labels_for_candidates(session, ChemicalDisease, cand_in_ctd_drug_disease_associations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labeling function for ctd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_cd_in_CTD(c):\n",
    "    if cand_in_ctd_drug_disease_associations(c) == 1:\n",
    "        return 1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from snorkel.lf_helpers import (\n",
    "    get_tagged_text,\n",
    "    rule_regex_search_tagged_text,\n",
    "    rule_regex_search_btw_AB,\n",
    "    rule_regex_search_btw_BA,\n",
    "    rule_regex_search_before_A,\n",
    "    rule_regex_search_before_B,\n",
    ")\n",
    "\n",
    "# List to parenthetical\n",
    "def ltp(x):\n",
    "    return '(' + '|'.join(x) + ')'\n",
    "\n",
    "def LF_induce(c):\n",
    "    return 1 if re.search(r'{{A}}.{0,20}induc.{0,20}{{B}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "causal_past = ['induced', 'caused', 'due']\n",
    "def LF_d_induced_by_c(c):\n",
    "    return rule_regex_search_btw_BA(c, '.{0,50}' + ltp(causal_past) + '.{0,9}(by|to).{0,50}', 1)\n",
    "def LF_d_induced_by_c_tight(c):\n",
    "    return rule_regex_search_btw_BA(c, '.{0,50}' + ltp(causal_past) + ' (by|to) ', 1)\n",
    "\n",
    "def LF_induce_name(c):\n",
    "    return 1 if 'induc' in c.chemical.get_span().lower() else 0     \n",
    "\n",
    "causal = ['cause[sd]?', 'induce[sd]?', 'associated with']\n",
    "def LF_c_cause_d(c):\n",
    "    return 1 if (\n",
    "        re.search(r'{{A}}.{0,50} ' + ltp(causal) + '.{0,50}{{B}}', get_tagged_text(c), re.I)\n",
    "        and not re.search('{{A}}.{0,50}(not|no).{0,20}' + ltp(causal) + '.{0,50}{{B}}', get_tagged_text(c), re.I)\n",
    "    ) else 0\n",
    "\n",
    "treat = ['treat', 'effective', 'prevent', 'resistant', 'slow', 'promise', 'therap']\n",
    "def LF_d_treat_c(c):\n",
    "    return rule_regex_search_btw_BA(c, '.{0,50}' + ltp(treat) + '.{0,50}', -1)\n",
    "def LF_c_treat_d(c):\n",
    "    return rule_regex_search_btw_AB(c, '.{0,50}' + ltp(treat) + '.{0,50}', -1)\n",
    "def LF_treat_d(c):\n",
    "    return rule_regex_search_before_B(c, ltp(treat) + '.{0,50}', -1)\n",
    "def LF_c_treat_d_wide(c):\n",
    "    return rule_regex_search_btw_AB(c, '.{0,200}' + ltp(treat) + '.{0,200}', -1)\n",
    "\n",
    "def LF_c_d(c):\n",
    "    return 1 if ('{{A}} {{B}}' in get_tagged_text(c)) else 0\n",
    "\n",
    "def LF_c_induced_d(c):\n",
    "    return 1 if (\n",
    "        ('{{A}} {{B}}' in get_tagged_text(c)) and \n",
    "        (('-induc' in c[0].get_span().lower()) or ('-assoc' in c[0].get_span().lower()))\n",
    "        ) else 0\n",
    "\n",
    "def LF_improve_before_disease(c):\n",
    "    return rule_regex_search_before_B(c, 'improv.*', -1)\n",
    "\n",
    "pat_terms = ['in a patient with ', 'in patients with']\n",
    "def LF_in_patient_with(c):\n",
    "    return -1 if re.search(ltp(pat_terms) + '{{B}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "uncertain = ['combin', 'possible', 'unlikely']\n",
    "def LF_uncertain(c):\n",
    "    return rule_regex_search_before_A(c, ltp(uncertain) + '.*', -1)\n",
    "\n",
    "def LF_induced_other(c):\n",
    "    return rule_regex_search_tagged_text(c, '{{A}}.{20,1000}-induced {{B}}', -1)\n",
    "\n",
    "def LF_far_c_d(c):\n",
    "    return rule_regex_search_btw_AB(c, '.{100,5000}', -1)\n",
    "\n",
    "def LF_far_d_c(c):\n",
    "    return rule_regex_search_btw_BA(c, '.{100,5000}', -1)\n",
    "\n",
    "def LF_risk_d(c):\n",
    "    return rule_regex_search_before_B(c, 'risk of ', 1)\n",
    "\n",
    "def LF_develop_d_following_c(c):\n",
    "    return 1 if re.search(r'develop.{0,25}{{B}}.{0,25}following.{0,25}{{A}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "procedure, following = ['inject', 'administrat'], ['following']\n",
    "def LF_d_following_c(c):\n",
    "    return 1 if re.search('{{B}}.{0,50}' + ltp(following) + '.{0,20}{{A}}.{0,50}' + ltp(procedure), get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "def LF_measure(c):\n",
    "    return -1 if re.search('measur.{0,75}{{A}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "def LF_level(c):\n",
    "    return -1 if re.search('{{A}}.{0,25} level', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "def LF_neg_d(c):\n",
    "    return -1 if re.search('(none|not|no) .{0,25}{{B}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "WEAK_PHRASES = ['none', 'although', 'was carried out', 'was conducted',\n",
    "                'seems', 'suggests', 'risk', 'implicated',\n",
    "               'the aim', 'to (investigate|assess|study)']\n",
    "\n",
    "WEAK_RGX = r'|'.join(WEAK_PHRASES)\n",
    "\n",
    "def LF_weak_assertions(c):\n",
    "    return -1 if re.search(WEAK_RGX, get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "\n",
    "def LF_closer_chem(c):\n",
    "    # Get distance between chemical and disease\n",
    "    chem_start, chem_end = c.chemical.get_word_start(), c.chemical.get_word_end()\n",
    "    dis_start, dis_end = c.disease.get_word_start(), c.disease.get_word_end()\n",
    "    if dis_start < chem_start:\n",
    "        dist = chem_start - dis_end\n",
    "    else:\n",
    "        dist = dis_start - chem_end\n",
    "    # Try to find chemical closer than @dist/2 in either direction\n",
    "    sent = c.get_parent()\n",
    "    closest_other_chem = float('inf')\n",
    "    for i in range(dis_end, min(len(sent.words), dis_end + dist // 2)):\n",
    "        et, cid = sent.entity_types[i], sent.entity_cids[i]\n",
    "        if et == 'Chemical' and cid != sent.entity_cids[chem_start]:\n",
    "            return -1\n",
    "    for i in range(max(0, dis_start - dist // 2), dis_start):\n",
    "        et, cid = sent.entity_types[i], sent.entity_cids[i]\n",
    "        if et == 'Chemical' and cid != sent.entity_cids[chem_start]:\n",
    "            return -1\n",
    "    return 0\n",
    "\n",
    "def LF_closer_dis(c):\n",
    "    # Get distance between chemical and disease\n",
    "    chem_start, chem_end = c.chemical.get_word_start(), c.chemical.get_word_end()\n",
    "    dis_start, dis_end = c.disease.get_word_start(), c.disease.get_word_end()\n",
    "    if dis_start < chem_start:\n",
    "        dist = chem_start - dis_end\n",
    "    else:\n",
    "        dist = dis_start - chem_end\n",
    "    # Try to find chemical disease than @dist/8 in either direction\n",
    "    sent = c.get_parent()\n",
    "    for i in range(chem_end, min(len(sent.words), chem_end + dist // 8)):\n",
    "        et, cid = sent.entity_types[i], sent.entity_cids[i]\n",
    "        if et == 'Disease' and cid != sent.entity_cids[dis_start]:\n",
    "            return -1\n",
    "    for i in range(max(0, chem_start - dist // 8), chem_start):\n",
    "        et, cid = sent.entity_types[i], sent.entity_cids[i]\n",
    "        if et == 'Disease' and cid != sent.entity_cids[dis_start]:\n",
    "            return -1\n",
    "    return 0\n",
    "\n",
    "\n",
    "LFs = [\n",
    "    LF_cd_in_CTD,\n",
    "    LF_c_cause_d,\n",
    "    LF_c_d,\n",
    "    LF_c_induced_d,\n",
    "    LF_c_treat_d,\n",
    "    LF_c_treat_d_wide,\n",
    "    LF_d_following_c,\n",
    "    LF_d_induced_by_c,\n",
    "    LF_d_induced_by_c_tight,\n",
    "    LF_d_treat_c,\n",
    "    LF_develop_d_following_c,\n",
    "    LF_far_c_d,\n",
    "    LF_far_d_c,\n",
    "    LF_improve_before_disease,\n",
    "    LF_in_patient_with,\n",
    "    LF_induce,\n",
    "    LF_induce_name,\n",
    "    LF_induced_other,\n",
    "    LF_level,\n",
    "    LF_measure,\n",
    "    LF_neg_d,\n",
    "    LF_risk_d,\n",
    "    LF_treat_d,\n",
    "    LF_uncertain,\n",
    "    LF_weak_assertions,\n",
    "    LF_closer_chem,\n",
    "    LF_closer_dis\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelAnnotator\n",
    "labeler = LabelAnnotator(lfs=LFs)\n",
    "\n",
    "%time L_train = labeler.apply(split=0)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also view statistics about the resulting label matrix.\n",
    "\n",
    "* **Coverage** is the fraction of candidates that the labeling function emits a non-zero label for.\n",
    "* **Overlap** is the fraction candidates that the labeling function emits a non-zero label for and that another labeling function emits a non-zero label for.\n",
    "* **Conflict** is the fraction candidates that the labeling function emits a non-zero label for and that another labeling function emits a *conflicting* non-zero label for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_train.lf_stats(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "L_dev = labeler.apply_existing(split=1)\n",
    "L_test = labeler.apply_existing(split=2)\n",
    "\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold',split=1)\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search on generative model to find the best parameter configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "from snorkel.learning import RandomSearch\n",
    "from snorkel.learning.structure import DependencySelector\n",
    "\n",
    "MAX_DEPS = 5\n",
    "\n",
    "ds = DependencySelector()\n",
    "deps = ds.select(L_train, threshold=0.1)\n",
    "deps = set(list(deps)[0:min(len(deps), MAX_DEPS)])\n",
    "\n",
    "print(\"Using {} dependencies\".format(len(deps)))\n",
    "\n",
    "\n",
    "\n",
    "# use random search to optimize the generative model\n",
    "param_grid = {\n",
    "    'step_size' : [1e-3, 1e-4, 1e-5, 1e-6],\n",
    "    'decay'     : [0.9, 0.95],\n",
    "    'epochs'    : [50,100], # ,150],\n",
    "    'reg_param' : [1e-3],\n",
    "}\n",
    "\n",
    "model_class_params = {'lf_propensity' : False }#, 'deps': deps}\n",
    "\n",
    "searcher = RandomSearch(GenerativeModel, param_grid, L_train, n=5, model_class_params=model_class_params)\n",
    "%time gen_model, run_stats = searcher.fit(L_dev, L_gold_dev) #, deps=deps)\n",
    "run_stats\n",
    "\n",
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_marginals, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, fp, tn, fn = gen_model.error_analysis(session, L_dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, fp, tn, fn = gen_model.error_analysis(session, L_test, L_gold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_marginals = gen_model.marginals(L_dev)\n",
    "_, _, _, _ = gen_model.error_analysis(session, L_dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cands = session.query(ChemicalDisease).filter(ChemicalDisease.split == 0).order_by(ChemicalDisease.id).all()\n",
    "dev_cands   = session.query(ChemicalDisease).filter(ChemicalDisease.split == 1).order_by(ChemicalDisease.id).all()\n",
    "test_cands  = session.query(ChemicalDisease).filter(ChemicalDisease.split == 2).order_by(ChemicalDisease.id).all()\n",
    "\n",
    "all_cands = []\n",
    "all_cands.extend(train_cands)\n",
    "all_cands.extend(dev_cands)\n",
    "all_cands.extend(test_cands)\n",
    "\n",
    "print(\"Amount of all candidates: {}\".format(len(all_cands)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.learning.pytorch import LSTM\n",
    "\n",
    "#train_kwargs = {\n",
    "#    'lr':              0.01,\n",
    "#    'embedding_dim':   75,\n",
    "#    'hidden_dim':      75,\n",
    "#    'n_epochs':        100,\n",
    "#    'dropout':         0.5,\n",
    "#    'rebalance':       0.25,\n",
    "#    'seed':            1701\n",
    "#}\n",
    "\n",
    "if not do_grid_search:\n",
    "    # Best Configuration after grid search\n",
    "    train_kwargs = {\n",
    "        'batchsize':       64,\n",
    "        'lr':              0.001,\n",
    "        'embedding_dim':   100,\n",
    "        'hidden_dim':      150,\n",
    "        'n_epochs':        100,\n",
    "        'dropout':         0.25,\n",
    "        'rebalance':       0.0,\n",
    "        'seed':            1701\n",
    "    }\n",
    "\n",
    "    lstm = LSTM(n_threads=10)\n",
    "    lstm.train(train_cands, train_marginals, X_dev=dev_cands, Y_dev=L_gold_dev,use_cudnn=True, **train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.learning import RandomSearch\n",
    "from snorkel.learning.pytorch import LSTM\n",
    "\n",
    "if do_grid_search:\n",
    "    seed = 12345\n",
    "    num_model_search = 25\n",
    "\n",
    "    # search over this parameter grid\n",
    "    param_grid = {}\n",
    "    param_grid['batch_size'] = [64, 128]\n",
    "    param_grid['lr']         = [1e-4, 1e-3, 1e-2]\n",
    "    #param_grid['l1_penalty'] = [1e-6, 1e-4, 1e-2]\n",
    "    #param_grid['l2_penalty'] = [1e-6, 1e-4, 1e-2]\n",
    "    param_grid['rebalance']  = [0.0,0.25, 0.5]\n",
    "    param_grid['embedding_dim'] = [75, 100, 125]\n",
    "    param_grid['hidden_dim'] = [50, 100, 150]\n",
    "    param_grid['dropout'] = [0, 0.25, 0.5]\n",
    "\n",
    "    model_class_params = {\n",
    "        'n_threads':1\n",
    "    }\n",
    "\n",
    "\n",
    "    model_hyperparams = {\n",
    "        'n_epochs': 100,\n",
    "        'print_freq': 25,\n",
    "        'dev_ckpt_delay': 0.5,\n",
    "        'X_dev': dev_cands,\n",
    "        'Y_dev': L_gold_dev,\n",
    "    }\n",
    "\n",
    "    #lstm = LSTM(n_threads=1)\n",
    "\n",
    "    searcher = RandomSearch(LSTM, param_grid, train_cands, train_marginals,\n",
    "                            n=num_model_search, seed=seed,\n",
    "                            model_class_params=model_class_params,\n",
    "                            model_hyperparams=model_hyperparams)\n",
    "\n",
    "    print(\"Discriminitive Model Parameter Space (seed={}):\".format(seed))\n",
    "    for i, params in enumerate(searcher.search_space()):\n",
    "        print(\"{} {}\".format(i, params))\n",
    "\n",
    "    disc_model, run_stats = searcher.fit(X_valid=dev_cands, Y_valid=L_gold_dev, n_threads=1)\n",
    "    lstm = disc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_grid_search:\n",
    "    run_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, f1 = lstm.score(test_cands, L_gold_test)\n",
    "print(\"Prec: {0:.3f}, Recall: {1:.3f}, F1 Score: {2:.3f}\".format(p, r, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, fp, tn, fn = lstm.error_analysis(session, test_cands, L_gold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.save_marginals(session, all_cands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ksnorkel import KSUtils\n",
    "\n",
    "all_sents = []\n",
    "all_sents.extend(train_sent)\n",
    "all_sents.extend(dev_sent)\n",
    "all_sents.extend(test_sent)\n",
    "\n",
    "header_str = '{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}'.format('document_id', 'sentence_id', 'cand_id', 'chemical_cid', 'chemical_span', 'disease_cid', 'disease_span')\n",
    "%time KSUtils.save_binary_relation_as_tsv('results/chemical_disease_association.tsv', session, all_cands, all_sents, header_str, 'chemical_cid', 'disease_cid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.save(\"chemical_disease.lstm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snorkel)",
   "language": "python",
   "name": "snorkel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
