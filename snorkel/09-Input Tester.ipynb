{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'data/test/pmc_simvastatin_amiodarone_filtered_128.pubtator'\n",
    "\n",
    "i = 0\n",
    "with open(file, 'r') as f:\n",
    "    line_buffer = []\n",
    "    for l in f:\n",
    "        line_buffer.append(l)\n",
    "        # split file here\n",
    "        if l == '\\n':\n",
    "            fo_name = '{}.{}'.format(file,i)\n",
    "            with open(fo_name, 'w') as fo:\n",
    "                for lo in line_buffer:\n",
    "                    fo.write(lo)\n",
    "            print('{} written'.format(fo_name))\n",
    "            line_buffer = []\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel import SnorkelSession\n",
    "from snorkel.parser import CorpusParser, Spacy, StanfordCoreNLPServer\n",
    "from pubtator import PubTatorDocPreprocessor, PubTatorTagProcessor, PubTatorParser\n",
    "from time import time\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "\n",
    "session = SnorkelSession()\n",
    "\n",
    "parser = \"spacy\"\n",
    "num_procs = 1\n",
    "\n",
    "\n",
    "\n",
    "for i in range(74, 75):\n",
    "    print('<<<<<< Process Document {}  >>>>>>>'.format(i))\n",
    "    start_ts = time()\n",
    "    file_name = '{}.{}'.format(file, i)\n",
    "    doc_preprocessor = PubTatorDocPreprocessor(file_name, annotations=False, debug=True)\n",
    "    #arser = Spacy() if parser == \"spacy\" else StanfordCoreNLPServer()\n",
    "    parser = PubTatorParser(stop_on_err=False)\n",
    "    corpus_parser = CorpusParser(parser=parser)\n",
    "    corpus_parser.apply(doc_preprocessor, parallelism=num_procs, clear=True)\n",
    "    end_ts = time()\n",
    "    \n",
    "    from snorkel.models import Document, Sentence\n",
    "\n",
    "    print(\"Documents:\", session.query(Document).count())\n",
    "    print(\"Sentences:\", session.query(Sentence).count())\n",
    "\n",
    "    print(\"Loading all sentences from db...\")\n",
    "    all_sents = session.query(Sentence).all()\n",
    "    print(\"Loading complete!\")\n",
    "\n",
    "\n",
    "    print('Amount of sentences: {}'.format(len(all_sents)))\n",
    "\n",
    "    print(\"\\nDONE in {}\".format((time() - start_ts)))\n",
    "    \n",
    "    from snorkel.models import Candidate, candidate_subclass\n",
    "    from snorkel.candidates import PretaggedCandidateExtractor\n",
    "\n",
    "    ChemicalGeneInteraction = candidate_subclass('ChemicalGeneInteraction', ['chemical', 'gene'])\n",
    "    candidate_extractor = PretaggedCandidateExtractor(ChemicalGeneInteraction, ['Chemical', 'Gene'])\n",
    "\n",
    "    for k, sents in enumerate([all_sents]):\n",
    "        candidate_extractor.apply(sents, split=k, clear=True)\n",
    "        print(\"Number of candidates:\", session.query(ChemicalGeneInteraction).filter(ChemicalGeneInteraction.split == k).count())\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snorkel)",
   "language": "python",
   "name": "snorkel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
