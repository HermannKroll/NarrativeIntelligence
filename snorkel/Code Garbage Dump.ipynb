{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "param_grid = {}\n",
    "param_grid['batch_size'] = [64, 128]\n",
    "param_grid['hidden_dim'] = [50, 100, 150]\n",
    "param_grid['dropout'] = [0, 0.25, 0.5]\n",
    "\n",
    "param_names = []\n",
    "param_names.extend(param_grid.keys())\n",
    "\n",
    "\n",
    "for pn, pv in param_grid.items():\n",
    "    print('ParamGrid {} (type = {}) = {}'.format(pn, type(pv[0]), pv))\n",
    "    \n",
    "def search_space():\n",
    "    return product(*[param_grid[pn] for pn in param_names])\n",
    "\n",
    "rand_state = np.random.RandomState()\n",
    "n = 1\n",
    "def search_space_2():\n",
    "    return list(zip(*[rand_state.choice(param_grid[pn], n)\n",
    "            for pn in param_names]))\n",
    "\n",
    "\n",
    "        \n",
    "for k, param_vals in enumerate(search_space_2()):\n",
    "        print('Search Space with Numpy Random State')\n",
    "        for v in param_vals:\n",
    "            print('{} (type = {})'.format(v, type(v)))\n",
    "        print('\\n')\n",
    "        \n",
    "param_names = param_names[0:1]\n",
    "for k, param_vals in enumerate(search_space()):\n",
    "        print('Search Space')\n",
    "        for v in param_vals:\n",
    "            print('{} (type = {})'.format(v, type(v)))\n",
    "        print('\\n')\n",
    "        \n",
    "        \n",
    "print(type(param_grid[param_names[0]][0]))\n",
    "print(type(rand_state.choice(param_grid[param_names[0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from snorkel.learning import GridSearch\n",
    "\n",
    "class RandomSearchGPU(GridSearch):\n",
    "    \"\"\"\n",
    "    A GridSearch over a random subsample of the hyperparameter search space.\n",
    "\n",
    "    :param seed: A seed for the GridSearch instance\n",
    "    \"\"\"\n",
    "    def __init__(self, model_class, parameter_dict, X_train, Y_train=None, n=10,\n",
    "        model_class_params={}, model_hyperparams={}, seed=123, \n",
    "        save_dir='checkpoints'):\n",
    "        \"\"\"Search a random sample of size n from a parameter grid\"\"\"\n",
    "        self.rand_state = np.random.RandomState()\n",
    "        self.rand_state.seed(seed)\n",
    "        self.n = n\n",
    "        random.seed(seed)\n",
    "        super(RandomSearchGPU, self).__init__(model_class, parameter_dict, X_train,\n",
    "            Y_train=Y_train, model_class_params=model_class_params,\n",
    "            model_hyperparams=model_hyperparams, save_dir=save_dir)\n",
    "\n",
    "#    def search_space(self):\n",
    "#        return list(zip(*[self.rand_state.choice(self.parameter_dict[pn], self.n)\n",
    "#            for pn in self.param_names]))\n",
    "    \n",
    "    def search_space(self):\n",
    "        return list(zip(*[random.choices(self.parameter_dict[pn], k=self.n)\n",
    "            for pn in self.param_names]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pretty_size(size):\n",
    "\t\"\"\"Pretty prints a torch.Size object\"\"\"\n",
    "\tassert(isinstance(size, torch.Size))\n",
    "\treturn \" × \".join(map(str, size))\n",
    "\n",
    "\n",
    "def dump_tensors(gpu_only=True):\n",
    "\t\"\"\"Prints a list of the Tensors being tracked by the garbage collector.\"\"\"\n",
    "\timport gc\n",
    "\ttotal_size = 0\n",
    "\tfor obj in gc.get_objects():\n",
    "\t\ttry:\n",
    "\t\t\tif torch.is_tensor(obj):\n",
    "\t\t\t\tif not gpu_only or obj.is_cuda:\n",
    "\t\t\t\t\tprint(\"%s:%s%s %s\" % (type(obj).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t  \" GPU\" if obj.is_cuda else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t  \" pinned\" if obj.is_pinned else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t  pretty_size(obj.size())))\n",
    "\t\t\t\t\ttotal_size += obj.numel()\n",
    "\t\t\telif hasattr(obj, \"data\") and torch.is_tensor(obj.data):\n",
    "\t\t\t\tif not gpu_only or obj.is_cuda:\n",
    "\t\t\t\t\tprint(\"%s → %s:%s%s%s%s %s\" % (type(obj).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   type(obj.data).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" GPU\" if obj.is_cuda else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" pinned\" if obj.data.is_pinned else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" grad\" if obj.requires_grad else \"\", \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" volatile\" if obj.volatile else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   pretty_size(obj.data.size())))\n",
    "\t\t\t\t\ttotal_size += obj.data.numel()\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tpass        \n",
    "\tprint(\"Total size:\", total_size)\n",
    "    \n",
    "dump_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('results/gene_chemical_metabolism.tsv', 'r') as f:\n",
    "    first = True\n",
    "    for line in f:\n",
    "        if first: # skip header\n",
    "            first = False\n",
    "            continue\n",
    "        \n",
    "        spl = line.replace('\\n', '').split('\\t')\n",
    "        doc_id = spl[0]\n",
    "        sen_id = spl[1]\n",
    "        gen_id = spl[3]\n",
    "        gen_span = spl[4]      \n",
    "        chem_id = spl[5]\n",
    "        chem_span = spl[6]\n",
    "   \n",
    "        fact_store.gen_id_to_span[gen_id] = gen_span\n",
    "        fact_store.chem_id_to_span[chem_id] = chem_span\n",
    "        #fact = ('meta', gen_span)       \n",
    "        fact = (gen_id,'meta',chem_id)\n",
    "        fact_store.add_fact(doc_id, fact)\n",
    "fact_store.print_info()\n",
    "\n",
    "with open('results/chemical_gene_inhibition.tsv', 'r') as f:\n",
    "    first = True\n",
    "    for line in f:\n",
    "        if first: # skip header\n",
    "            first = False\n",
    "            continue\n",
    "        \n",
    "        spl = line.replace('\\n', '').split('\\t')\n",
    "        doc_id = spl[0]\n",
    "        sen_id = spl[1]\n",
    "        chem_id = spl[3]\n",
    "        chem_span = spl[4]\n",
    "        gen_id = spl[5]\n",
    "        gen_span = spl[6]\n",
    "        \n",
    "        fact_store.chem_id_to_span[chem_id] = chem_span\n",
    "        fact_store.gen_id_to_span[gen_id] = gen_span\n",
    "                \n",
    "        #fact = (chem_span, 'inh', gen_span)\n",
    "        fact = (chem_id, 'inh', gen_id)\n",
    "        fact_store.add_fact(doc_id, fact)\n",
    "\n",
    "        \n",
    "fact_store.print_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim id\n",
    "sim_id = 'MESH:D019821'\n",
    "cyp3a4_id = '1576'\n",
    "key = frozenset((sim_id, 'cd', rhabdo_id))\n",
    "print(key)\n",
    "\n",
    "f_sr_id = fact_store.fact_to_id[key]\n",
    "\n",
    "print(f_sr_id)\n",
    "\n",
    "key = frozenset((cyp3a4_id, 'meta', sim_id))\n",
    "f_gs_id = fact_store.fact_to_id[key]\n",
    "\n",
    "print(f_gs_id)\n",
    "\n",
    "check_set = set()\n",
    "check_set.add(f_sr_id)\n",
    "check_set.add(f_gs_id)\n",
    "\n",
    "to_check = []\n",
    "to_check.append(check_set)\n",
    "print(\"To_check: {}\".format(to_check))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#str_text = 'telaprevir inhibits the reaction [CYP3A4 protein results in increased metabolism of Simvastatin]'.lower()\n",
    "#str_text = 'simvastatin inhibits the reaction [CYP3A4 protein results in inhibit metabolism of Simvastatin]'.lower()\n",
    "str_text = 'tamoxifen inhibits the reaction [amitraz results in increased expression of th protein]' \n",
    "\n",
    "if 'inhibit' in str_text:\n",
    "    print(\"yes contained\")\n",
    "\n",
    "che_name = 'tamoxifen'\n",
    "gen_name = 'amitraz'\n",
    "regex1 = '{}[^\\]\\[]+inhibit[^\\]\\[]+{}'.format(che_name, gen_name)\n",
    "regex2 = '{}[^\\]\\[]+inhibit[^\\]\\[]+{}'.format(gen_name, che_name)\n",
    "\n",
    "res1 = re.search(regex1, str_text)   \n",
    "res2 = re.search(regex2, str_text)  \n",
    "\n",
    "print(res1)\n",
    "print(res2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snorkel)",
   "language": "python",
   "name": "snorkel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
