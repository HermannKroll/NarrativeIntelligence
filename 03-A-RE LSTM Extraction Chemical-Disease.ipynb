{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove snorkel db...\n",
      "snorkel db removed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print('remove snorkel db...')\n",
    "os.remove(\"snorkel.db\") \n",
    "print('snorkel db removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running UDF...\n",
      "\n",
      "DONE in 2.7572879791259766\n"
     ]
    }
   ],
   "source": [
    "from snorkel import SnorkelSession\n",
    "from snorkel.parser import CorpusParser, Spacy, StanfordCoreNLPServer\n",
    "from pubtator import PubTatorDocPreprocessor, PubTatorTagProcessor, PubTatorParser\n",
    "from time import time\n",
    "\n",
    "parser = \"spacy\"\n",
    "num_procs = 1\n",
    "\n",
    "start_ts = time()\n",
    "\n",
    "filelist = ['data/Tafamidis97_filtered.pubtator']\n",
    "\n",
    "for fp in filelist:\n",
    "    doc_preprocessor = PubTatorDocPreprocessor(fp, annotations=False)\n",
    "    #arser = Spacy() if parser == \"spacy\" else StanfordCoreNLPServer()\n",
    "    parser = PubTatorParser(stop_on_err=False)\n",
    "    corpus_parser = CorpusParser(parser=parser)\n",
    "    corpus_parser.apply(doc_preprocessor, parallelism=num_procs, clear=False)\n",
    "    end_ts = time()\n",
    "\n",
    "print(\"\\nDONE in {}\".format((time() - start_ts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: 97\n",
      "Sentences: 1038\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Document, Sentence\n",
    "\n",
    "print(\"Documents:\", session.query(Document).count())\n",
    "print(\"Sentences:\", session.query(Sentence).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the directory results/tafamidis97/ \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#subdir in results\n",
    "result_path = 'results/tafamidis97/'\n",
    "\n",
    "try:  \n",
    "    os.mkdir(result_path)\n",
    "except OSError:  \n",
    "    print (\"Creation of the directory {} failed because it may exists\".format(result_path))\n",
    "else:  \n",
    "    print (\"Successfully created the directory %s \" % result_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of docs: 97\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Document\n",
    "\n",
    "all_docs = session.query(Document).all()\n",
    "\n",
    "print('Amount of docs: {}'.format(len(all_docs)))\n",
    "with open(result_path + 'doc_mapping.tsv', 'w') as f:\n",
    "    f.write('{}\\t{}\\n'.format('snorkel_id', 'pmid'))\n",
    "    for doc in all_docs:\n",
    "        f.write('{}\\t{}\\n'.format(doc.id, doc.name))\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: 97\n",
      "Sentences: 1038\n",
      "Loading all sentences from db...\n",
      "Loading complete!\n",
      "Amount of sentences: 1038\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Document, Sentence\n",
    "\n",
    "print(\"Documents:\", session.query(Document).count())\n",
    "print(\"Sentences:\", session.query(Sentence).count())\n",
    "\n",
    "print(\"Loading all sentences from db...\")\n",
    "all_sents = session.query(Sentence).all()\n",
    "print(\"Loading complete!\")\n",
    "\n",
    "\n",
    "print('Amount of sentences: {}'.format(len(all_sents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 52/1038 [00:00<00:01, 515.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1038/1038 [00:01<00:00, 896.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Candidate, candidate_subclass\n",
    "from snorkel.candidates import PretaggedCandidateExtractor\n",
    "\n",
    "ChemicalDisease = candidate_subclass('ChemicalDisease', ['chemical', 'disease'])\n",
    "candidate_extractor = PretaggedCandidateExtractor(ChemicalDisease, ['Chemical', 'Disease'])\n",
    "\n",
    "for k, sents in enumerate([all_sents]):\n",
    "    candidate_extractor.apply(sents, split=k, clear=True)\n",
    "    print(\"Number of candidates:\", session.query(ChemicalDisease).filter(ChemicalDisease.split == k).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM] Loaded model <chemical_disease.lstm>\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning.pytorch import LSTM\n",
    "\n",
    "lstm = LSTM(n_threads=10)\n",
    "lstm.load('chemical_disease.lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all candidates from db...\n",
      "124 candidates load from db!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading all candidates from db...\")\n",
    "all_cands = session.query(ChemicalDisease).filter(ChemicalDisease.split == 0).order_by(ChemicalDisease.id).all()\n",
    "print(\"{} candidates load from db!\".format(len(all_cands)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LSTM to candidates...\n",
      "Saved 124 marginals\n",
      "CPU times: user 2.11 s, sys: 100 ms, total: 2.21 s\n",
      "Wall time: 474 ms\n",
      "LSTM applied!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kroll/.conda/envs/snorkel/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "print(\"Applying LSTM to candidates...\")\n",
    "%time lstm.save_marginals(session, all_cands)\n",
    "print(\"LSTM applied!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing candidate labels into result file: results/tafamidis97/chemical_disease_association.tsv\n",
      "Amount of candidates: 124\n",
      "Load mariginals from db...\n",
      "Marginals loaded!\n",
      "Building sentence to document map...\n",
      "Map built!\n",
      "Saved 24 positive predicitions for binary relation!\n",
      "CPU times: user 3.17 s, sys: 24 ms, total: 3.19 s\n",
      "Wall time: 1.35 s\n"
     ]
    }
   ],
   "source": [
    "from ksnorkel import KSUtils\n",
    "\n",
    "header_str = '{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}'.format('document_id', 'sentence_id', 'cand_id', 'chemical_cid', 'chemical_span', 'disease_cid', 'disease_span')\n",
    "%time KSUtils.save_binary_relation_as_tsv(result_path + \"chemical_disease_association.tsv\", session, all_cands, all_sents, header_str, 'chemical_cid', 'disease_cid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snorkel)",
   "language": "python",
   "name": "snorkel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
