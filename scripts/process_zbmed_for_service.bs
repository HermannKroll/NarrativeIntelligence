#!/bin/bash

ZBMED_JSON="/hdd2/datasets/zbmed/zbmed_updates.json"
# Default : START_CRAWL_DATA="2019-12-01"
START_CRAWL_DATA="2021-12-01"
STOP_CRAWL_DATA="2021-12-05"
ZBMED_PUBTATOR="/hdd2/datasets/zbmed/zbmed.json"
UPDATED_IDS="/hdd2/datasets/zbmed/updated_ids.txt"

## Load everything
# curl 'https://preview.zbmed.de/api/documents/' -X 'POST' -H 'Content-Type: application/json' -H 'Accept: application/json' --data-binary '{"size":40000,"from":0,"query":{"bool":{"must":[{"range":{"date":{"gte":"2019-12-01||/M","lt":"2021-12-18"}}}]}},"sort":[{"_score":{"order":"asc"}}],"track_total_hits":true}' >  $ZBMED_JSON


# First curl the updates
# #curl 'https://preview.zbmed.de/api/documents/' -X 'POST' -H 'Content-Type: application/json' -H 'Accept: application/json' --data-binary '{"size":40000,"from":0,"query":{"bool":{"must":[{"range":{"date":{"gte":"$START_CRAWL_DATA||/M","lt":"$STOP_CRAWL_DATA"}}}]}},"sort":[{"_score":{"order":"asc"}}],"track_total_hits":true}' > $ZBMED_JSON
curl 'https://preview.zbmed.de/api/documents/' -X 'POST' -H 'Content-Type: application/json' -H 'Accept: application/json' --data-binary '{"size":40000,"from":0,"query":{"bool":{"must":[{"range":{"date":{"gte":"2021-12-15||/M","lt":"2022-01-06"}}}]}},"sort":[{"_score":{"order":"asc"}}],"track_total_hits":true}' > $ZBMED_JSON

# Load everything
python3 ~/NarrativeIntelligence/src/narraint/backend/load_zbmed_json.py $ZBMED_JSON -c ZBMed

# Next, tag the documents with our PharmDictTagger
python3 ~/NarrativeAnnotation/src/narrant/preprocessing/dictpreprocess.py -c ZBMed --skip-load --workers 15

# Perform pharmaceutical classification
python3 ~/NarrativeAnnotation/src/narrant/preprocessing/classification.py -c ZBMed -r /home/kroll/NarrativeAnnotation/resources/classification/pharmaceutical_classification_rules.txt --cls Pharmaceutical -w 15 --skip-load


# Export the document content
python3 ~/NarrativeAnnotation/src/narrant/backend/export.py -d $ZBMED_PUBTATOR --collection ZBMed --format json

# Run GNormPlus
python3 ~/NarrativeAnnotation/src/narrant/preprocessing/preprocess.py $ZBMED_PUBTATOR -c ZBMed --skip-load --workers 5 --gnormplus



# Do the statement extraction for all ZBMed documents via our Pipeline
python3 ~/NarrativeIntelligence/src/narraint/extraction/pharmaceutical_pipeline.py -c ZBMed -et PathIE --workers 15 --relation_vocab ~/NarrativeIntelligence/resources/pharm_relation_vocab.json

# Do the canonicalizing step
python3 ~/KGExtractionToolbox/src/kgextractiontoolbox/cleaning/canonicalize_predicates.py -c ZBMed --word2vec_model /home/kroll/workingdir/BioWordVec_PubMed_MIMICIII_d200.bin --relation_vocab ~/NarrativeIntelligence/resources/pharm_relation_vocab.json

# Apply the rules
python3 ~/NarrativeIntelligence/src/narraint/cleaning/pharmaceutical_rules.py -c ZBMed

